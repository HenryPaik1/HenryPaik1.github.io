<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>[Hadoop_Cluster] Tutorial with GCP(Google Cloud Platform)</title>
      <link href="/2019/04/15/hadoop_tutorial/"/>
      <url>/2019/04/15/hadoop_tutorial/</url>
      
        <content type="html"><![CDATA[<h1 id="Tutorial-GCP-instance로-Hadoop-Cluster-구성"><a href="#Tutorial-GCP-instance로-Hadoop-Cluster-구성" class="headerlink" title="Tutorial: GCP instance로 Hadoop Cluster 구성"></a>Tutorial: GCP instance로 Hadoop Cluster 구성</h1><ul><li><a href="https://codethief.io/hadoop101/" target="_blank" rel="noopener">reference</a> 참고하여 정리한 글입니다.<a id="more"></a></li></ul><h3 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h3><ul><li>GCP VM instance 생성 및 Hadoop 환경/ssh key 설정</li><li>상기 instance로 snapshot 생성</li><li>slave node용 instance 추가 생성 by snapshot</li></ul><h3 id="Step-1-install-and-set-Hadoop-config"><a href="#Step-1-install-and-set-Hadoop-config" class="headerlink" title="Step 1: install and set Hadoop config."></a>Step 1: install and set Hadoop config.</h3><ul><li>Prerequisite: GCP VM instance<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ sudo add-apt-repository ppa:webupd8team/java</span><br><span class="line">$ sudo apt-get update &amp;&amp; sudo apt-get install -y build-essential oracle-java8-set-default</span><br><span class="line"></span><br><span class="line">$ wget http://apache.claz.org/hadoop/common/hadoop-3.1.1/hadoop-3.1.1.tar.gz</span><br><span class="line">$ tar -xzvf hadoop-3.1.1.tar.gz</span><br><span class="line">$ sudo mv hadoop-3.1.1 /usr/local/hadoop</span><br><span class="line"></span><br><span class="line">$ sudo vi /etc/environment</span><br><span class="line"></span><br><span class="line">PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/hadoop/bin:/usr/local/hadoop/sbin&quot;</span><br><span class="line">JAVA_HOME=&quot;/usr/lib/jvm/java-8-oracle/jre&quot;</span><br><span class="line"></span><br><span class="line">$ source /etc/environment #or export JAVA_HOME=/usr/lib/jvm/java-8-oracle/jre</span><br><span class="line"></span><br><span class="line"># Run test application</span><br><span class="line">$ hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar wordcount /usr/local/hadoop/LICENSE.txt ~/output</span><br><span class="line">cat ~/output/part-r-*</span><br></pre></td></tr></table></figure></li></ul><h4 id="cf-Official-tutorial"><a href="#cf-Official-tutorial" class="headerlink" title="cf. Official tutorial"></a>cf. <a href="https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" target="_blank" rel="noopener">Official tutorial</a></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Complie and Create jar</span><br><span class="line">$ bin/hadoop com.sun.tools.javac.Main WordCount.java</span><br><span class="line">$ jar cf wc.jar WordCount*.class</span><br><span class="line"></span><br><span class="line"># Input dir</span><br><span class="line">$ bin/hadoop fs -ls /user/joe/wordcount/input/</span><br><span class="line">&gt;&gt; /user/joe/wordcount/input/file01</span><br><span class="line">&gt;&gt; /user/joe/wordcount/input/file02</span><br><span class="line"></span><br><span class="line">$ bin/hadoop fs -cat /user/joe/wordcount/input/file01</span><br><span class="line">&gt;&gt; Hello World Bye World</span><br><span class="line"></span><br><span class="line">$ bin/hadoop fs -cat /user/joe/wordcount/input/file02</span><br><span class="line">&gt;&gt; Hello Hadoop Goodbye Hadoop</span><br></pre></td></tr></table></figure><h3 id="Step2-Set-Hadoop-Cluster-link"><a href="#Step2-Set-Hadoop-Cluster-link" class="headerlink" title="Step2. Set Hadoop Cluster (link)"></a>Step2. Set Hadoop Cluster <a href="https://hadoop.apache.org/docs/r3.1.2/hadoop-project-dist/hadoop-common/ClusterSetup.html" target="_blank" rel="noopener">(link)</a></h3><p>1)  <code>hdfs-site.xml</code></p><ul><li>Configurations for Name/DataNode</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vi /usr/local/hadoop/etc/hadoop/hdfs-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/usr/local/hadoop/data/nameNode&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/usr/local/hadoop/data/dataNode&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;2&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>2) <code>core-site.xml</code></p><ul><li>NameNode URI</li><li>Size of R/W buffer, etc  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vi /usr/local/hadoop/etc/hadoop/core-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.default.name&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://master:9000&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>3) <code>yarn-site.xml</code></p><ul><li>Configurations for ResourceManager and NodeManager</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vi /usr/local/hadoop/etc/hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>4) <code>mapred-site.xml</code></p><ul><li>Configurations for MapReduce App</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vi /usr/local/hadoop/etc/hadoop/mapred-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>5) Define Master/Workers</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vi /usr/local/hadoop/etc/hadoop/workers</span><br><span class="line"></span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line"></span><br><span class="line">$ sudo vi /usr/local/hadoop/etc/hadoop/masters</span><br><span class="line"></span><br><span class="line">master</span><br></pre></td></tr></table></figure><h3 id="Step-3-Set-SSH"><a href="#Step-3-Set-SSH" class="headerlink" title="Step 3. Set SSH"></a>Step 3. Set SSH</h3><ul><li>make the master node connect to the slave nodes without password<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># generate key</span><br><span class="line">$ ssh-keygen -t rsa</span><br><span class="line"></span><br><span class="line"># append it to &apos;authorized_keys&apos;</span><br><span class="line">$ cat &gt;&gt; ~/.ssh/authorized_keys &lt; ~/.ssh/id_rsa.pub</span><br><span class="line"></span><br><span class="line"># check ssh</span><br><span class="line">$ ssh localhost</span><br></pre></td></tr></table></figure></li></ul><h3 id="Step-4-Create-Snapshot-GCP"><a href="#Step-4-Create-Snapshot-GCP" class="headerlink" title="Step 4. Create Snapshot(GCP)"></a>Step 4. Create Snapshot(GCP)</h3><ul><li>Create snapshot and launch two more instances</li><li>Create a instance Group<ul><li>AWS Security Group설정 대신 그룹으로 묶음</li><li>Bind all the 3 instances</li></ul></li></ul><h3 id="Step-5-ssh-Connection"><a href="#Step-5-ssh-Connection" class="headerlink" title="Step 5. ssh Connection"></a>Step 5. ssh Connection</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vi /etc/hosts</span><br><span class="line"></span><br><span class="line"># Private IP</span><br><span class="line">127.0.0.1 localhost</span><br><span class="line">10.0.0.1.2 master</span><br><span class="line">10.0.0.1.3 slave1</span><br><span class="line">10.0.0.1.4 slave2</span><br><span class="line"></span><br><span class="line"># test connection</span><br><span class="line">$ ssh slave1</span><br><span class="line">$ exit</span><br><span class="line">$ ssh slave2</span><br><span class="line">$ exit</span><br><span class="line"></span><br><span class="line"># update each instance&apos;s hosts files</span><br><span class="line">$ cat /etc/hosts | ssh slave1 &quot;sudo sh -c &apos;cat &gt;/etc/hosts&apos;&quot;</span><br><span class="line">$ cat /etc/hosts | ssh slave2 &quot;sudo sh -c &apos;cat &gt;/etc/hosts&apos;&quot;</span><br></pre></td></tr></table></figure><h3 id="Step-6-Run-Hadoop-Cluster"><a href="#Step-6-Run-Hadoop-Cluster" class="headerlink" title="Step 6. Run Hadoop Cluster"></a>Step 6. Run Hadoop Cluster</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># test cluster</span><br><span class="line">$ hdfs namenode -format</span><br><span class="line">$ start-dfs.sh</span><br><span class="line">$ jps</span><br><span class="line">$ hadoop fs -mkdir /test</span><br><span class="line">$ hadoop fs -ls /</span><br><span class="line">$ hdfs dfsadmin -report</span><br><span class="line"></span><br><span class="line"># run cluster manager</span><br><span class="line">$ start-yarn.sh</span><br><span class="line">$ yarn node -list</span><br><span class="line"></span><br><span class="line"># upload data and run wordcount</span><br><span class="line">$ hadoop fs -put /usr/local/hadoop/LICENSE.txt /test/</span><br><span class="line">$ yarn jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar wordcount hdfs:///test/LICENSE.txt /test/output</span><br><span class="line"></span><br><span class="line"># read data</span><br><span class="line">$ hadoop fs -text /test/output/*</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Spark_5] Kafka with twitter stream(1)</title>
      <link href="/2019/04/08/spark-twi/"/>
      <url>/2019/04/08/spark-twi/</url>
      
        <content type="html"><![CDATA[<h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><ul><li>분산처리가 가능한 고성능 메세지 큐(streaming data를 저장/읽기/분석을 가능하게 함)<a id="more"></a></li><li>kafka는 Broker의 역할</li><li>Topic안에 partition 기능 존재 <a href="https://www.slideshare.net/HadoopSummit/apache-kafka-best-practices" width-500="" target="_blank" rel="noopener">(link)</a><ul><li>partition안에서는 순서 바뀌고, b/w partition은 순서 보장(유지)<br><img src="/img/kafka_concept.png"></li></ul></li><li>특징<ul><li>file copy 불필요</li><li>delay되지 않도록, 저장되기 전 consumer에 뿌려줘야 함.</li><li>메세지를 디스크에 저장. 유실없음.</li><li>메세지 중복/유실 문제<ul><li>trade-off</li><li>유실 안하려면 중복 vs 중복 안하면 유실 위험</li><li>default: At least once(유실 회피)</li></ul></li></ul></li><li>구조<ul><li>cluster형식으로 실행</li><li>Kafka cluster는 <code>topic</code>의 records stream을 저장</li><li>record는 key, value, timestamp로 구성됨</li></ul></li><li>핵심 API: Producer/Consumer/Streams/Connector API<br><img src="/img/kafka-api.png" width="500"><ul><li>Producer API: App이 steram of records를 Kafka Topic으로 전송하도록 함</li><li>Consumer API: App이 topic을 subscribe하고 stream of records를 처리하도록 함</li><li>Streams API: App이 stream processor 역할을 하도록 함. stream processor는 topic의 input stream을 받아 transform하여 output stream 생성  </li><li>Connector API: Kafka topic을 현재 app 또는 data system에 연결하는 producers/consumers를 실행하도록 함. eg. RDB에 연결된 Connector는 table의 모든 변경사항을 capture</li></ul></li></ul><hr><h1 id="Tutorial-twitter-stream을-kafka로-받아오기"><a href="#Tutorial-twitter-stream을-kafka로-받아오기" class="headerlink" title="Tutorial: twitter stream을 kafka로 받아오기"></a>Tutorial: twitter stream을 kafka로 받아오기</h1><h4 id="kafka-실행"><a href="#kafka-실행" class="headerlink" title="kafka 실행"></a>kafka 실행</h4><ul><li><p>install</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ curl &quot;http://www-eu.apache.org/dist/kafka/1.1.0/kafka_2.12-1.1.0.tgz&quot; -o ~/Downloads/kafka.tgz</span><br><span class="line">$ mkdir ~/kafka &amp;&amp; cd ~/kafka</span><br><span class="line">$ tar -xvzf ~/Downloads/kafka.tgz --strip 1</span><br></pre></td></tr></table></figure></li><li><p>zookeeper &amp; server 실행: zookeeper가 서버 매니징</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># start server</span><br><span class="line">## terminal1</span><br><span class="line">$ bin/zookeeper-server-start.sh config/zookeeper.properties</span><br><span class="line"></span><br><span class="line">## terminal2</span><br><span class="line">$ bin/kafka-server-start.sh config/server.properties</span><br><span class="line"></span><br><span class="line"># create a topic</span><br><span class="line">## terminal3</span><br><span class="line">$ bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test</span><br><span class="line"></span><br><span class="line"># create producer</span><br><span class="line">## terminal4</span><br><span class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test</span><br><span class="line">&gt;&gt; This is a message</span><br><span class="line">&gt;&gt; This is another message</span><br><span class="line"></span><br><span class="line"># create consumer</span><br><span class="line">## terminal5</span><br><span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</span><br><span class="line">&gt;&gt; This is a message</span><br><span class="line">&gt;&gt; This is another message</span><br></pre></td></tr></table></figure></li><li><p>정리: producer(console) - kafka(zookeeper) - consumer(console)</p><ul><li>각 단계에서 test topic create - subscribe  </li></ul></li></ul><h4 id="twitter-설정"><a href="#twitter-설정" class="headerlink" title="twitter 설정"></a>twitter 설정</h4><ul><li>install <code>twitter connector</code></li><li><p><a href="https://github.com/Eneco/kafka-connect-twitter" target="_blank" rel="noopener">https://github.com/Eneco/kafka-connect-twitter</a></p><ul><li>install mvn <code>mvn clean package</code></li><li>export CLASSPATH=<code>pwd</code>/target/kafka-connect-twitter-0.1-jar-with-dependencies.jar</li><li>CLASSPATH = /home/henry/kafka_twitter/kafka-connect-twitter/target/kafka-connect-twitter-0.1-jar-with-dependencies.jar<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export KAFKA=카프카_다운로드_받은_경로 `pwd`</span><br><span class="line">$KAFKA/bin/connect-standalone.sh connect-simple-source-standalone.properties twitter-source.properties</span><br></pre></td></tr></table></figure></li></ul></li><li><p>설정파일 만들기</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cp twitter-source.properties.example twitter-source.properties</span><br></pre></td></tr></table></figure></li><li><p>key 토큰 받기</p><ul><li>트위터 스트림 받기: <a href="https://dev.twitter.com/streaming/overview" target="_blank" rel="noopener">https://dev.twitter.com/streaming/overview</a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ vim twitter-source.properties</span><br><span class="line"></span><br><span class="line">twitter.consumerkey=TI~</span><br><span class="line">twitter.consumersecret=GP~</span><br><span class="line">twitter.token=11~</span><br><span class="line">twitter.secret=5N~</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>중요: outdated된 code 최신화 필요</strong>(<a href="https://github.com/Eneco/kafka-connect-twitter/pull/56/files" target="_blank" rel="noopener">https://github.com/Eneco/kafka-connect-twitter/pull/56/files</a>)</p><ul><li>수정 후 다시 build <code>mvn clean package</code></li></ul></li></ul><h4 id="실행"><a href="#실행" class="headerlink" title="실행"></a>실행</h4><ul><li>kafka: <code>connect-standalone.sh</code></li><li>kafka-connect-twitter: <code>connect-simple-source-standalone.properties</code> &amp; <code>twitter-source.properties</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd kafka-connect-twitter</span><br><span class="line">$ $KAFKA/bin/connect-standalone.sh connect-simple-source-standalone.properties twitter-source.properties</span><br></pre></td></tr></table></figure></li></ul><hr><h3 id="추가"><a href="#추가" class="headerlink" title="추가"></a>추가</h3><ul><li>실행파일 jar - zip파일 압축파일임</li><li>build: 소스코드를 실행 가능한 상태로 만들기<ul><li>소스코드를 컴파일하면 실행파일이 나옴</li></ul></li><li><code>maven</code>: 빌드해야할 코드가 너무 많고 다른 pjt코드도 가져와야 할 때 사용</li></ul>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[AWS_5] AWS kinesis</title>
      <link href="/2019/04/08/AWS-kinesis/"/>
      <url>/2019/04/08/AWS-kinesis/</url>
      
        <content type="html"><![CDATA[<h3 id="AWS-kinesis"><a href="#AWS-kinesis" class="headerlink" title="AWS kinesis?"></a>AWS kinesis?</h3><ul><li>Kinesis Stream: 대규모 데이터 레코드 스트림을 실시간 수집/처리(<em>Amazon Kinesis is an AWS service that collects, processes, and analyzes data in real time.</em>)</li></ul><h2 id="이벤트-log-등-수집-단계에서-유의점"><a href="#이벤트-log-등-수집-단계에서-유의점" class="headerlink" title="(이벤트/log 등)수집 단계에서 유의점"></a>(이벤트/log 등)수집 단계에서 유의점</h2><a id="more"></a><ul><li>lambda 사용하지 말자<ul><li>프로그램(coding)없이 기존 서비스로 저장 가능하다면 해당 서비스 사용</li><li>eg. API Gateway, Kinesis Stream, Firehose -&gt; 수집하여 -&gt; S3에 넣기(RDBMS (X))</li></ul></li><li>수집은 실시간(event 등)</li><li>cf. ETL Tool: 테이블 옮기기 위해서는 DMS tool사용</li></ul><h3 id="1-Data-Pipeline-개괄-link"><a href="#1-Data-Pipeline-개괄-link" class="headerlink" title="1) Data Pipeline 개괄(link)"></a>1) Data Pipeline 개괄(<a href="https://www.xenonstack.com/blog/ingestion-processing-big-data-iot-stream/" target="_blank" rel="noopener">link</a>)</h3><p><img src="/img/datapipe-archi.png" width="500"></p><ul><li>Data Collect: Kinesis, Firehose, Amazone API Gateway<ul><li>온프레미스 경우, DB에 다 넣음(RDBMS) by Sqoop -&gt; 이후 병렬작업해서 S3로 내림</li><li>수집pipline은 한번 Set-up해두면 새로운 channel 추가는 빠름</li><li>협력업체 데이터도 수집필요</li><li>S3에 쌓기</li></ul></li><li>전처리: EMR + Glue/S3 -&gt; 의미있는 값의 집합(전처리된 데이터). 이후 S3에 저장.<ul><li>Spark 처리하려면 S3안에 있어야 함<ul><li>Why? RDB에 넣어두면 여러명이 접근하면 부하걸림 S3에 다 넣기</li><li>eg. SQL join 등등</li></ul></li></ul></li><li>분석 및 시각화:<ul><li>Data Mart: 각 부서에서 원하는 데이터 구성(A single subject or functional organization area)<br><img src="/img/data_mart.jpg"></li><li>하둡 테이블로 저장해두면 red shift, AWS Athena 등이 S3에 있는 데이터를 읽어옴 -&gt; tableau, Periscope data, Apache Superset, Zeppelin</li></ul></li></ul><h3 id="2-Kinesis-Firehose-Amazone-API-Gateway-amp-S3"><a href="#2-Kinesis-Firehose-Amazone-API-Gateway-amp-S3" class="headerlink" title="2) Kinesis, Firehose, Amazone API Gateway &amp; S3"></a>2) Kinesis, Firehose, Amazone API Gateway &amp; S3</h3><ul><li>상기 조합의 장점<ul><li>S3 저장공간 무제한</li><li>kinesis Stream에서 데이터 24시간 보존 -&gt; 바로 가공 가능</li><li>S3에 반정형화된 json형식으로 데이터 저장 -&gt; 가변적 데이터 수집, 유연한 분석 가능</li></ul></li></ul><hr><p>AWS 실습</p><h4 id="1-kinesis"><a href="#1-kinesis" class="headerlink" title="1) kinesis"></a>1) kinesis</h4><ul><li>shard 숫자 설정</li><li>Delivery stream name = kinesis name<ul><li>운영시 압축확장자: gzip</li></ul></li><li><p>kinessis firehose에 S3 버킷 지정: raw-data/bhr-dees2/</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># send sth to kinesis from ec2(S3에 저장)</span><br><span class="line">$ aws kinesis put-record --stream-name [kineisis name:bhr-dee2] --partition-key [option: 123] --data [data:bhr_testdata123] aws configure</span><br><span class="line"></span><br><span class="line"># data 확인</span><br><span class="line">$ SHARD_ITERATOR=$(aws kinesis get-shard-iterator --shard-id shardId-000000000000 --shard-iterator-type TRIM_HORIZON --stream-name bhr-dee2 --query &apos;ShardIterator&apos;)</span><br><span class="line">aws kinesis get-records --shard-iterator $SHARD_ITERATOR</span><br><span class="line"></span><br><span class="line"># 하기 링크에사 base 64 디코딩</span><br><span class="line">http://www.convertstring.com/ko/EncodeDecode/Base64Decode</span><br><span class="line">&gt;&gt; result: [data:bhr_testdata123]</span><br></pre></td></tr></table></figure></li><li><p>record하면 ec2 -&gt; kinesis로 쏴주는 것.</p></li><li>조회는 kinesis로 작성한 내용 조회</li><li>kinesis monitoring: get_records 그래프로 작성여부  확인가능</li></ul><h4 id="2-API-gateway"><a href="#2-API-gateway" class="headerlink" title="2) API gateway"></a>2) API gateway</h4><ul><li>모든 event를 API gateway 통해서 받으면 가격이 비쌈</li><li>kinesis agent 가 log 정리/취합</li><li><code>create resource</code></li><li>data receive method: http 방식<ul><li>어떤 method? post 방식<ul><li>get은 파일 크기가 정해져 있음. 이슈발생 가능성 있음.</li></ul></li></ul></li><li><p>send data to kinesis from API gateway</p><ul><li>헤더값을 보고 인식</li><li><code>intergration</code>: 들어온 데이터 어떻게 처리/관리 (언어: velocity(context handling))</li><li><code>deploy</code> 적용<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># json형식 data를 kinesis로 발송</span><br><span class="line">$ curl -d &apos;&#123;&quot;key1&quot;:&quot;value1&quot;, &quot;key2&quot;:&quot;value2&quot;&#125;&apos; -H &quot;Content-Type: application/json&quot; -X POST  https://7ud79aqdo7.execute-api.ap-northeast-2.amazonaws.com/prod/v1</span><br></pre></td></tr></table></figure></li></ul></li><li><p><code>cloud watch</code>: API ID 사용(eg. 7ud79aqdo7)</p><ul><li>API 설정시 enable cloudwatch log 설정</li><li>throattling setting 필요: 10k개 이상되면 뱉어내기 때문.</li></ul></li></ul><hr><h3 id="추가1-Shard-link"><a href="#추가1-Shard-link" class="headerlink" title="추가1. Shard (link)"></a>추가1. Shard <a href="https://stackoverflow.com/questions/992988/what-is-sharding-and-why-is-it-important" target="_blank" rel="noopener">(link)</a></h3><ul><li>similar to “horizontal partitioning” of DB</li><li><ul><li>horizontal partitioning이외에 여러개 instance에 대해서도 작업 가능 (<em>does this across potentially multiple instances of the schema.</em>)</li></ul></li><li>Horizontal partitioning: DB table을 column이 아닌 row 단위로 partitioning하여 따로 관리(<em>Horizontal partitioning is a design principle whereby rows of a database table are held separately, rather than splitting by columns (as for normalization)</em>)</li><li>각 partition이 shard의 부분(<em>Each partition forms part of a shard, which may in turn be located on a separate database server or physical location</em>)</li><li>search perfomance 향상</li></ul><h3 id="추가2-Kinesis-Firehose-link"><a href="#추가2-Kinesis-Firehose-link" class="headerlink" title="추가2. Kinesis Firehose (link)"></a>추가2. Kinesis Firehose <a href="https://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html" target="_blank" rel="noopener">(link)</a></h3><ul><li>consumer 중 하나로서, 자동으로 데이터를 S3/redshift(AWS의 DW)/AWS ES(elastic search)/Splunk로 보내기 위한 관리형 서비스</li><li><em>Amazon Kinesis Data Firehose is a fully managed service for delivering real-time streaming data to destinations such as Amazon Simple Storage Service (Amazon S3), Amazon Redshift, Amazon Elasticsearch Service (Amazon ES), and Splunk. </em><ul><li>이전에는 Lambda가 위 역할수행</li></ul></li><li>Firehose가 없다면 큐는 인덱싱없이 FIFO만 구현</li><li>Firehose는 큐의 인덱싱을 관리하는 역할<br><img src="/img/firehose-flow1.png" width="500"><br><img src="/img/firehose-flow2.png" width="500"></li><li>Destination: S3, RedShift, AWS ES, splunk</li><li>유용한 기능<ul><li>데이터를 받아서 서로 다른 bucket에 저장 가능</li><li>여러 consumer로부터 데이터 수집/관리 가능</li></ul></li></ul><hr><p>질문 1)<br>서버에 있는 로그는 어떻게 수집?</p><ul><li>kinesis는 서버에 쌓여있는 로그를 읽어와서 다시 저장.</li><li>폴더를 바라보고 있으면 데이터가 쌓일 때마다 쏴줌</li><li>EC2가 kinesis 바라보고 있으면, kinesis로 계속 쏴줌</li></ul><p>질문 2)</p><ul><li>실시간 분석은 DB가 아니라 큐(kafka: 하드디스크 queue…)에 넣어야 함.</li><li>큐에 넣어두면, 큐에 데이터가 존재하는 동안 여러 consumer(ec2 instance -&gt; S3/Rdeshift/EMR …)가 사용할 수 있음</li><li>그렇지 않으면, DB connection, JDBC등 사용하여 접속하여 다시 접근하므로 cost발생.</li></ul><p>질문 3)<br>비정형데이터를 정형화 데이터로 바꾼다는 의미?</p><ul><li>raw Data -&gt; transformed Data</li></ul><p>질문 4)</p><ul><li>AWS 안쓰고 온프레미스라면? 최근 2년 기간 데이터는 oracle, 나머지는 하둡.</li></ul><p>질문 5)<br>왜 큐에다 쏘는가?</p><ul><li>큐는 데이터 처리의 완충작용</li><li>앱 구동시, RDBMS에 insert하면서 5초 소요된다면? 큰 문제.</li><li>때문에 로그 처리는 바로 큐로 날려줌 -&gt; 앱 사용에 딜레이 발생X</li><li>큐에 던지면 큐가 일단 받음.</li><li>앱에서만 이용하는 이벤트도 큐로 받음.</li></ul><p>질문 6)<br>AWS의 S3와 Spark 조합을, 온프레미스 MySQL과 Spark 조합으로 대체 가능한가?</p><ul><li>성능차이 발생. S3를 수백대의 Slave가 바라봐도 문제없음. MySQL은 과부하 발생</li></ul><p>기타 1)</p><ul><li>AWS 서비스별 API 존재. kinesis Stream의 Shard 자동 조절 가능.</li><li>raw data는 json형식으로. Parquet은 바로 안됨.</li></ul>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kinesis </tag>
            
            <tag> Shard </tag>
            
            <tag> API_gateway </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Spark_4] Cluster Resource Management</title>
      <link href="/2019/04/06/spark-resource/"/>
      <url>/2019/04/06/spark-resource/</url>
      
        <content type="html"><![CDATA[<p>이하는 link 자료를 정리함 <a href="https://www.samsungsds.com/global/ko/support/insights/Spark-Cluster-job-server.html" target="_blank" rel="noopener">(link1, <a href="https://www.samsungsds.com/global/ko/support/insights/Spark-Cluster-job-server-2.html" target="_blank" rel="noopener">link2)</a></a></p><hr><h3 id="Cluster-resource-최적화"><a href="#Cluster-resource-최적화" class="headerlink" title="Cluster resource 최적화"></a>Cluster resource 최적화</h3><h2 id=""><a href="#" class="headerlink" title=""></a><a id="more"></a></h2><h4 id="1-Spark-Job-Server-이용하여-Spark-Context-리소스-미리-확보"><a href="#1-Spark-Job-Server-이용하여-Spark-Context-리소스-미리-확보" class="headerlink" title="1) Spark Job Server 이용하여 Spark Context 리소스 미리 확보"></a>1) Spark Job Server 이용하여 Spark Context 리소스 미리 확보</h4><ul><li>문제상황: 여러 Application 실행시, 매 실행마다 Spark Context 생성/resource 해제를 반복하면, 스로세스 실행/종료에 따른 일련의 과정에서 시간이 낭비<ul><li>Application(eg. 1+1 function) 실행 -&gt; Spark Context 생성 -&gt; executor 프로세스 실행 -&gt; 작업 완료 -&gt; Application 종료: 새로 App 실행하려면 n 초가 소요됨</li><li>App 여러개면 이걸 반복하고  n초 x m 개의 시간이 낭비됨</li></ul></li><li>해결책: Spark Job Server<ul><li>하나의 Application을 Deamon형태로 실행 -&gt; 이곳에 Job group을 실행(n Job 1 App(0) vs1 Job 1 App(X))</li></ul></li></ul><h4 id="2-Fair-Scheduler-Spark-Context-내-Job의-우선순위-및-적정배분"><a href="#2-Fair-Scheduler-Spark-Context-내-Job의-우선순위-및-적정배분" class="headerlink" title="2) Fair Scheduler: Spark Context 내 Job의 우선순위 및 적정배분"></a>2) Fair Scheduler: Spark Context 내 Job의 우선순위 및 적정배분</h4><ul><li>문제상황: <strong>여러 개의 Job</strong> 실행, Task 수는 다름.<ul><li>Application 1개에서 Job A, B, C 실행 -&gt; 각 Job은 n개의 Task로 나눠짐</li><li>Job A: t1, t2, …, t10 / Job B: t1, t2, …, t10, / Job C: t1, t2</li><li>Queue와 같이 Job은 FIFO를 따름</li><li>즉 Job A, Job B의 Task들이 모든 Executor를 독점하고 끝낼 때까지, Job C는 Task2인데 대기해야.</li></ul></li><li>해결책: Fair Scheduler<ul><li><strong>한 가지 Job의 Task가 executor 독점하지 못하고, 각 executor에 여러가지 Job의 Task를 실행</strong>  </li></ul></li></ul><h4 id="3-Dynamic-Resource-Allocation-Spark-Context-간-효율적-리소스-재분배"><a href="#3-Dynamic-Resource-Allocation-Spark-Context-간-효율적-리소스-재분배" class="headerlink" title="3) Dynamic Resource Allocation: Spark Context 간 효율적 리소스 재분배"></a>3) Dynamic Resource Allocation: Spark Context 간 효율적 리소스 재분배</h4><ul><li>문제상황: Spark Cluster에 <strong>여러 Application 존재</strong><ul><li>App1, App2, App3은 Cluster Manager를 통해 resource 예약(여기서 resource는 executor의 수 및 각 executor가 사용가능한 CPU core 수)</li><li>App1의 작업이 빨리 종료. executor 남음.</li><li>App2, App3에 이미 할당한 executor가 정해져 있으므로, (App1 작업 끝낸) resource는 사용되지 않음.</li></ul></li><li>해결책: Dynamic Resource Allocation<ul><li>Resource(executor)를 많이 필요로 하는 App2, 3에서 추가로 Resource 요청</li><li>다만, 개별 App가 최대로 사용할 수 있는 executor의 수를 정하여, 독점하지 못하게 함.</li><li>이유는, App1의 작업이 끝나고, 다음 App n을 실행해야 하는데, resource를 이미 모두 App2, App3에 할당했을 경우, 바로 App n에 대응을 할 수 없음</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark_resource </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Stat_Test_2] Basic Statistical Test</title>
      <link href="/2019/03/22/test_basic/"/>
      <url>/2019/03/22/test_basic/</url>
      
        <content type="html"><![CDATA[<h1 id="SciyPy-활용한-기초-검정"><a href="#SciyPy-활용한-기초-검정" class="headerlink" title="SciyPy 활용한 기초 검정"></a>SciyPy 활용한 기초 검정</h1><a id="more"></a><ul><li>이항 검정 (Binomial test): 이항분포의 모수가 예상 모수와 일치하는가?</li><li><strong>카이 제곱 검정 (Chi-square test)</strong><ul><li>카테고리분포가 exp와 일치하는가?</li><li>두 확률변수가 독립인가?</li></ul></li><li><strong>단일 표본 t-검정 (One-sample t-test)</strong>: 정규분포일 때 기댓값 mu인가?</li><li><strong>독립 표본 t-검정 (Independent-two-sample t-test)</strong>: 두 집단 기댓값이 같은가?</li><li>대응 표본 t-검정 (Paired-two-sample t-test)</li><li>분산 검정 (Chi squared variance test)</li><li>등분산 검정 (Equal-variance test)</li><li>정규성 검정 (Normality test)</li><li><strong>Kolmogorov-Smirove test</strong>: 두 표본이 같은 분포인지 검정</li></ul><h2 id="1-이항-검정-두-가지-값을-가지는-확률변수의-분포-판단"><a href="#1-이항-검정-두-가지-값을-가지는-확률변수의-분포-판단" class="headerlink" title="1. 이항 검정: 두 가지 값을 가지는 확률변수의 분포 판단"></a>1. 이항 검정: 두 가지 값을 가지는 확률변수의 분포 판단</h2><h3 id="이항검정-예1"><a href="#이항검정-예1" class="headerlink" title="이항검정 예1"></a>이항검정 예1</h3><ul><li>동전 10번 던질 때,<ul><li>앞: 7</li><li>뒤: 3</li></ul></li><li>위 동전은 앞면이 더 잘 나오는 동전인가?</li><li>= 앞면 나올 확률이 0.5 초과하는가?</li><li>귀무가설: 앞면 나올 확률은 0.5. 기각하지 못함</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 실제 모수 0.5</span></span><br><span class="line"><span class="comment"># n: 베르누이 시행, 10개 샘플에서 1(성공) 갯수</span></span><br><span class="line">mu_0 = <span class="number">0.5</span>; N = <span class="number">10</span>;</span><br><span class="line">sample = sp.stats.bernoulli(mu_0).rvs(N)</span><br><span class="line">n = np.count_nonzero(sample)</span><br><span class="line">n</span><br></pre></td></tr></table></figure><pre><code>3</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.binom_test(<span class="number">3</span>, N, p=mu_0)</span><br></pre></td></tr></table></figure><pre><code>0.3437499999999999</code></pre><h3 id="이항검정-예2"><a href="#이항검정-예2" class="headerlink" title="이항검정 예2"></a>이항검정 예2</h3><ul><li>동전 100 번 던졌을 때, 앞면이 52번 나왔다면</li><li>위 동전은 앞면이 더 잘 나오는 동전인가? No</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mu_0 = <span class="number">0.5</span>; N = <span class="number">100</span>;</span><br><span class="line">sample = sp.stats.bernoulli(mu_0).rvs(N)</span><br><span class="line">n = np.count_nonzero(sample)</span><br><span class="line">n</span><br></pre></td></tr></table></figure><pre><code>52</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.binom_test(n, N, p=mu_0)</span><br></pre></td></tr></table></figure><pre><code>0.7643534344026666</code></pre><h3 id="이항검정-예3"><a href="#이항검정-예3" class="headerlink" title="이항검정 예3"></a>이항검정 예3</h3><ul><li>동전을 N 번 던졌을 때,<ul><li>N = 10, 유의수준 10% 일 때, 앞면 몇 번 나와야 귀무가설 기각 가능?</li></ul></li><li>2 미만, 8 초과</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">N = <span class="number">10</span></span><br><span class="line">pvalue = []</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(N+<span class="number">1</span>):</span><br><span class="line">    pvalue.append(sp.stats.binom_test(n, N, p=<span class="number">0.5</span>))</span><br><span class="line">plt.plot(np.arange(N+<span class="number">1</span>), pvalue)</span><br><span class="line">plt.axhline(<span class="number">0.1</span>, color=<span class="string">'r'</span>)</span><br><span class="line">plt.xlabel(<span class="string">"The number of occurence: Head"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"p-value"</span>)</span><br><span class="line">plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/test_basic_files/test_basic_8_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pvalue = pd.Series(pvalue, index=np.arange(N+<span class="number">1</span>))</span><br><span class="line">criteria = pvalue &lt;= <span class="number">0.1</span></span><br><span class="line">accept = pvalue[criteria]</span><br><span class="line">plt.fill_between(pvalue.index, pvalue, color=<span class="string">'blue'</span>, alpha=<span class="number">0.1</span>)</span><br><span class="line">plt.fill_between(accept.index[:<span class="number">2</span>], accept[:<span class="number">2</span>], color=<span class="string">'blue'</span>)</span><br><span class="line">plt.fill_between(accept.index[<span class="number">2</span>:], accept[<span class="number">2</span>:], color=<span class="string">'blue'</span>)</span><br><span class="line">plt.axvline(x=<span class="number">1</span>, linestyle= <span class="string">'--'</span>, color=<span class="string">'k'</span>)</span><br><span class="line">plt.axvline(x=<span class="number">9</span>, linestyle= <span class="string">'--'</span>, color=<span class="string">'k'</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/test_basic_files/test_basic_9_0.png" alt=""></p><h3 id="이항검정-예4"><a href="#이항검정-예4" class="headerlink" title="이항검정 예4"></a>이항검정 예4</h3><ul><li>동전을 N 번 던졌을 때,<ul><li>N = 1000, 유의수준 10% 일 때, 앞면 몇 번 나와야 귀무가설 기각 가능?</li></ul></li><li>475 이하, 525 이상</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">N = <span class="number">1000</span></span><br><span class="line">pvalue = []</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(N+<span class="number">1</span>):</span><br><span class="line">    pvalue.append(sp.stats.binom_test(n, N, p=<span class="number">0.5</span>))</span><br><span class="line">plt.plot(np.arange(N+<span class="number">1</span>), pvalue)</span><br><span class="line">plt.axhline(<span class="number">0.1</span>, color=<span class="string">'r'</span>)</span><br><span class="line">plt.xlabel(<span class="string">"The number of occurence: Head"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"p-value"</span>)</span><br><span class="line">plt.xlim(<span class="number">400</span>, <span class="number">600</span>)</span><br><span class="line">plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/test_basic_files/test_basic_11_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pvalue = pd.Series(pvalue, index=np.arange(N+<span class="number">1</span>))</span><br><span class="line">criteria = pvalue &gt; <span class="number">0.1</span></span><br><span class="line">accept = pvalue[criteria]</span><br><span class="line">plt.fill_between(pvalue.index, pvalue, color=<span class="string">'blue'</span>, alpha=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">start = accept.index[<span class="number">0</span>]</span><br><span class="line">end = accept.index[<span class="number">-1</span>]</span><br><span class="line">plt.fill_between(range(N)[:start], pvalue[:start], <span class="number">0</span>, color=<span class="string">'blue'</span>)</span><br><span class="line">plt.fill_between(range(N+<span class="number">1</span>)[end:], pvalue[end:], <span class="number">0</span>, color=<span class="string">'blue'</span>)</span><br><span class="line">plt.axvline(x=start, linestyle= <span class="string">'--'</span>, color=<span class="string">'k'</span>)</span><br><span class="line">plt.axvline(x=end, linestyle= <span class="string">'--'</span>, color=<span class="string">'k'</span>)</span><br><span class="line">plt.xlim(<span class="number">400</span>, <span class="number">600</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/test_basic_files/test_basic_12_0.png" alt=""></p><h3 id="이항검정-예5"><a href="#이항검정-예5" class="headerlink" title="이항검정 예5"></a>이항검정 예5</h3><ul><li>찬반 조사: 70%가 찬성</li><li>국민(모집단)의 2/3이 넘게 찬성한다는 결론을 유의 수준 1%에서 판단하려면 응답자수 몇<br>명 이상?<ul><li>우측 유의 확률</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pvalue = []</span><br><span class="line">N = <span class="number">1160</span></span><br><span class="line">range_ = range(<span class="number">1100</span>, N+<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range_:</span><br><span class="line">    p = sp.stats.binom_test(<span class="number">0.7</span> * n, n, p=<span class="number">2</span>/<span class="number">3</span>, alternative=<span class="string">'greater'</span>)</span><br><span class="line">    pvalue.append(p)</span><br><span class="line"></span><br><span class="line">n = <span class="number">1148</span></span><br><span class="line">n_p = sp.stats.binom_test(<span class="number">0.7</span> * n, n, p=<span class="number">2</span>/<span class="number">3</span>, alternative=<span class="string">'greater'</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(range_, pvalue)</span><br><span class="line">plt.axhline(y=<span class="number">0.01</span>, linestyle=<span class="string">'--'</span>, color=<span class="string">'k'</span>)</span><br><span class="line">plt.scatter(n, n_p, s=<span class="number">90</span>)</span><br><span class="line">plt.ylabel(<span class="string">'p-value'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/test_basic_files/test_basic_14_0.png" alt="png"></p><hr><h2 id="2-카이-제곱-검정-1-카테고리분포-모수-가설-조사"><a href="#2-카이-제곱-검정-1-카테고리분포-모수-가설-조사" class="headerlink" title="2. 카이 제곱 검정(1): 카테고리분포 모수 가설 조사"></a>2. 카이 제곱 검정(1): 카테고리분포 모수 가설 조사</h2><h3 id="goodness-of-fit-test"><a href="#goodness-of-fit-test" class="headerlink" title="goodness of fit test"></a>goodness of fit test</h3><ul><li>모든 카테고리 나올 확률 공정한가?</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4면체 10번 던졌을 때, 각 면이 나온 횟수</span></span><br><span class="line">N = <span class="number">10</span></span><br><span class="line">K = <span class="number">4</span></span><br><span class="line">mu_0 = np.ones(K)/K</span><br><span class="line"></span><br><span class="line">x = np.random.choice(K, N, p)</span><br><span class="line">n = np.bincount(x, minlength=K)</span><br><span class="line">n</span><br></pre></td></tr></table></figure><pre><code>array([3, 1, 3, 3])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">obs = np.array([<span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">exp = np.array([<span class="number">0.25</span>*<span class="number">3</span>, <span class="number">0.25</span>*<span class="number">3</span>, <span class="number">0.25</span>*<span class="number">3</span>, <span class="number">0.25</span>*<span class="number">3</span>])</span><br><span class="line">sp.stats.chisquare(obs, exp)</span><br></pre></td></tr></table></figure><pre><code>Power_divergenceResult(statistic=9.0, pvalue=0.02929088653488826)</code></pre><ul><li>모수가 등분이 아닐 때</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">N = <span class="number">100</span></span><br><span class="line">K = <span class="number">4</span></span><br><span class="line">mu_0 = np.array([<span class="number">0.35</span>, <span class="number">0.30</span>, <span class="number">0.20</span>, <span class="number">0.15</span>])</span><br><span class="line">x = np.random.choice(K, N, p=mu_0)</span><br><span class="line">n = np.bincount(x, minlength=K)</span><br><span class="line">n</span><br></pre></td></tr></table></figure><pre><code>array([37, 33, 15, 15])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.chisquare(n, mu_0*N)</span><br></pre></td></tr></table></figure><pre><code>Power_divergenceResult(statistic=1.6642857142857141, pvalue=0.6449028660305953)</code></pre><h3 id="카이-제곱-검정-1-예1"><a href="#카이-제곱-검정-1-예1" class="headerlink" title="카이 제곱 검정(1) 예1"></a>카이 제곱 검정(1) 예1</h3><ul><li>4 면체 주사위 3번 던졌을 때,</li><li>3번 모두 1이 나왔다면 주사위는 공정한가?</li><li>유의수준 3%: 기각, 공정하지 않음</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.chisquare(np.array([<span class="number">3</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><pre><code>Power_divergenceResult(statistic=9.0, pvalue=0.02929088653488826)</code></pre><hr><h2 id="3-카이-제곱-검정-2-범주형-확률변수-간-독립여부"><a href="#3-카이-제곱-검정-2-범주형-확률변수-간-독립여부" class="headerlink" title="3. 카이 제곱 검정(2): 범주형 확률변수 간 독립여부"></a>3. 카이 제곱 검정(2): 범주형 확률변수 간 독립여부</h2><h3 id="귀무가설-독립"><a href="#귀무가설-독립" class="headerlink" title="귀무가설: 독립"></a>귀무가설: 독립</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">obs = np.array([[<span class="number">5</span>, <span class="number">15</span>],</span><br><span class="line">                [<span class="number">10</span>, <span class="number">20</span>]])</span><br><span class="line">sp.stats.chi2_contingency(obs,)</span><br></pre></td></tr></table></figure><pre><code>(0.0992063492063492, 0.7527841326498471, 1, array([[ 6., 14.],        [ 9., 21.]]))</code></pre><h3 id="카이-제곱-검정-2-예1"><a href="#카이-제곱-검정-2-예1" class="headerlink" title="카이 제곱 검정(2) 예1"></a>카이 제곱 검정(2) 예1</h3><ul><li>수업 들은 학생 학점 분포: 4, 16, 20</li><li>안들은 학생 분포: 23, 18, 19</li><li>귀무가설 기각: 독립X</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">obs = np.array([[<span class="number">4</span>, <span class="number">16</span>, <span class="number">20</span>],</span><br><span class="line">               [<span class="number">23</span>, <span class="number">18</span>, <span class="number">19</span>]])</span><br><span class="line">sp.stats.chi2_contingency(obs)</span><br></pre></td></tr></table></figure><pre><code>(9.910060890453046, 0.00704786570249751, 2, array([[10.8, 13.6, 15.6],        [16.2, 20.4, 23.4]]))</code></pre><hr><h2 id="4-단일-표본-t-검정-One-sample-t-test"><a href="#4-단일-표본-t-검정-One-sample-t-test" class="headerlink" title="4. 단일 표본 t-검정 One-sample t-test"></a>4. 단일 표본 t-검정 One-sample t-test</h2><h3 id="정규분포-모수-기댓값이-mu인지-검사"><a href="#정규분포-모수-기댓값이-mu인지-검사" class="headerlink" title="정규분포 모수 기댓값이 mu인지 검사"></a>정규분포 모수 기댓값이 mu인지 검사</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mu = 0</span></span><br><span class="line">N = <span class="number">10</span>; mu_0 = <span class="number">0</span></span><br><span class="line">x = sp.stats.norm(mu_0).rvs(N)</span><br><span class="line">sns.distplot(x, kde=<span class="keyword">False</span>, fit=sp.stats.norm)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/test_basic_files/test_basic_31_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 유의수준 3%에서 귀무가설 성립</span></span><br><span class="line">sp.stats.ttest_1samp(x, popmean=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><pre><code>Ttest_1sampResult(statistic=2.3525596749498336, pvalue=0.043123869250344005)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mu_0 = 5</span></span><br><span class="line">N = <span class="number">100</span>; mu_0 = <span class="number">5</span></span><br><span class="line">x = sp.stats.norm(mu_0).rvs(N)</span><br><span class="line">sns.distplot(x, kde=<span class="keyword">False</span>, fit=sp.stats.norm)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/test_basic_files/test_basic_33_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 유의수준 3%에서 귀무가설 성립</span></span><br><span class="line">sp.stats.ttest_1samp(x, popmean=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>Ttest_1sampResult(statistic=1.0707330751268116, pvalue=0.286892939529473)</code></pre><hr><h2 id="5-독립-표본-t-검정-Independent-two-sample-t-test"><a href="#5-독립-표본-t-검정-Independent-two-sample-t-test" class="headerlink" title="5. 독립 표본 t-검정 Independent-two-sample t-test"></a>5. 독립 표본 t-검정 Independent-two-sample t-test</h2><h3 id="귀무가설-기댓값-동일"><a href="#귀무가설-기댓값-동일" class="headerlink" title="귀무가설: 기댓값 동일"></a>귀무가설: 기댓값 동일</h3><ul><li>두 개의 독립적인 정규분포에서 나온 N, M 개의 데이터 셋을 사용</li><li>두 정규 분포의 기댓값이 동일한지 검사</li><li>등분산 여부 모르면 <code>equal_var=False</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 샘플수 10</span></span><br><span class="line">N_1 = <span class="number">10</span>; mu_1 = <span class="number">0</span>; sigma_1 = <span class="number">1</span></span><br><span class="line">N_2 = <span class="number">10</span>; mu_2 = <span class="number">0.5</span>; sigma_2 = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">x1 = sp.stats.norm(mu_1, sigma_1).rvs(N_1)</span><br><span class="line">x2 = sp.stats.norm(mu_2, sigma_2).rvs(N_2)</span><br><span class="line"></span><br><span class="line">sns.distplot(x1, kde=<span class="keyword">False</span>, fit=sp.stats.norm)</span><br><span class="line">sns.distplot(x2, kde=<span class="keyword">False</span>, fit=sp.stats.norm)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/test_basic_files/test_basic_37_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.mean(x1), np.mean(x2)</span><br></pre></td></tr></table></figure><pre><code>(-0.633908976759515, 0.44641580049465757)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.ttest_ind(x1, x2, equal_var=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><pre><code>Ttest_indResult(statistic=-2.190476852611547, pvalue=0.04261703836609451)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">N_1 = <span class="number">100</span>; mu_1 = <span class="number">0</span>; sigma_1 = <span class="number">1</span></span><br><span class="line">N_2 = <span class="number">100</span>; mu_2 = <span class="number">0.5</span>; sigma_2 = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">x1 = sp.stats.norm(mu_1, sigma_1).rvs(N_1)</span><br><span class="line">x2 = sp.stats.norm(mu_2, sigma_2).rvs(N_2)</span><br><span class="line"></span><br><span class="line">sns.distplot(x1, kde=<span class="keyword">False</span>, fit=sp.stats.norm)</span><br><span class="line">sns.distplot(x2, kde=<span class="keyword">False</span>, fit=sp.stats.norm)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/test_basic_files/test_basic_40_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.mean(x1), np.mean(x2)</span><br></pre></td></tr></table></figure><pre><code>(-0.11491908003495595, 0.3982785742299076)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.ttest_ind(x1, x2, equal_var=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><pre><code>Ttest_indResult(statistic=-3.6540766320275124, pvalue=0.000330869218712974)</code></pre><h3 id="독립-표본-t-검정-예1"><a href="#독립-표본-t-검정-예1" class="headerlink" title="독립 표본 t-검정 예1"></a>독립 표본 t-검정 예1</h3><ul><li>두 집단의 모수 기댓값 같음</li><li>실력 차이 없음</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x1 = np.array([<span class="number">80</span>, <span class="number">75</span>, <span class="number">85</span>, <span class="number">50</span>, <span class="number">60</span>, <span class="number">75</span>, <span class="number">45</span>, <span class="number">70</span>, <span class="number">90</span>, <span class="number">95</span>, <span class="number">85</span>, <span class="number">80</span>])</span><br><span class="line">x2 = np.array([<span class="number">80</span>, <span class="number">85</span>, <span class="number">70</span>, <span class="number">80</span>, <span class="number">35</span>, <span class="number">55</span>, <span class="number">80</span>])</span><br><span class="line">sp.stats.ttest_ind(x1, x2, equal_var=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><pre><code>Ttest_indResult(statistic=0.596519621317167, pvalue=0.562790180213766)</code></pre><hr><h2 id="6-등분산-검정-Equal-variance-test-두-샘플의-분산-모수가-같은지-확인"><a href="#6-등분산-검정-Equal-variance-test-두-샘플의-분산-모수가-같은지-확인" class="headerlink" title="6. 등분산 검정 Equal-variance test: 두 샘플의 분산 모수가 같은지 확인"></a>6. 등분산 검정 Equal-variance test: 두 샘플의 분산 모수가 같은지 확인</h2><h3 id="귀무가설-등분산"><a href="#귀무가설-등분산" class="headerlink" title="귀무가설: 등분산"></a>귀무가설: 등분산</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">N1 = <span class="number">100</span>; N2 = <span class="number">100</span>;</span><br><span class="line">sigma_1 = <span class="number">1</span>; sigma_2 = <span class="number">1.2</span></span><br><span class="line"></span><br><span class="line">x1 = sp.stats.norm(<span class="number">0</span>, sigma_1).rvs(N1)</span><br><span class="line">x2 = sp.stats.norm(<span class="number">0</span>, sigma_2).rvs(N2)</span><br><span class="line"></span><br><span class="line">sns.distplot(x1, kde=<span class="keyword">False</span>, fit=sp.stats.norm)</span><br><span class="line">sns.distplot(x2, kde=<span class="keyword">False</span>, fit=sp.stats.norm)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/test_basic_files/test_basic_47_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x1.std(), x2.std()</span><br></pre></td></tr></table></figure><pre><code>(0.830350164236609, 1.2378678279504765)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># bartlett</span></span><br><span class="line">sp.stats.bartlett(x1, x2)</span><br></pre></td></tr></table></figure><pre><code>BartlettResult(statistic=15.304737977781903, pvalue=9.148676067337196e-05)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># flinger</span></span><br><span class="line">sp.stats.fligner(x1, x2)</span><br></pre></td></tr></table></figure><pre><code>FlignerResult(statistic=4.1657669000613815, pvalue=0.04124873547614382)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># levene</span></span><br><span class="line">sp.stats.levene(x1, x2)</span><br></pre></td></tr></table></figure><pre><code>LeveneResult(statistic=5.820286459312568, pvalue=0.01675411819434604)</code></pre><h2 id="7-정규성-검정"><a href="#7-정규성-검정" class="headerlink" title="7. 정규성 검정"></a>7. 정규성 검정</h2><h3 id="가우시안-정규분포-여부-확인"><a href="#가우시안-정규분포-여부-확인" class="headerlink" title="가우시안 정규분포 여부 확인"></a>가우시안 정규분포 여부 확인</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = sp.stats.norm(<span class="number">0</span>, <span class="number">1</span>).rvs(<span class="number">10</span>)</span><br><span class="line">sp.stats.shapiro(x)</span><br></pre></td></tr></table></figure><pre><code>(0.9501180052757263, 0.6698970198631287)</code></pre><h2 id="8-Kolmogorov-Smirove-검정"><a href="#8-Kolmogorov-Smirove-검정" class="headerlink" title="8. Kolmogorov-Smirove 검정"></a>8. Kolmogorov-Smirove 검정</h2><h3 id="두-표본이-같은-분포를-따르는지-확인"><a href="#두-표본이-같은-분포를-따르는지-확인" class="headerlink" title="두 표본이 같은 분포를 따르는지 확인"></a>두 표본이 같은 분포를 따르는지 확인</h3><h3 id="귀무가설-같은-분포"><a href="#귀무가설-같은-분포" class="headerlink" title="귀무가설: 같은 분포"></a>귀무가설: 같은 분포</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">N = <span class="number">50</span>; N2 = <span class="number">100</span>;</span><br><span class="line">x1 = sp.stats.norm(<span class="number">0</span>, <span class="number">1</span>).rvs(N)</span><br><span class="line">x2 = sp.stats.norm(<span class="number">0.5</span>, <span class="number">1.5</span>).rvs(N2)</span><br><span class="line"></span><br><span class="line">sns.distplot(x1)</span><br><span class="line">sns.distplot(x2)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/test_basic_files/test_basic_55_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.ks_2samp(x1, x2)</span><br></pre></td></tr></table></figure><pre><code>Ks_2sampResult(statistic=0.27, pvalue=0.012231085367552404)</code></pre>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> Stat_test </tag>
            
            <tag> Chi_Squared_test </tag>
            
            <tag> t-test </tag>
            
            <tag> Binomial_test </tag>
            
            <tag> Equal_Var_test </tag>
            
            <tag> Normality_test </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[AWS_4] AWS EMR</title>
      <link href="/2019/03/20/asw-9/"/>
      <url>/2019/03/20/asw-9/</url>
      
        <content type="html"><![CDATA[<h4 id="EMR-개괄"><a href="#EMR-개괄" class="headerlink" title="EMR 개괄"></a>EMR 개괄</h4><a id="more"></a><ul><li><p>1) EMR: Amazon Elastic MapReduce, Apach Hadoop/Spark 등 대용량 데이터 Framework 실행을 간소화하는 관리형 Cluster Platform <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-mgmt.pdf" target="_blank" rel="noopener">(그림: aws_doc.pdf p.106)</a><br><img src="/img/aws_emr.png" width="300"></p></li><li><p>2) EMR로 Spark 운용</p></li><li>3) EMR 구성: Master Node,  Core and Task<ul><li>Master Node, Core 쌍이 반드시 있어야.</li><li>Worker Node: Core and Task</li><li>Core: 자체 HDFS, Temp folder로 활용. multiple Core을 resize할 때는 HDFS의 replica를 고려(저장할 용량없으면 terminate안됨)</li><li>Task Node: compting 위함. eg. 1000개 instance 생성해서 computing 가능</li></ul></li><li>4) <strong>복수의 EMR cluster를 동일한 S3(HDFS처럼 활용) 데이터 참조하게 할 수 있음.</strong> (vs Hadoop은 아님)<ul><li>Bucket에 전처리된/raw data두고 각 EMR에서 활용 가능</li><li>작업중 EMR terminate시 해당 Core의 HDFS만 사라짐. <strong>즉 S3의 Data는 영향받지 않음</strong></li></ul></li></ul><h4 id="EMR-실행"><a href="#EMR-실행" class="headerlink" title="EMR 실행"></a>EMR 실행</h4><ul><li>1) Software Config<ul><li>Hadoop</li><li>Ganglia: Spark 리소스를 모니터링. 각 서버 상황 실시간 체크.</li><li>Zeppline</li><li>Livy: remote로 spark에 명령 전달</li><li>Flink: real분석. 키네시스 내부에 flink있음</li><li>zoo keeprer: 클러스터 간 관리</li><li>oozie: ETL job은 선행 후행작업이 있으므로 이걸 관리(Airflow 사용추천)</li></ul></li><li>2) AWS Glue Data Catalog(아래 참조): 사용</li><li>3) Instance Type<ul><li>Maste &amp; Corer:  r3(메모리 집중). 안정성 위해 On-demand.</li></ul></li><li>4) keypair</li><li>5) Security Group: My IP 추가</li><li>6) Hardware tab에서 Scale-out/in 가능</li></ul><h4 id="EMR-활용"><a href="#EMR-활용" class="headerlink" title="EMR 활용"></a>EMR 활용</h4><ul><li>1) Zeppline Notebook: Browser에서 Python, Scala, R 등의 언어로 분석코드 표현. 실행결과 바로 확인. 데이터 visualization 가능<ul><li>Spark SQL을 통해 CSV/Json/RDBMS/ParquetData 등 하나의 DataFrame으로 만들 수 있음.(데이터 형식에 구애받지 않고 R/W 모두 가능)</li></ul></li><li>2) AWS Glue <a href=" https://docs.aws.amazon.com/athena/latest/ug/glue-athena.html" target="_blank" rel="noopener">(link)</a>: ETL Workflow를 정의하고 관리 가능<br><img src="/img/aws_glue.png"><ul><li>Data catalog: 영구적 Metadata Store(The AWS Glue Data Catalog is an index to the location, schema, and runtime metrics of your data)</li><li>Crawler 사용하여 Table구성 및 Sequel사용환경 구성</li><li>활용 <a href="https://aws.amazon.com/glue/" target="_blank" rel="noopener">(link)</a>: 정제되지 않은 데이터 빠르게 query 사용 가능하게 정제<ul><li>Queries Against an Amazon S3 Data Lake: S3 data 를 분석 가능 상태로 변환</li><li>Analyze Log Data in the Data Warehouse: Semi-structured된 데이터로 schema 생성해줌</li></ul></li></ul></li></ul><h4 id="cf-컴퓨터-cluster란-link"><a href="#cf-컴퓨터-cluster란-link" class="headerlink" title="cf. 컴퓨터 cluster란? (link)"></a>cf. 컴퓨터 cluster란? <a href="https://ko.wikipedia.org/wiki/%EC%BB%B4%ED%93%A8%ED%84%B0_%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0" target="_blank" rel="noopener">(link)</a></h4><p><img src="/img/cluster.png" width="500"></p><ul><li>1) 여러 대의 컴퓨터를 연결하여 하나의 시스템처럼 동작하는 컴퓨터들의 집합 (아래: Master/Slave 구성)</li><li>2) cluster 구성요소<ul><li>클러스터 노드: processing resource 제공</li><li>클러스터 관리자: 노드를 서로 연결하여 단일 시스템처럼 보이게 만드는 로직 제공</li></ul></li></ul><h4 id="cf-AWS-Glue-상세-link"><a href="#cf-AWS-Glue-상세-link" class="headerlink" title="cf. AWS Glue 상세 (link)"></a>cf. AWS Glue 상세 <a href="https://docs.aws.amazon.com/glue/latest/dg/components-key-concepts.html" target="_blank" rel="noopener">(link)</a></h4><ul><li><strong>AWS Glue는 Service 자체를 뜻하는 듯. Console로 필요 API들을 Orchestrate하는 듯.</strong> 아래는 AWS Glue environment.(AWS Glue is a fully managed ETL (extract, transform, and load) service that makes it simple and cost-effective to categorize your data, clean it, enrich it, and move it reliably between various data stores. AWS Glue consists of a central metadata repository known as the AWS Glue Data Catalog, an ETL engine that automatically generates Python or Scala code, and a flexible scheduler that handles dependency resolution, job monitoring, and retries. AWS Glue is serverless, so there’s no infrastructure to set up or manage.<a href="https://docs.aws.amazon.com/glue/latest/dg/what-is-glue.html" target="_blank" rel="noopener">link</a>)<br><img src="/img/aws_glue_con.png" width="500"></li><li>1) <strong>생성된 테이블과 데이터 베이스는 모두 AWS Glue의 obj. Data catalog는 Metadata를 지닐 뿐, Data자체를 저장하지는 않음.</strong>(Tables and databases in AWS Glue are objects in the AWS Glue Data Catalog. They contain metadata; they don’t contain data from a data store.)</li><li>2) <strong>AWS Glue를 통해 데이터 원본에서 ETL작업 -&gt; 원하는 데이터로 만듦.</strong> (You define jobs in AWS Glue to accomplish the work that’s required to extract, transform, and load (ETL) data from a data source to a data target. You typically perform the following actions:)<ul><li><strong>Crawler가 Data catalog를 채움 with table definition.</strong> (You define a crawler to populate your AWS Glue Data Catalog with metadata table definitions. You point your crawler at a data store, and the crawler creates table definitions in the Data Catalog.)</li><li><strong>Data catalog는 data transform에 사용될 Metadata도 지님.</strong> (In addition to table definitions, the AWS Glue Data Catalog contains other metadata that is required to define ETL jobs. You use this metadata when you define a job to transform your data.</li><li>… and etc</li></ul></li><li>3) <strong>AWS Glue Data Catalog: AWS 계정마다 하나 존재. AWS Glue의 영구적 Metadata store.</strong> (The persistent metadata store in AWS Glue. Each AWS account has one AWS Glue Data Catalog. It contains table definitions, job definitions, and other control information to manage your AWS Glue environment.)</li><li>4) <strong>Crawler: Data store(S3…) 등에 접속하고, classfier을 통해 스키마 결정하고 Data catalog에 Metadata 생성</strong> (A program that connects to a data store (source or target), progresses through a prioritized list of classifiers to determine the schema for your data, and then creates metadata in the AWS Glue Data Catalog.)</li></ul>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> Cluster </tag>
            
            <tag> EMR </tag>
            
            <tag> AWS_glue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Spark_2_보충] Dag, Stages and Task</title>
      <link href="/2019/03/20/spark-dag/"/>
      <url>/2019/03/20/spark-dag/</url>
      
        <content type="html"><![CDATA[<h1 id="Workflow-DAG-Directed-Acyclic-Graph-Stages-and-Task"><a href="#Workflow-DAG-Directed-Acyclic-Graph-Stages-and-Task" class="headerlink" title="Workflow: DAG(Directed Acyclic Graph), Stages and Task"></a>Workflow: DAG(Directed Acyclic Graph), Stages and Task</h1><a id="more"></a><h4 id="Overview-link"><a href="#Overview-link" class="headerlink" title="Overview (link)"></a>Overview <a href="https://data-flair.training/blogs/how-apache-spark-works/" target="_blank" rel="noopener">(link)</a></h4><p><img src="/img/exe_flow.jpg" width="500"></p><h4 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h4><ol><li>Action되는 순간 DAG 생성 및 DAG scheduler로 전송</li><li>DAG Scheduler는 Operations(Map, reduce 등등)를 stages로 나눔 <a href="https://medium.com/@goyalsaurabh66/spark-basics-rdds-stages-tasks-and-dag-8da0f52f0454" target="_blank" rel="noopener">(link)</a><br><img src="/img/dag_stage.png" width="300"><ul><li>2.1) stage는 transformation에 근거해 만들어짐</li><li>2.2) 각 <strong>stage</strong>는 Task로 구성됨(stage: a collection of tasks)<br><img src="/img/stage_rdd.png" width="300"></li><li>2.3) <strong>Task</strong>는 partion에서 행해지는 작업의 단위(Task: a unit of work on a partition)</li><li>2.4) Task의 수는 $\sum(stage \times \text{Partitions in the stage} )$, 즉 task갯수는 partion갯수/per stage eg. following stage1 consists of 4 set of tasks(=4 partions)<br><img src="/img/stage_rdd2.png" width="300"><ul><li>모든 RDD는 defined number of partitions를 가짐</li><li>partitions의 갯수는 input format에 따라 쪼개진 수량 (<strong>partitions</strong>: subset of RDD, <code>rdd2=rdd1.repartition(1000) # resulting in rdd2 having 1000 partitions</code>) <a href="https://www.slideshare.net/datamantra/anatomy-of-rdd" target="_blank" rel="noopener">(link)</a><br><img src="/img/rdd_part.jpg" width="300"></li></ul></li><li>2.5) DAG Scheduler의 result는 a set of stages</li></ul></li><li>a set of stages를 Task Scheduler에게 전송</li><li>Task Scheduler는 Cluster Manager에게 task전송</li><li>Worker Node의 Executor가 task 실행</li><li>결과 Driver Program에 전달</li></ol><hr><p>reference</p><ul><li><a href="https://stackoverflow.com/questions/37528047/how-are-stages-split-into-tasks-in-spark" target="_blank" rel="noopener">https://stackoverflow.com/questions/37528047/how-are-stages-split-into-tasks-in-spark</a></li><li><a href="https://stackoverflow.com/questions/25836316/how-dag-works-under-the-covers-in-rdd" target="_blank" rel="noopener">https://stackoverflow.com/questions/25836316/how-dag-works-under-the-covers-in-rdd</a></li><li><a href="https://data-flair.training/blogs/how-apache-spark-works/" target="_blank" rel="noopener">https://data-flair.training/blogs/how-apache-spark-works/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> DAG </tag>
            
            <tag> Spark_Task </tag>
            
            <tag> Spark_Stage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Spark_3] Spark SQL basic</title>
      <link href="/2019/03/17/spark-sql-basic/"/>
      <url>/2019/03/17/spark-sql-basic/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark-SQL-basic"><a href="#Spark-SQL-basic" class="headerlink" title="Spark_SQL basic"></a>Spark_SQL basic</h1><a id="more"></a><h4 id="Spark-SQL-link"><a href="#Spark-SQL-link" class="headerlink" title="Spark SQL (link)"></a>Spark SQL <a href="https://spark.apache.org/docs/latest/sql-programming-guide.html" target="_blank" rel="noopener">(link)</a></h4><ul><li>RDD vs DataSet/DataFrame: 두 개 다 사용하지만 이제 Dataset사용이 많아짐<ul><li>DataSet: a distributed collection of data</li><li>DataFrame: a DataSet organized into named columns  </li><li>RDD를 DS, DF 변환가능</li><li>Python은 DataSet 개념없음</li></ul></li></ul><h4 id="SparkContext-vs-SparkSession"><a href="#SparkContext-vs-SparkSession" class="headerlink" title="SparkContext vs SparkSession"></a>SparkContext vs SparkSession</h4><ul><li>SparkContext: Old entry point of Spark. RDD 조작</li><li>SparkSession: New entry point of Spark. 내부 SparkContext 있음. (it is essentially combination of SQLContext, HiveContext and future StreamingContext)</li><li>SparkContext: Spark Application이 Cluster Manager에 접근</li><li>SparkSession: Spark SQL 접속 포인트 (the entry point to Spark SQL)</li></ul><h4 id="Spark-library-link"><a href="#Spark-library-link" class="headerlink" title="Spark library (link)"></a>Spark library <a href="https://softwareengineering.stackexchange.com/questions/54451/library-vs-framework-vs-api" target="_blank" rel="noopener">(link)</a></h4><ul><li>Spark SQL / Streaming / MLlib / GraphX</li><li>library?<ul><li>library: 필요 기능을 Class, Function로 만들어 둔 것. collection of various packages. eg. <code>reqeusts</code></li><li>Framework: 특정 기능 구현 위해 라이브러리 모아둔 것. collection of libraries. eg. <code>Django</code></li><li>API: 다른 프로그램과 직접적 연결없이 interaction 위한 인터페이스 eg. <code>pyspark</code><ul><li>An API may be referred to as an Interface. <strong>API exist at many levels including system, library, framework, program, and application.</strong> APIs should be defined before the code implementing them is implemented.</li></ul></li></ul></li></ul><hr><h3 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h3><h4 id="Spark-Cluster-Manager"><a href="#Spark-Cluster-Manager" class="headerlink" title="Spark Cluster Manager"></a>Spark Cluster Manager</h4><ul><li>Standalone Deplot Mode</li><li>Apache Mesos</li><li>Hadoop YARN</li><li>Kubernetes</li></ul>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DataFrame </tag>
            
            <tag> SparkSQL </tag>
            
            <tag> SparkSession </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] Install_pyspark</title>
      <link href="/2019/03/16/install-pyspark/"/>
      <url>/2019/03/16/install-pyspark/</url>
      
        <content type="html"><![CDATA[<h1 id="How-to-install-Pyspark"><a href="#How-to-install-Pyspark" class="headerlink" title="How to install Pyspark"></a>How to install Pyspark</h1><ul><li>prerequisite: python3<a id="more"></a><h1 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># install java</span><br><span class="line">sudo add-apt-repository ppa:webupd8team/java</span><br><span class="line">sudo apt-get install oracle-java8-installer</span><br><span class="line">sudo apt-get install oracle-java8-set-default</span><br><span class="line"></span><br><span class="line"># set path and variable</span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/java-8-oracle</span><br><span class="line">export JRE_HOME=/usr/lib/jvm/java-8-oracle/jre</span><br><span class="line"></span><br><span class="line"># install scala</span><br><span class="line">sudo apt-get install scala</span><br><span class="line"></span><br><span class="line"># install python-java integration</span><br><span class="line">pip3 install py4j</span><br><span class="line"></span><br><span class="line"># download and untagz</span><br><span class="line">sudo tar -zxvf spark-2.3.1-bin-hadoop2.7.tgz # use latest one</span><br><span class="line"></span><br><span class="line"># edit path and variables</span><br><span class="line">$vim .bashrc</span><br><span class="line"></span><br><span class="line">export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH</span><br><span class="line">export PYSPARK_DRIVER_PYTHON=jupyter</span><br><span class="line">export PYSPARK_DRIVER_PYTHON_OPTS=&quot;notebook&quot;</span><br><span class="line">export PYSPARK_PYTHON=python3</span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/java-8-oracle/jre</span><br><span class="line">export SPARK_HOME=/home/henry/apache_spark/spark-2.4.0-bin-hadoop2.7</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin:$SPARK_HOME/bin</span><br><span class="line"># shift + : -&gt; wq -&gt; enter</span><br><span class="line"># run pyspark</span><br><span class="line">pyspark</span><br></pre></td></tr></table></figure></li></ul><p>reference</p><ul><li><a href="https://medium.freecodecamp.org/how-to-set-up-pyspark-for-your-jupyter-notebook-7399dd3cb389" target="_blank" rel="noopener">https://medium.freecodecamp.org/how-to-set-up-pyspark-for-your-jupyter-notebook-7399dd3cb389</a></li><li><a href="https://medium.com/tinghaochen/how-to-install-pyspark-locally-94501eefe421" target="_blank" rel="noopener">https://medium.com/tinghaochen/how-to-install-pyspark-locally-94501eefe421</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Pyspark_install </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Spark_2_보충] HDFS Basic</title>
      <link href="/2019/03/15/hdfs-recap/"/>
      <url>/2019/03/15/hdfs-recap/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop-HDFS-Architecture"><a href="#Hadoop-HDFS-Architecture" class="headerlink" title="Hadoop HDFS Architecture"></a>Hadoop HDFS Architecture</h1><a id="more"></a><p>하기는 <a href="https://www.edureka.co/blog/apache-hadoop-hdfs-architecture/" target="_blank" rel="noopener">링크</a> 자료를 토대로 HDFS 개념을 정리한 내용입니다.<br><br> 모든 그림은 해당 <a href="https://www.edureka.co/blog/apache-hadoop-hdfs-architecture/" target="_blank" rel="noopener">링크</a>에서 발췌했습니다.<br></p><hr><h2 id="0-요약"><a href="#0-요약" class="headerlink" title="0. 요약"></a>0. 요약</h2><p>1) 구성</p><ul><li>NameNode</li><li>DataNode</li><li>Secondary NameNode</li><li>Block</li></ul><p>2) Operation/Process</p><ul><li>Replication</li><li>HDRF Write &amp; Read</li><li>Data Streaming</li></ul><h3 id="1-기본"><a href="#1-기본" class="headerlink" title="1. 기본"></a>1. 기본</h3><ul><li>HDFS는 기본적으로 Data를 쪼개서 관리(block-structured file system)</li><li>Write Once! - Read Many!(이미 Write하면 바꿀 수 없음. New data를 또 Write함)</li></ul><h3 id="2-구성"><a href="#2-구성" class="headerlink" title="2. 구성"></a>2. 구성</h3><p><img src="/img/hdfs_archi.png" width="500px"></p><ul><li>1) <strong>NameNode</strong><ul><li>metadata(block 저장 위치, 파일 사이즈, 권한 등등) 들고 있다가 Client 요청이 들어오면 해당 DataNode의 IP를 알려줌</li><li>DataNode와 주기적으로 정보를 교환하여, Block 위치, 정보 등을 계속 업데이트</li><li>metadata는 FsImage(namespace포함한 데이터 모든  정보) / EditLogs(DataNode에서 발생한 데이터 변환 내역)으로 이루어짐</li><li>namespace는 데이터를 특정할(identify) 수 있게 하는 역할</li></ul></li><li>2) <strong>Secondary NameNode</strong><ul><li>Check Point의 역할</li><li>NameNode의 RAM을 계속 백업</li><li>FsImage를 EditLogs에 결합하여 저장하며, NameNode는 이 FsImage를 copy</li></ul></li><li>3) <strong>DataNode</strong><ul><li>고장나면 갈아치울 수 있는 값싼 하드웨어로 이해</li><li>실제 block의 read/write 요청에 대응</li><li>대략 3초 주기로 block 상황을 NameNode에 보고</li></ul></li><li>4) <strong>Block</strong><ul><li>작은 location</li><li>HDFS가 아닌 일반적인 경우에는 Collection of Blcoks로 데이터를 저장</li><li>HDFS는 각 Block으로 쪼개서 저장</li><li>기본 128MB/Block</li></ul></li></ul><h3 id="3-Operation-Process"><a href="#3-Operation-Process" class="headerlink" title="3. Operation / Process"></a>3. Operation / Process</h3><ul><li>1) <strong>Replicate</strong>: HDFS는 각 Block을 3벌씩 저장; DataNode와 Rack 고려<br><img src="/img/hdfs_blocks.png" width="500px"><ul><li>Data = BlockA + BlockB라면 BlockA<em>3, BlockB</em>3 개를 서로 다른 6개 DataNode에 저장</li><li>각 6개 Block을 replication factor라고 부름</li><li>NameNode는 replication factor의 갯수와 저장장소(DataNode 겹치지 않도록) 관리(del or add)</li><li>Rack: 서버 담는 캐비닛.<ul><li>BlockA의 replication factor 3개는 Rack1, Rack2에 1:2로 나누어 저장.<ul><li>어떤 rack을 고를까요? rack awarness algorithm을 따름</li></ul></li><li>Rack 하나 통째로 날아갈 위험이 있어서 2개로 나눔</li><li>그럼 왜 3개로 안나누는가? 같은 rack에 있으면 속도가 빠름(greater network bandwidth). 3개 다 같은 rack에 두고 싶으나 부득불 1:2로 나눈 것.</li></ul></li></ul></li><li>2) <strong>Write</strong><br><img src="/img/hdfs_write.png" width="500px"><ul><li>Data = BlockA + BLockB Write해보자  </li><li>Client: NameNode에게 저장가능한지 확인 요청</li><li>NameNode: 확인후 허가. DataNodes IP(랜덤하게 DataNode 선택)를 전달.<ul><li>이때 DataNode availability, different DataNode, Rack awareness algorithm을 고려</li><li>BlockA: DataNode1,2,3</li><li>BlockB: DataNode4,5,6</li></ul></li><li>DataNode에 replication factor 작성</li></ul></li><li>3) <strong>Write_details</strong><ul><li>파이프라인 구축</li><li>데이터 흘려보내기streaming &amp; 복사replication</li><li>파이프라인 종료</li><li>상기 과정에서 데이터를 흘려보내는 과정 이해할 필요<ul><li>Client가 각 DataNode에 파이프 라인을 각각 만들고(1번 과정)</li><li>BlockA, B를 첫번째 DataNode(1, 4)에 write</li><li>그럼 DataNode(1, 4)가 그다음 DataNode(2, 5)에 데이터를 흘려보냄</li></ul></li></ul></li><li>4) <strong>Read</strong><br><img src="/img/hdfs_read.png"><ul><li>Client: 원하는 Data(=BlockA + BlockB) 위치(DataNode1, 2)를 NameNode에게 받고</li><li>각 DataNode에서 Parellel하게 Block(BlockA, BlockB)들을 읽어냄</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> Spark </tag>
            
            <tag> HDFS </tag>
            
            <tag> Rack </tag>
            
            <tag> Replica </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Spark_2] Spark Intro_Architecture and Components</title>
      <link href="/2019/03/13/spark3/"/>
      <url>/2019/03/13/spark3/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark-Intro"><a href="#Spark-Intro" class="headerlink" title="Spark Intro"></a>Spark Intro</h1><a id="more"></a><ul><li>reference: <a href="http://datastrophic.io/core-concepts-architecture-and-internals-of-apache-spark/" target="_blank" rel="noopener">Apache Spark: core concepts, architecture and internals</a><h3 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h3></li><li>RDD</li><li>Operation<ul><li>Create RDD</li><li>Action: Count, Collect, Take</li><li>Transformation: Map, Filter</li></ul></li><li>Partition, Dependency</li></ul><h2 id="1-RDD-Resilient-Distributed-Datasets"><a href="#1-RDD-Resilient-Distributed-Datasets" class="headerlink" title="1. RDD (Resilient Distributed Datasets)"></a>1. RDD (Resilient Distributed <strong>Datasets</strong>)</h2><ul><li>Important aspect: <strong>Distributed/ Immutable/ Resilient</strong><ul><li>Distributed: Each RDD is split into multiple pieces(<strong>partitions</strong>) -&gt; partitions are <strong>divided</strong> across the <strong>clusters</strong></li><li>Immutable(read-only): cannot be changed after created -&gt; <strong>remove all the potential problems</strong> due to <strong>updates from multiple threads</strong></li><li>Resilient: in case of any node in the cluster goes down, can <strong>recover</strong> the parts of the RDDs(cuz can be recreated <strong>at any time</strong> &amp; ‘Lineage’) -&gt; make sure <strong>fault-tolerance</strong></li></ul></li><li>Basic concept<ul><li>can contain any types of obj, such as Python, Java, or Scala objects, including user-defined classes</li><li>is <strong>a capsulation</strong> around a very large dataset</li><li>will <strong>automatically distribute</strong> the data contained in RDDs, across your cluster and <strong>parallelize the operaton</strong> your perfom on them</li><li><strong>paralleize applications</strong>(compute-intensive app, app requiring input from data streams, and etc) across clusters</li></ul></li><li>RDD workflow<ul><li><strong>Create initial RDDs</strong> from external data</li><li>Apply <strong>Transformation</strong></li><li>Launch <strong>Actions</strong></li></ul></li></ul><h3 id="How-to-create-a-RDD"><a href="#How-to-create-a-RDD" class="headerlink" title="How to create a RDD"></a>How to create a RDD</h3><ul><li>1) (Not practical to large datasets)Take an <strong>existing collection</strong> and pass it to SparkContext’s <code>parallelize</code> method.</li><li>2) <strong>Load RDDs</strong> from external strage by calling <code>textFile</code> method on SparkContext.<ul><li>External storage: AWS S3, HDFS and etc. (JDBC, Cassandra, Elasticsearch)</li></ul></li></ul><h2 id="2-Spark-Architecture-link"><a href="#2-Spark-Architecture-link" class="headerlink" title="2. Spark Architecture (link)"></a>2. Spark Architecture <a href="http://datastrophic.io/core-concepts-architecture-and-internals-of-apache-spark/" target="_blank" rel="noopener">(link)</a></h2><p><img src="/img/spark_archi.png"></p><ul><li><code>Driver Program</code>(Spark Application) eg. shell<ul><li>Drive application</li><li>Consists of <code>SparkContext</code> and user code</li></ul></li><li><code>SparkContext</code><ul><li>Take the job, break the job in tasks and distribute them to the <code>worker nodes</code></li><li>Represent <strong>connection</strong> to spark <code>Cluster Managers</code> which allocate resourecs across app</li><li><code>Driver Program</code> access Spark app through <code>SparckContext</code> obj</li></ul></li><li><code>Cluster Manager</code><ul><li>not need to be on the same machines with <code>Driver Program</code></li><li>Manage job <strong>within the cluster</strong></li><li>Allocate resource</li></ul></li><li><code>Executor</code><ul><li><strong>Excute</strong> the tasks on the <strong>partitioned RDDs</strong></li><li>Launch at the beginning of the Spark app</li><li><strong>Return back</strong> result to <code>SparkContext</code></li><li>Interact with storage system</li></ul></li><li><code>DAG</code>(Direct Acyclic Graph): User code containing RDD transformations forms DAG<ul><li>split into stages of task by DAGScheduler</li></ul></li></ul><h2 id="3-Spark-Components-link"><a href="#3-Spark-Components-link" class="headerlink" title="3. Spark Components (link)"></a>3. Spark Components <a href="http://datastrophic.io/core-concepts-architecture-and-internals-of-apache-spark/" target="_blank" rel="noopener">(link)</a></h2><h4 id="Main-Components"><a href="#Main-Components" class="headerlink" title="Main Components"></a>Main Components</h4><p><img src="/img/main_com.png" width="300px"></p><ul><li><code>Spark Driver</code></li><li><code>Executors</code></li><li><code>Cluster Manger</code></li></ul><h4 id="Other-Components"><a href="#Other-Components" class="headerlink" title="Other Components"></a>Other Components</h4><p>: Responsible for translation of user code into actual jobs executed on cluster</p><p><img src="/img/spark_com2.png"></p><ul><li><code>SparkContext</code></li><li><code>DAGScheduler</code></li><li><code>TaskScheduler</code></li><li><code>SchedulerBackend</code></li><li><code>BlockManager</code></li></ul><h2 id="4-Operation"><a href="#4-Operation" class="headerlink" title="4. Operation"></a>4. Operation</h2><ul><li>1) <code>Action</code>: <strong>compute(count, collect)</strong> a result based on an RDD and <strong>return result to <code>Driver Program</code> or write it to storage</strong></li><li>2) <code>Transformation</code>: Apply some <strong>functions</strong> to the data in RDD to <strong>create a new RDD</strong><ul><li><code>filter</code>: <strong>return a new RDD</strong> with a subset of the data in the original RDD(selecting elems from those passed to func())<ul><li>used to remove invalid row to <strong>clean up</strong></li></ul></li><li><code>map</code>: pass each elem through the function and yield the new value of each elem in the resulting RDD</li></ul></li><li>3) Transformation vs Actions: due to <strong> Lazy Execution</strong>,  all the RDDs won’t be computed until they are used in an <strong>ACTION()</strong>(eg. collect(), first())</li></ul><h2 id="5-Others"><a href="#5-Others" class="headerlink" title="5. Others"></a>5. Others</h2><ul><li>Dependencies<ul><li>Wide(shuffle): multiple child partitions may depend on one parent partition; require data from all parent partitions</li><li>Narrow: each partition of the parent RDD is used by <strong>at most one partition</strong> of the child RDD eg. Map(), Filter()</li></ul></li></ul><hr><p>Operation Code from <a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener">Spark Doc</a></p><hr><h3 id="transformations">Transformations</h3><p>The following table lists some of the common transformations supported by Spark. Refer to theRDD API doc(<a href="api/scala/index.html#org.apache.spark.rdd.RDD">Scala</a>, <a href="api/java/index.html?org/apache/spark/api/java/JavaRDD.html">Java</a>, <a href="api/python/pyspark.html#pyspark.RDD">Python</a>, <a href="api/R/index.html">R</a>)and pair RDD functions doc(<a href="api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions">Scala</a>, <a href="api/java/index.html?org/apache/spark/api/java/JavaPairRDD.html">Java</a>)for details.</p><table class="table"><tr><th style="width:25%">Transformation</th><th>Meaning</th></tr><tr>  <td> <b>map</b>(<i>func</i>) </td>  <td> Return a new distributed dataset formed by passing each element of the source through a function <i>func</i>. </td></tr><tr>  <td> <b>filter</b>(<i>func</i>) </td>  <td> Return a new dataset formed by selecting those elements of the source on which <i>func</i> returns true. </td></tr><tr>  <td> <b>flatMap</b>(<i>func</i>) </td>  <td> Similar to map, but each input item can be mapped to 0 or more output items (so <i>func</i> should return a Seq rather than a single item). </td></tr><tr>  <td> <b>mapPartitions</b>(<i>func</i>) <a name="MapPartLink"></a> </td>  <td> Similar to map, but runs separately on each partition (block) of the RDD, so <i>func</i> must be of type    Iterator&lt;T&gt; =&gt; Iterator&lt;U&gt; when running on an RDD of type T. </td></tr><tr>  <td> <b>mapPartitionsWithIndex</b>(<i>func</i>) </td>  <td> Similar to mapPartitions, but also provides <i>func</i> with an integer value representing the index of  the partition, so <i>func</i> must be of type (Int, Iterator&lt;T&gt;) =&gt; Iterator&lt;U&gt; when running on an RDD of type T.  </td></tr><tr>  <td> <b>sample</b>(<i>withReplacement</i>, <i>fraction</i>, <i>seed</i>) </td>  <td> Sample a fraction <i>fraction</i> of the data, with or without replacement, using a given random number generator seed. </td></tr><tr>  <td> <b>union</b>(<i>otherDataset</i>) </td>  <td> Return a new dataset that contains the union of the elements in the source dataset and the argument. </td></tr><tr>  <td> <b>intersection</b>(<i>otherDataset</i>) </td>  <td> Return a new RDD that contains the intersection of elements in the source dataset and the argument. </td></tr><tr>  <td> <b>distinct</b>([<i>numPartitions</i>])) </td>  <td> Return a new dataset that contains the distinct elements of the source dataset.</td></tr><tr>  <td> <b>groupByKey</b>([<i>numPartitions</i>]) <a name="GroupByLink"></a> </td>  <td> When called on a dataset of (K, V) pairs, returns a dataset of (K, Iterable&lt;V&gt;) pairs. <br>    <b>Note:</b> If you are grouping in order to perform an aggregation (such as a sum or      average) over each key, using <code>reduceByKey</code> or <code>aggregateByKey</code> will yield much better      performance.    <br>    <b>Note:</b> By default, the level of parallelism in the output depends on the number of partitions of the parent RDD.      You can pass an optional <code>numPartitions</code> argument to set a different number of tasks.  </td></tr><tr>  <td> <b>reduceByKey</b>(<i>func</i>, [<i>numPartitions</i>]) <a name="ReduceByLink"></a> </td>  <td> When called on a dataset of (K, V) pairs, returns a dataset of (K, V) pairs where the values for each key are aggregated using the given reduce function <i>func</i>, which must be of type (V,V) =&gt; V. Like in <code>groupByKey</code>, the number of reduce tasks is configurable through an optional second argument. </td></tr><tr>  <td> <b>aggregateByKey</b>(<i>zeroValue</i>)(<i>seqOp</i>, <i>combOp</i>, [<i>numPartitions</i>]) <a name="AggregateByLink"></a> </td>  <td> When called on a dataset of (K, V) pairs, returns a dataset of (K, U) pairs where the values for each key are aggregated using the given combine functions and a neutral "zero" value. Allows an aggregated value type that is different than the input value type, while avoiding unnecessary allocations. Like in <code>groupByKey</code>, the number of reduce tasks is configurable through an optional second argument. </td></tr><tr>  <td> <b>sortByKey</b>([<i>ascending</i>], [<i>numPartitions</i>]) <a name="SortByLink"></a> </td>  <td> When called on a dataset of (K, V) pairs where K implements Ordered, returns a dataset of (K, V) pairs sorted by keys in ascending or descending order, as specified in the boolean <code>ascending</code> argument.</td></tr><tr>  <td> <b>join</b>(<i>otherDataset</i>, [<i>numPartitions</i>]) <a name="JoinLink"></a> </td>  <td> When called on datasets of type (K, V) and (K, W), returns a dataset of (K, (V, W)) pairs with all pairs of elements for each key.    Outer joins are supported through <code>leftOuterJoin</code>, <code>rightOuterJoin</code>, and <code>fullOuterJoin</code>.  </td></tr><tr>  <td> <b>cogroup</b>(<i>otherDataset</i>, [<i>numPartitions</i>]) <a name="CogroupLink"></a> </td>  <td> When called on datasets of type (K, V) and (K, W), returns a dataset of (K, (Iterable&lt;V&gt;, Iterable&lt;W&gt;)) tuples. This operation is also called <code>groupWith</code>. </td></tr><tr>  <td> <b>cartesian</b>(<i>otherDataset</i>) </td>  <td> When called on datasets of types T and U, returns a dataset of (T, U) pairs (all pairs of elements). </td></tr><tr>  <td> <b>pipe</b>(<i>command</i>, <i>[envVars]</i>) </td>  <td> Pipe each partition of the RDD through a shell command, e.g. a Perl or bash script. RDD elements are written to the    process's stdin and lines output to its stdout are returned as an RDD of strings. </td></tr><tr>  <td> <b>coalesce</b>(<i>numPartitions</i>) <a name="CoalesceLink"></a> </td>  <td> Decrease the number of partitions in the RDD to numPartitions. Useful for running operations more efficiently    after filtering down a large dataset. </td></tr><tr>  <td> <b>repartition</b>(<i>numPartitions</i>) </td>  <td> Reshuffle the data in the RDD randomly to create either more or fewer partitions and balance it across them.    This always shuffles all data over the network. <a name="RepartitionLink"></a></td></tr><tr>  <td> <b>repartitionAndSortWithinPartitions</b>(<i>partitioner</i>) <a name="Repartition2Link"></a></td>  <td> Repartition the RDD according to the given partitioner and, within each resulting partition,  sort records by their keys. This is more efficient than calling <code>repartition</code> and then sorting within  each partition because it can push the sorting down into the shuffle machinery. </td></tr></table><h3 id="actions">Actions</h3><p>The following table lists some of the common actions supported by Spark. Refer to theRDD API doc(<a href="api/scala/index.html#org.apache.spark.rdd.RDD">Scala</a>, <a href="api/java/index.html?org/apache/spark/api/java/JavaRDD.html">Java</a>, <a href="api/python/pyspark.html#pyspark.RDD">Python</a>, <a href="api/R/index.html">R</a>)</p><p>and pair RDD functions doc(<a href="api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions">Scala</a>, <a href="api/java/index.html?org/apache/spark/api/java/JavaPairRDD.html">Java</a>)for details.</p><table class="table"><tr><th>Action</th><th>Meaning</th></tr><tr>  <td> <b>reduce</b>(<i>func</i>) </td>  <td> Aggregate the elements of the dataset using a function <i>func</i> (which takes two arguments and returns one). The function should be commutative and associative so that it can be computed correctly in parallel. </td></tr><tr>  <td> <b>collect</b>() </td>  <td> Return all the elements of the dataset as an array at the driver program. This is usually useful after a filter or other operation that returns a sufficiently small subset of the data. </td></tr><tr>  <td> <b>count</b>() </td>  <td> Return the number of elements in the dataset. </td></tr><tr>  <td> <b>first</b>() </td>  <td> Return the first element of the dataset (similar to take(1)). </td></tr><tr>  <td> <b>take</b>(<i>n</i>) </td>  <td> Return an array with the first <i>n</i> elements of the dataset. </td></tr><tr>  <td> <b>takeSample</b>(<i>withReplacement</i>, <i>num</i>, [<i>seed</i>]) </td>  <td> Return an array with a random sample of <i>num</i> elements of the dataset, with or without replacement, optionally pre-specifying a random number generator seed.</td></tr><tr>  <td> <b>takeOrdered</b>(<i>n</i>, <i>[ordering]</i>) </td>  <td> Return the first <i>n</i> elements of the RDD using either their natural order or a custom comparator. </td></tr><tr>  <td> <b>saveAsTextFile</b>(<i>path</i>) </td>  <td> Write the elements of the dataset as a text file (or set of text files) in a given directory in the local filesystem, HDFS or any other Hadoop-supported file system. Spark will call toString on each element to convert it to a line of text in the file. </td></tr><tr>  <td> <b>saveAsSequenceFile</b>(<i>path</i>) <br> (Java and Scala) </td>  <td> Write the elements of the dataset as a Hadoop SequenceFile in a given path in the local filesystem, HDFS or any other Hadoop-supported file system. This is available on RDDs of key-value pairs that implement Hadoop's Writable interface. In Scala, it is also   available on types that are implicitly convertible to Writable (Spark includes conversions for basic types like Int, Double, String, etc). </td></tr><tr>  <td> <b>saveAsObjectFile</b>(<i>path</i>) <br> (Java and Scala) </td>  <td> Write the elements of the dataset in a simple format using Java serialization, which can then be loaded using    <code>SparkContext.objectFile()</code>. </td></tr><tr>  <td> <b>countByKey</b>() <a name="CountByLink"></a> </td>  <td> Only available on RDDs of type (K, V). Returns a hashmap of (K, Int) pairs with the count of each key. </td></tr><tr>  <td> <b>foreach</b>(<i>func</i>) </td>  <td> Run a function <i>func</i> on each element of the dataset. This is usually done for side effects such as updating an <a href="#accumulators">Accumulator</a> or interacting with external storage systems.  <br><b>Note</b>: modifying variables other than Accumulators outside of the <code>foreach()</code> may result in undefined behavior. See <a href="#understanding-closures-a-nameclosureslinka">Understanding closures </a> for more details.</td></tr></table>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> Spark </tag>
            
            <tag> DAG </tag>
            
            <tag> RDD </tag>
            
            <tag> Spark_component </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Stat_Test_1] ANOVA_집단간 비교</title>
      <link href="/2019/03/13/recap-annova/"/>
      <url>/2019/03/13/recap-annova/</url>
      
        <content type="html"><![CDATA[<h1 id="통계-검정-집단간-비교"><a href="#통계-검정-집단간-비교" class="headerlink" title="통계 검정: 집단간 비교"></a>통계 검정: 집단간 비교</h1><a id="more"></a><h2 id="Two-groups"><a href="#Two-groups" class="headerlink" title="Two groups"></a>Two groups</h2><ul><li>z-test: 모집단 분산 미리 알고/ 표본크기 30이상 (대개 분산모르므로 사용안함)</li><li>t-test(등분산/이분산): 독립된 두 개의 표본집단간의 <strong>평균차이</strong> 검정. eg. 어떤 변인에 따른 두 집단 차이</li></ul><h2 id="Two-or-More-groups"><a href="#Two-or-More-groups" class="headerlink" title="Two or More groups"></a>Two or More groups</h2><h3 id="1-F-test-두-개-이상의-집단-비교-집단-내-amp-집단-간-분산을-분석"><a href="#1-F-test-두-개-이상의-집단-비교-집단-내-amp-집단-간-분산을-분석" class="headerlink" title="1. F-test: 두 개 이상의 집단 비교. 집단 내 &amp; 집단 간 분산을 분석"></a>1. F-test: 두 개 이상의 집단 비교. 집단 내 &amp; 집단 간 분산을 분석</h3><p>   <img src="/img/ftest.png"></p><ul><li>eg. A, B, C 각 집단내 &amp; 집단간 연령 분산 -&gt; A 집단 연령의 분산 &gt; B, C 집단 연령의 분산 = A는 이질적 연령대로 구성 되어 있음</li></ul><h3 id="2-1-ANOVA-Analysis-of-Variance-분산분석-범주형-x-연속형-y-F-test-사용-link"><a href="#2-1-ANOVA-Analysis-of-Variance-분산분석-범주형-x-연속형-y-F-test-사용-link" class="headerlink" title="2.1 ANOVA(Analysis of Variance, 분산분석): 범주형 x, 연속형 y, F-test 사용 (link)"></a>2.1 ANOVA(Analysis of Variance, 분산분석): 범주형 x, 연속형 y, F-test 사용 <a href="http://www.cqeacademy.com/cqe-body-of-knowledge/quantitative-methods-tools/anova-analysis/" target="_blank" rel="noopener">(link)</a></h3><p>   <img src="/img/anova_2.jpg" width="500px"></p><script type="math/tex; mode=display">F-static = \dfrac{MST}{MSE} \approx \dfrac{\text{Var b/w Groups}}{\text{Var within Groups}}</script><ul><li><strong>결론</strong>: 가변수 활용한 <strong>회귀분석</strong> 결과와 같음.(변수의 category값이 너무 많으면 그때 ANOVA 하자)<ul><li>회귀분석과 ANOVA 관계: ANOVA를 통해 회귀식의 F 검정 가능(결정계수 R^2에 대해 F 검정. 즉, 회귀식의 적합성 검정)</li><li>결정계수 R^2 -&gt; F 검정 통계량 계산: test statistics F = f(R^2) -&gt; F 검정 <a href="https://datascienceschool.net/view-notebook/897c3471597e42f0a17627953007780b/" target="_blank" rel="noopener">(검정 통계량이란?)</a><script type="math/tex; mode=display">F_{k, n-k-1} = \dfrac{R^2/(k-1)}{(1-R^2)(n-k-1)} = \dfrac{회귀제곱평균(MSR)}{오차제곱평균(MSE)}</script><ul><li>k: num of group; n: num of sample</li><li>MSR_(explained var.) = SSR/df; MSE_(unexplained var.) = SSE/df</li><li>Regression : ANOVA</li></ul></li><li>= SSR(sum of squares of reg.) : SSB(b/w groups sum of squares)</li><li>= SSE(sum of squares error) : SSW(within gorups sum of squares)</li></ul></li><li>회귀분석이 제공하는 정보가 더 많음. eg. ANOVA: y에 영향 유무 vs 회귀: 어떻게 영향</li><li>H0: 모집단의 평균이 모두 같다</li><li>목적: 평균값의 차이가 의미 있는가. 아니면 분산이 커서 평균 차이가 발생하는지 확인</li><li>조건: 정규성, 분산의 동질성, 관찰의 독립성</li><li>종류:<ul><li>일원 분산분석 model: y ~ x1</li><li>이원 분산분석 model: y ~ x1, x2, x1:x2(교호 작용/주 효과)</li></ul></li></ul><h3 id="2-2-ANOVA-Question-link"><a href="#2-2-ANOVA-Question-link" class="headerlink" title="2.2 ANOVA Question (link)"></a>2.2 ANOVA Question <a href="http://analyticspro.org/2016/03/15/r-tutorial-how-to-interpret-f-statistic-in-regression-models/" target="_blank" rel="noopener">(link)</a></h3><ul><li>Q: F-통계량과 R^2가 어떻게 다른가 (How is F Statistic different from R Squared?)</li><li>A: <strong>R^2</strong>는 종속/독립 변수가 얼마나 강하게 연관이 있는지 보여주지만, 유의도를 제공하지는 않음. <strong>F-통계량</strong>은 그 연관성의 유의도를 보여줌. (<strong>R squared</strong> provides <strong>a measure of strength of relationship</strong> between our predictors and our response variable and it does not comment on whether the relationship is statistically significant. <strong>F Statistic</strong> gives us a power to judge whether that relationship is statistically significant in other words it comments on <strong>whether or R² is significant or not.</strong>)</li><li>Q: 회귀분석에서 F-통계량을 어떻게 활용해야하는가? (What should I do with F statistic in Regression model?)</li><li>A: R^2의 신뢰도 측정에 부가적으로 사용 (If my <strong>F-statistic is significant</strong> that gives me <strong>extra confidence on the R² value</strong> that I have got and Vice Versa))</li></ul><h3 id="예제-link"><a href="#예제-link" class="headerlink" title="예제 (link)"></a>예제 <a href="https://github.com/HenryPaik1/study/blob/master/06.Math/Recap/Recap_test_ANOVAegok.ipynb" target="_blank" rel="noopener">(link)</a></h3><hr><ul><li>reference<ul><li><a href="https://datascienceschool.net/view-notebook/897c3471597e42f0a17627953007780b/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/897c3471597e42f0a17627953007780b/</a></li><li><a href="https://rfriend.tistory.com/135" target="_blank" rel="noopener">https://rfriend.tistory.com/135</a></li><li><a href="https://socialinnovation.tistory.com/142" target="_blank" rel="noopener">https://socialinnovation.tistory.com/142</a></li><li><a href="https://medium.com/@rrfd/f-tests-and-anovas-examples-with-the-iris-dataset-fe7caa3e21d0" target="_blank" rel="noopener">https://medium.com/@rrfd/f-tests-and-anovas-examples-with-the-iris-dataset-fe7caa3e21d0</a></li><li><a href="http://analyticspro.org/2016/03/15/r-tutorial-how-to-interpret-f-statistic-in-regression-models/" target="_blank" rel="noopener">http://analyticspro.org/2016/03/15/r-tutorial-how-to-interpret-f-statistic-in-regression-models/</a></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Stat </tag>
            
            <tag> Study </tag>
            
            <tag> ANOVA </tag>
            
            <tag> Ftest </tag>
            
            <tag> Stat_test </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Web] Basic</title>
      <link href="/2019/03/11/net1/"/>
      <url>/2019/03/11/net1/</url>
      
        <content type="html"><![CDATA[<h1 id="공부-필기-정리"><a href="#공부-필기-정리" class="headerlink" title="공부 필기 정리"></a>공부 필기 정리</h1><a id="more"></a><p><img src="/img/net1.png"></p><p><img src="/img/net2.png"></p><p>refernce: <a href="https://www.youtube.com/user/egoing2/playlists" target="_blank" rel="noopener">https://www.youtube.com/user/egoing2/playlists</a></p>]]></content>
      
      
      <categories>
          
          <category> Net/Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> Host </tag>
            
            <tag> Server/Client </tag>
            
            <tag> IP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Stat] 회귀분석 가정과 잔차분석</title>
      <link href="/2019/03/11/assumption/"/>
      <url>/2019/03/11/assumption/</url>
      
        <content type="html"><![CDATA[<h1 id="확률론적-선형회귀-가정-amp-잔차-분석"><a href="#확률론적-선형회귀-가정-amp-잔차-분석" class="headerlink" title="확률론적 선형회귀 가정 &amp; 잔차 분석"></a>확률론적 선형회귀 가정 &amp; 잔차 분석</h1><a id="more"></a><h2 id="1-확률론적-선형회귀-가정"><a href="#1-확률론적-선형회귀-가정" class="headerlink" title="1. 확률론적 선형회귀 가정"></a>1. 확률론적 선형회귀 가정</h2><ul><li><strong>확률론적 선형회귀</strong>: 데이터가 확률변수로부터 생성된 표본으로 가정(MLE 사용)</li><li>결정론적 선형회귀: 표본 데이터에 따라 값이 달라짐(OLS 사용: RSS 최소화)</li><li>MLE/OLS 해는 같으나, MLE를 사용하면 <strong>가중치 추정값의 오차</strong> 구할 수 있음<h3 id="요약"><a href="#요약" class="headerlink" title="요약"></a>요약</h3></li><li>선형 정규 분포</li><li>오차항 정규분포</li><li>오차항 기댓값0</li><li>독립변수와 오차항 상관관계X</li><li>오차항 등분산</li><li>오차항 자기상관X</li><li>독립변수간 상관관계X</li></ul><h3 id="1-선형-정규-분포-가정-gt-오차항-정규성과-연결"><a href="#1-선형-정규-분포-가정-gt-오차항-정규성과-연결" class="headerlink" title="1) 선형 정규 분포 가정(-&gt; 오차항 정규성과 연결)"></a>1) 선형 정규 분포 가정(-&gt; 오차항 정규성과 연결)</h3><ul><li>의미: $y \sim \mathcal{N}(w^Tx, \sigma^2)$<ul><li>종속변수y는, <strong>독립변수 x의 선형조합으로 이루어진 기댓값</strong> &amp; <strong>고정된 분산</strong>을 가지는 <strong>가우시안 정규분포</strong></li><li>중요: <strong>y는 x 조건부 정규 분포</strong> (아닐 경우 일반화 선형회귀GLS 사용); x, y 무조건부 정규분포 필요없음</li></ul></li><li>비선형일 때 option<ul><li>변수 추가</li><li><strong>변수 변환(log, exp, sqrt): 비추. 해석에 어려움 생길 가능성</strong></li><li>해당 변수 제거</li><li><strong>모델 만든 후 변수 선택(선호)</strong></li></ul></li><li>질문: x1은 비선형이지만, 전체 모델 coef는 유의한 이유는?<ul><li>x_1과 y는 비선형이지만, 다른 x_n들의 영향을 제거한 partial regression은 선형관계일 수 있음</li></ul></li></ul><h3 id="2-오차항-기댓값0-amp-독립변수와-오차항-간-상관관계-없음"><a href="#2-오차항-기댓값0-amp-독립변수와-오차항-간-상관관계-없음" class="headerlink" title="2) 오차항 기댓값0 &amp; 독립변수와 오차항 간 상관관계 없음"></a>2) 오차항 기댓값0 &amp; 독립변수와 오차항 간 상관관계 없음</h3><ul><li>외생성 가정(Exogeneity): 오차항 기댓값은 독립변수에 상관 없이 0 -&gt; 무조건부 기댓값 0<script type="math/tex; mode=display">E[\epsilon | x] = 0, E[\epsilon] = 0, E[\epsilon x] = 0​</script></li></ul><h3 id="3-오차항-등분산"><a href="#3-오차항-등분산" class="headerlink" title="3) 오차항 등분산"></a>3) 오차항 등분산</h3><ul><li>문제 원인: 잔차의 <strong>조건부 이분산성</strong>(오차항의 분산과 독립변수가 일정한 상관관계) eg. y_hat에 따라 잔차 분산 증가</li><li>영향<ul><li><strong>회귀계수의 표준오차</strong> 신뢰문제:  <strong>회귀계수coef 분산</strong>은 <strong>잔차의 분산</strong> 으로 추정</li><li>표준오차 과소 계산 -&gt; t 통계량 과대평가 -&gt; 귀무가설 기각 -&gt; $coef \neq 0​$<ul><li>cf. <strong>표준오차</strong>: 모평균과 표본평균 사이에 평균적으로 얼마나 오차 발생하는가</li><li>모집단의 표준편차 high &amp; 표본 many -&gt;표준오차 low</li></ul></li></ul></li><li>해결:  WLS, 종속변수 변환(log, exp, …), white corrected std error</li></ul><h3 id="4-오차항-자기-상관성X"><a href="#4-오차항-자기-상관성X" class="headerlink" title="4) 오차항 자기 상관성X"></a>4) 오차항 자기 상관성X</h3><ul><li>실제로는, 시계열 자료가 아닌 횡단면 자료에 대해서는 실시하지 않음</li><li>영향: 자기상관 존재하면,<ul><li>coef 표준오차 신뢰도 하락</li></ul></li><li>검사<ul><li>plotting: 지그재그,  +/-반복, …</li><li>Ljung box</li></ul></li></ul><h3 id="5-독립변수간-상관관계X"><a href="#5-독립변수간-상관관계X" class="headerlink" title="5) 독립변수간 상관관계X"></a>5) 독립변수간 상관관계X</h3><ul><li>문제: 다중공선성 발생</li><li>영향<ul><li>coef의 p-value 높음</li><li>조건수 condition 증가- 표준오차 증가(coef값이 불안정해짐. 즉, data가 바뀌면 값이 전혀 달라질 수 있음.)</li></ul></li><li>해결: PCA, 변수제거</li></ul><hr><h1 id="2-잔차-분석"><a href="#2-잔차-분석" class="headerlink" title="2. 잔차 분석"></a>2. 잔차 분석</h1><ul><li>normality, homoscadicity, independence</li><li>얻고자 하는 정보<ul><li>설명변수 - 종속변수는 선형관계?<ul><li>아니라면, 오차항이 다항함수 모양 -&gt; 다항회귀 필요</li></ul></li><li>오차 분산은 설명 변수 값에 따라 변하는가? 등분산성</li><li>오차항은 서로 독립? 자기상관</li><li>이상치나 영향치 존재?</li><li>오차항은 정규분포 따르는가</li><li>다른 설명 변수는 없는가?<ul><li>오차항이 함수형태를 띠면 다른 독립변수 필요</li></ul></li></ul></li></ul><p>reference:</p><ul><li><a href="http://blog.naver.com/PostView.nhn?blogId=yonxman&amp;logNo=220950614789&amp;categoryNo=0&amp;parentCategoryNo=0&amp;viewDate=&amp;currentPage=2&amp;postListTopCurrentPage=1&amp;from=postView&amp;userTopListOpen=true&amp;userTopListCount=30&amp;userTopListManageOpen=false&amp;userTopListCurrentPage=2" target="_blank" rel="noopener">http://blog.naver.com/PostView.nhn?blogId=yonxman&amp;logNo=220950614789&amp;categoryNo=0&amp;parentCategoryNo=0&amp;viewDate=&amp;currentPage=2&amp;postListTopCurrentPage=1&amp;from=postView&amp;userTopListOpen=true&amp;userTopListCount=30&amp;userTopListManageOpen=false&amp;userTopListCurrentPage=2</a></li><li><a href="https://datascienceschool.net/view-notebook/743cdedec523447a907b2b0abda45533/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/743cdedec523447a907b2b0abda45533/</a></li><li><a href="http://wolfpack.hnu.ac.kr/Stat_Notes/adv_stat/LinearModel/Regression/ch3_residual.pdf" target="_blank" rel="noopener">http://wolfpack.hnu.ac.kr/Stat_Notes/adv_stat/LinearModel/Regression/ch3_residual.pdf</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Regression </tag>
            
            <tag> Study </tag>
            
            <tag> 잔차 </tag>
            
            <tag> 회귀분석가정 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Spark_1] Distributed Computing Basic</title>
      <link href="/2019/03/10/spark1/"/>
      <url>/2019/03/10/spark1/</url>
      
        <content type="html"><![CDATA[<h2 id="대용량-데이터"><a href="#대용량-데이터" class="headerlink" title="대용량 데이터"></a>대용량 데이터</h2><a id="more"></a><ul><li>키워드<ul><li>기존 데이터베이스 관리도구: SQL 기반 데이터 베이스</li><li>대량: 컴퓨터 1대로 데이터 처리할 수 없음(수십TB 이상). 3V(Volumne, Velocity, Variety).</li><li>비정형: 그림, 영상, 문서 등 “형태 &amp; 구조”가 다른, 구조화 되지 않은 데이터(vs 숫자Numeric 데이터)</li></ul></li></ul><h2 id="기술"><a href="#기술" class="headerlink" title="기술"></a>기술</h2><h3 id="1-고전-빅데이터-기술"><a href="#1-고전-빅데이터-기술" class="headerlink" title="1. 고전 빅데이터 기술"></a>1. 고전 빅데이터 기술</h3><ul><li>큐잉/샤딩<ul><li>샤딩<ul><li>eg. 회원 저장 -&gt; 지역별 “조각”내서 저장</li></ul></li><li>갈수록 시스템이 복잡/유지보수 매우 어려워짐<ul><li>eg. 컴퓨터 10대 중 하나 고장나면? 100대라면?</li><li>eg. resource 증가 시켜야 하면? 다시 서버 나누고 이미 있는 것들 다시 옮겨야 함</li></ul></li></ul></li></ul><h3 id="2-현대-빅데이터-기술"><a href="#2-현대-빅데이터-기술" class="headerlink" title="2. 현대 빅데이터 기술"></a>2. 현대 빅데이터 기술</h3><ul><li>키워드: GFS, 자동분산(샤딩shading), 자동복구</li></ul><h3 id="2-1-빅데이터의-시초-GFS-중요"><a href="#2-1-빅데이터의-시초-GFS-중요" class="headerlink" title="2.1 빅데이터의 시초 GFS(중요)"></a>2.1 빅데이터의 시초 GFS(중요)</h3><p>1) 개괄</p><ul><li>File System: File-dir 구조</li><li>막대한 양의 웹 문서 저장/조회를 위해 고안<ul><li>중복저장(redundancy)</li><li><strong>insert(good)/ del&amp;update(bad)</strong></li></ul></li><li>latency &lt; Throughput: page rank 알고리즘을 위해 <strong>throughput</strong> 에 집중<ul><li><strong>page rank algorithm</strong>: linked된 횟수, link주체 사이트의 importance 고려하여 page rank 산출 (“PageRank works by <strong>counting the number and quality of links to a page</strong> to determine a rough estimate of how important the website is”, wiki)</li><li>latency: Transaction요청 시간부터 반환까지 걸리는 시간<ul><li>eg. 문서 클릭 - 바로 열림 - latency good</li></ul></li><li>throughput: 단위 시간 당 처리할 수 있는 Transaction의 양(the amount of material or items passing through a system or process)</li></ul></li></ul><p>2) GFS 구조<br><img src="/img/GFS.png" width="500"></p><ul><li>Master &amp; Slave 구조<ul><li>Master: 파일위치 확인     </li><li>중복복사(Redundancy): 각기 다른 chunk server에 chunk file 여러벌 복사해둠</li></ul></li><li>Shadow Master: Master 복구용도</li></ul><h3 id="2-2-MapReduce"><a href="#2-2-MapReduce" class="headerlink" title="2.2 MapReduce"></a>2.2 MapReduce</h3><p>1) 핵심: Map - Shuffle(Groupby) - Reduce, 병렬</p><ul><li>여러대의 분산 저장소에 존재하는 데이터를 변환하거나 계산하기 위한 FrameWork</li><li>Functional programming: 특정 elem에 func() 적용 -&gt; 병렬 시스템에서 잘 적용됨<ul><li>Reduce: 각 서버에서 우선 Reduce, 이후 각 서버별 결과를 최종 Reduce</li></ul></li><li>~MapReduce: 각 data 하나씩 확인/가공 * loop</li><li>참고: <a href="http://engineering.vcnc.co.kr/2015/05/data-analysis-with-spark/" target="_blank" rel="noopener">http://engineering.vcnc.co.kr/2015/05/data-analysis-with-spark/</a></li></ul><p>2) 구조 (<a href="https://www.dummies.com/programming/big-data/data-science/the-mapreduce-programming-paradigm/" target="_blank" rel="noopener">link</a>)</p><ul><li>data들은 key-value형태<br><img src="/img/mapredu.png" width="500"></li></ul><p>3) Workflow (<a href="https://www.slideshare.net/diliprk/mapreduce-paradigm" target="_blank" rel="noopener">link</a>)<br><img src="/img/mapreduce.png" width="500px"></p><ul><li><strong>Split</strong> “input files” into blocks + assign blocks(typically 64MB) to workers</li><li>Operates on <strong>key/value</strong> pairs</li><li>Mappers <strong>filter &amp; transform</strong> “input data”: Map()</li><li><strong>Save</strong> intermediate files</li><li>Reducers <strong>aggregate</strong> mappers’ output: Reduce()</li></ul><h3 id="2-3-Hadoop-master-slave-구조-GFS-구현"><a href="#2-3-Hadoop-master-slave-구조-GFS-구현" class="headerlink" title="2.3 Hadoop: master/slave 구조, GFS 구현"></a>2.3 Hadoop: master/slave 구조, GFS 구현</h3><p>1) 구조 (<a href="https://www.dezyre.com/article/hadoop-architecture-explained-what-it-is-and-why-it-matters/317" target="_blank" rel="noopener">link</a>)<br><img src="/img/hadooparch.png" width="500px"></p><ul><li><strong>Job Tracker</strong>: The master node for parallel processing of data using <strong>Hadoop MapReduce</strong></li><li><strong>NameNode</strong>: The master node for data storage, hadoop <strong>HDFS</strong></li></ul><p>2) <strong>Data Flow</strong> in hadoop</p><ul><li><strong>Map tasks(Mapper)</strong> write their output to local disk</li><li><strong>Reduce tasks(Reducer)</strong> write their output to HDFS(<strong>Final answer</strong>)</li><li><strong>Fault tolerence</strong>(결함 발생시 부분/정상적 기능 수행할 수 있는 시스템): re-run tasks failure(실패한 부분만 다시 실행)</li></ul><p>3) Hadoop MapReduce (<a href="https://www.slideshare.net/diliprk/mapreduce-paradigm" target="_blank" rel="noopener">link</a>)</p><ul><li>single <strong>master node</strong>, many <strong>worker nodes</strong></li><li><strong>Client</strong> submits a job to master node</li><li><strong>Master</strong> splits each job into tasks (MapRedue), and assigns tasks to <strong>worker nodes</strong></li></ul><p>4) Hadoop Distributed File System(HDFS)($\approx$GFS) (<a href="https://www.dezyre.com/article/hadoop-architecture-explained-what-it-is-and-why-it-matters/317" target="_blank" rel="noopener">link</a>)<br><img src="/img/HDFS.png" width="500"></p><ul><li><strong>Name node</strong>: store file system metadata</li><li><strong>Data nodes</strong>: store Application data</li><li>Files stored as large &amp; fixed size(eg 64MB) blocks: Block을 여러 노드에 나누어 보관(default: 3 Repilca) -&gt; 노드 장애 대응</li><li>HDFS typically <strong>holds map input and reduce output</strong></li></ul><h2 id="기타-Tools-Frame-work"><a href="#기타-Tools-Frame-work" class="headerlink" title="기타: Tools/Frame work"></a>기타: Tools/Frame work</h2><ul><li>Hadoop 리소스 관리 플랫폼<ul><li>darker</li></ul></li><li>데이터 수집기: 여러 대의 서버에서 남은 로그를 효과적으로 취합<ul><li>Apache Flume</li><li>Kafka: 여러서버/DB에서 자료 받아서 여러군데로 보내줌 eg. Hadoop에 쏘면서 Spark로 분석</li></ul></li><li>workflow 관리<ul><li>Apache AirFlow: crontab 단점 보강<ul><li>Dag: directed acyclic graph</li></ul></li></ul></li><li>검색엔진: Elastic search</li><li>Hive: SQL -&gt; MapReduce</li></ul><h2 id="기타2-NoSQL-Spark"><a href="#기타2-NoSQL-Spark" class="headerlink" title="기타2: NoSQL / Spark"></a>기타2: NoSQL / Spark</h2><h3 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h3><ul><li>RDBS<ul><li>Relational: table간에 관계 by join</li></ul></li><li>병렬처리 위해 관계 포기<ul><li>컬럼 하나의 key-value</li></ul></li><li>key 부여가 핵심 eg. 채팅방ID + 시간 - value: 발신자 내용 시간</li><li>활용처: 데이터 <strong>형식 단순</strong> + 고성능이 필요 eg. 페이스북 메시지</li><li>예<ul><li>Apache HBase: 컬럼 기반 DataBase, Hadoop 생태계: HDFS 위에서 동작</li><li>Mongo DB: Web개발에서 많이 활용<ul><li>JSON 형식을 바로 저장</li><li>단점: cluster가 증가해도 효율이 증가하지 않음<ul><li>linear scalability: Cluster가 증가할수록 thoughout이 계속 증가해야 함(linear)</li></ul></li></ul></li></ul></li></ul><h3 id="Apache-Spark"><a href="#Apache-Spark" class="headerlink" title="Apache Spark"></a>Apache Spark</h3><ul><li>Hard Disk에 저장하는 것은 시간이 걸리니, Meomory에 Cluster를 올리자</li><li>메모리에 중간 결과 올리고 + 장애복구<ul><li>하드에 저장할 바에는 장애 시점에서 거슬러 올라가서 다시 계산</li></ul></li><li>NoSQL -&gt; Spark 가능</li><li>RDB 되면 굳이 Spark 안써도 됨</li><li>예전과 비교<ul><li>예전: data locality 중시. 저장한 곳에서 계산(HDFS + MapReduce) + 데이터 전송 No</li><li>최근: 저장 클러스터 &amp; 계산 클러스터 구분. 연결하는 네트워크를 고도화.</li></ul></li></ul><p>cf. The Sushi Principle(Raw Data is Better): ETL(hidden cost 높음) 생략하고 바로 가져와서 분석하자! (<a href="https://www.interana.com/blog/the-sushi-principle-raw-data-is-better" target="_blank" rel="noopener">link</a>)</p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Hadoop </tag>
            
            <tag> GFS </tag>
            
            <tag> MapReduce </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[AWS_3] AWS RDS</title>
      <link href="/2019/03/06/aws6/"/>
      <url>/2019/03/06/aws6/</url>
      
        <content type="html"><![CDATA[<h1 id="AWS-RDS"><a href="#AWS-RDS" class="headerlink" title="AWS RDS"></a>AWS RDS</h1><a id="more"></a><h2 id="개괄"><a href="#개괄" class="headerlink" title="개괄"></a>개괄</h2><ul><li>관계형 DB를 더 쉽게 설치, 운영, 확장할 수 있는  웹서비스</li><li>종류: MySQL, MariaDB, PostgreSQL, Aurora, Oracle, MS SQL Server</li><li>Aurora<ul><li>기존: Storage &amp; Computation 분리 + Instance 중심</li><li>개선: Cluster 중심의 구성 + S3활용</li><li>용량 64TB까지 증가<ul><li>MySQL: 20GB까지 증가. 이후 Application 중단</li></ul></li><li>물리적으로 wirter/reader가 참조하는 디스크 동일(논리적으로 다름)<ul><li>vs MySQL: disk 나눔</li></ul></li></ul></li><li>생성: service &gt; RDS</li><li>MySQL connection(linux workbench: jdbc필요없음)<br><img src="/img/workbench.png" width="300px"><ul><li>Connection Name: writer instance ID</li><li>Hostname: end point</li><li>Port: 3306</li><li>Username: Mastt #Master name</li></ul></li><li>Backup/Recovery<ul><li>Backup: Action &gt; Take snapshot</li><li>Recovery: Snapshots</li></ul></li><li>Scale-up: Modify</li><li>Scale-out: add reader</li><li>cache 서비스: 자주 접근하는 데이터를 cache서버에 저장 <a href="https://aws.amazon.com/caching/database-caching/" target="_blank" rel="noopener">(more…)</a><br><img src="/img/ca2.png" width="500px"><ul><li>예시: 게임 데이터 분석 아키텍처<a href="https://www.slideshare.net/awskorea/aws-cloud-game-architecture" target="_blank" rel="noopener"> (more…)</a><br><img src="/img/awscache2.png" width="400px"></li></ul></li><li>Redshift: Relational data warehouse (<a href="https://medium.com/team-mangoplate/%EB%A7%9D%EA%B3%A0%ED%94%8C%EB%A0%88%EC%9D%B4%ED%8A%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9B%A8%EC%96%B4%ED%95%98%EC%9A%B0%EC%8A%A4-%EC%9D%B4%EC%95%BC%EA%B8%B0-602e4e073078" target="_blank" rel="noopener">more…</a>)<br><img src="/img/resh1.png" width="400px"></li></ul><h2 id="Aurora-DB"><a href="#Aurora-DB" class="headerlink" title="Aurora DB"></a>Aurora DB</h2><blockquote><p>Aurora brings a novel architecture to the relational database to address this constraint, most notably by pushing redo processing to a multi-tenant scaleout storage service, purpose-built for Aurora. We describe how doing so not only reduces network traffic, but also allows for fast crash recovery, failovers to replicas without loss of data, and fault-tolerant, self-healing storage.(“<a href="http://allthingsdistributed.com/files/p1041-verbitski.pdf" target="_blank" rel="noopener">Amazon Aurora: Design Considerations for HighThroughput Cloud-Native Relational Databases</a>“)</p></blockquote><ul><li>AWS Aurora 생성시 DB 클러스터 생성 <a href="https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.html" target="_blank" rel="noopener">(more…)</a><br><img src="/img/Au1.png" width="500px"><ul><li>DB클러스터는 하나 이상의 인스턴스 &amp; 데이터 관리하는 클러스터 볼륨으로 구성</li><li>Aurora 클러스터 볼륨은 Multiple AZ 아우르는 가상 DB Storage Volume으로서, 각 AZ에는 클러스터 Data 사본이 복사됨</li><li><strong>기본primary DB 인스턴스</strong><ul><li>read/write &amp; data modification to the cluster volume</li></ul></li><li><strong>Aurora Replica</strong><ul><li>only read &amp; Connect to the same storage volume as the primary DB instance</li><li>up to 15 Aurora Replicas</li></ul></li></ul></li><li>특징: Multi-masters<ul><li>Multi AZ에 Multi reads/writes master instance 생성 가능</li><li>master instance 중 하나에 장애(또는 특정 AZ 전체 장애) 발생 -&gt; cluster의 다른 instance가 즉시 이어받아 중단 안됨<ul><li>즉 마스터 DB서버에 장애 발생시, cluster 안의 다른 서버가 이를 즉시 대체</li></ul></li></ul></li><li>SQL vs Aurora 비교 <a href="https://www.slideshare.net/AmazonWebServices/aws-reinvent-2016-getting-started-with-amazon-aurora-dat203-70508626" target="_blank" rel="noopener">(more…)</a><br><img src="/img/aucompare.png"><ul><li>MySQL: reader별로 디스크가 다름</li><li>Aurora: wirter/reader 참조 디스크가 하나(Cluster Volume)</li></ul></li></ul><h2 id="용어"><a href="#용어" class="headerlink" title="용어"></a>용어</h2><ul><li>ETL: Extract - Transform - Load<ul><li>eg.  <strong>extract</strong>: Y/M/D/t/m column using <code>SQL select</code>-&gt; <strong>transform</strong>: Y-M-D(tm) -&gt; <strong>load</strong>, insert</li></ul></li><li>Transaction: data 내용에 영향을 미치는 거래/입출고/저장 등의 단위행위</li><li>OLTP(Online Transaction Processing)<ul><li>업무기반(원시 데이터 활용 가공/분석), 금융 전산 부문에서 자주 사용</li><li>여러 과정의 연산이 <strong>하나의 단위 프로세스(Trasaction)</strong> 로 실행<ul><li>네트워크 상 여러 이용자 실시간 DB data 갱신/조회의 단위 작업 처리</li></ul></li><li>다수 이용자 거의 동시 이용할 수 있도록, 송수신 자료를 Transaction 단위로 압축, 비어있는 공간을 다른 사용자에게 할당</li></ul></li><li>OLAP(Online Analytical Processing)<ul><li>분석기반</li><li>대용량 데이터 고속 처리</li><li>사용자가 데이터 직접 접근</li></ul></li><li>Cluster: 디스크로부터 데이터를 읽어오는 시간을 줄이기 위해, 조인이나 자주 사용되는 테이블의 데이터를 <strong>디스크의 같은 위치</strong> 에 저장시키는 방법<ul><li>Aurora <a href="https://www.slideshare.net/AmazonWebServices/aws-reinvent-2016-getting-started-with-amazon-aurora-dat203-70508626" target="_blank" rel="noopener">(more…)</a><br><img src="/img/au2.png" width="500px"></li><li>장점: grouped된 컬럼 data 행들이 같은 data Block에 저장되므로 디스크 I/O 단축</li></ul></li><li>Replication<ul><li>MySQL Replication<a href="https://dev.mysql.com/doc/refman/5.5/en/replication-solutions-scaleout.html" target="_blank" rel="noopener"><img src="/img/sqlms.png" width="500px"></a></li><li>개념: scale-out(서버 추가)의 한 방법.</li><li>어떤 환경에서 활용? hight Num of reads / low Num of writes&amp;updates</li><li>어떻게 활용? 읽기 분산시킴(distribute the reads over the replication slaves, while still enabling your web servers to communicate with the replication master when a write is required. )</li></ul></li><li>Master/Slave $\approx$ Manager/Worker: Aurora Cluster 구조에서 Worker가 부족하다 싶으면 reader 추가 + 추가 + 추가…</li><li>계층형 쿼리(Hierarchical Query VS Relational)<ul><li>오라클에서만 지원</li></ul></li></ul><h2 id="기타"><a href="#기타" class="headerlink" title="기타"></a>기타</h2><ul><li>Dark data: 더이상 사용하지 않는 데이터 -&gt; 정리 필 쟝소</li><li>메타 시스템: 테이블 생성 절차 및 사용하지 않는 데이터 어떻게 처리할지</li><li>Query<ul><li><strong>모집단, 기준</strong> 을 잡고 우측에 붙여나가야 됨</li><li><strong>count</strong> 무조건 사용해서 모집단이 1000명이면 <strong>join</strong> 할 때 2000명… 등으로 달라지지 않도록 유의</li></ul></li><li>inner join/ left outer join/ left anti<br><img src="/img/sql_join.png" width="500px"></li><li><strong>replica 서버</strong> 는 master와 동급이거나 높은 사양으로 맞춰야 함(과부하 방지)</li></ul><p>참조</p><ul><li><a href="https://www.slideshare.net/awskorea/aws-cloud-game-architecture" target="_blank" rel="noopener">https://www.slideshare.net/awskorea/aws-cloud-game-architecture</a></li><li><a href="https://www.allthingsdistributed.com/files/p1041-verbitski.pdf" target="_blank" rel="noopener">https://www.allthingsdistributed.com/files/p1041-verbitski.pdf</a></li><li><a href="https://medium.com/team-mangoplate/%EB%A7%9D%EA%B3%A0%ED%94%8C%EB%A0%88%EC%9D%B4%ED%8A%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9B%A8%EC%96%B4%ED%95%98%EC%9A%B0%EC%8A%A4-%EC%9D%B4%EC%95%BC%EA%B8%B0-602e4e073078" target="_blank" rel="noopener">https://medium.com/team-mangoplate/%EB%A7%9D%EA%B3%A0%ED%94%8C%EB%A0%88%EC%9D%B4%ED%8A%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9B%A8%EC%96%B4%ED%95%98%EC%9A%B0%EC%8A%A4-%EC%9D%B4%EC%95%BC%EA%B8%B0-602e4e073078</a></li><li><a href="https://www.slideshare.net/awskorea/aws-cloud-game-architecture" target="_blank" rel="noopener">https://www.slideshare.net/awskorea/aws-cloud-game-architecture</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> RDS </tag>
            
            <tag> AURORA </tag>
            
            <tag> Cache </tag>
            
            <tag> Redshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Python] if __name__ == &#39;__main__&#39;</title>
      <link href="/2019/03/02/ifnamemain/"/>
      <url>/2019/03/02/ifnamemain/</url>
      
        <content type="html"><![CDATA[<p>의미: 만일 이 파일이 인터프리터에 의해 실행되는 경우<br><a id="more"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &quot;__main__&quot;</span><br></pre></td></tr></table></figure></p><p>예시</p><p><code>code</code>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/python</span><br><span class="line"># Filename: using_name.py</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print &apos;run by itself&apos;</span><br><span class="line">else:</span><br><span class="line">    print &apos;imported from another module&apos;</span><br></pre></td></tr></table></figure></p><p><code>output</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># case1</span><br><span class="line">$ python using_name.py</span><br><span class="line">&gt;&gt; run by itself</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># case2</span><br><span class="line">$ python</span><br><span class="line">$ (python) import using_name</span><br><span class="line">&gt;&gt; imported from another module</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> __main__ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[AWS_2] EC2 &amp; S3</title>
      <link href="/2019/02/28/aws2/"/>
      <url>/2019/02/28/aws2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-create-EC2-instance"><a href="#1-create-EC2-instance" class="headerlink" title="1. create EC2 instance"></a>1. create EC2 instance</h1><ul><li>EC2(Amazon Elastic Compute): 확장식 컴퓨팅<ul><li>instance: 가상 컴퓨팅 환경</li></ul></li><li>AMI(Amazon Machine Image): 서버에 필요한 OS, software 등 구성된 상태로 제공되는 template to launch instance<a id="more"></a></li></ul><h3 id="1-EC2-launch-instance-설정-순"><a href="#1-EC2-launch-instance-설정-순" class="headerlink" title="1) EC2 launch instance(설정 순)"></a>1) EC2 <code>launch instance</code>(설정 순)</h3><ul><li>AMI 종류: centos + compiler, centos + software, … 여러종류</li><li>instance type<ul><li>Ephemeral(수명이 짧은/단명하는): virtual machine instance 파괴시 루트/임시디스크 데이터 삭제</li><li>Block storage(EBS, Elastic Block Storage): 영속적 디스크 영역</li><li>가상 서버 리소스 ~ 블록스토리지 간 네트워크 성능<ul><li>IOPS: 초당 input/output<ul><li>Maximum: AWS EBS SSD type은 GB단위 용량의 3배</li><li>more reading: <a href="https://stackoverflow.com/questions/37058095/what-does-iops-in-amazon-ebs-mean-in-practice" target="_blank" rel="noopener">https://stackoverflow.com/questions/37058095/what-does-iops-in-amazon-ebs-mean-in-practice</a></li></ul></li><li>스루풋(Throughput): 초당 전송 대역, AWS instance type에 따름</li><li>SR-IOV(Single Root I/O Virtualization)<ul><li>각 가상NIC에서 오는 명령을 하나의 하이퍼바이저가 순차 처리하므로, 병목 현상 발생</li><li>before: multiple 가상머신 vs 하나의 하이퍼바이저(물리 NIC, Network Interface CARD)</li><li>after: vs 물리 NIC + PCI 지원</li></ul></li></ul></li></ul></li><li>Network: VPC/Public &amp; Subnet: Zone</li><li>Advanced Details: <code>script</code> to run right after lauching instance</li></ul><h3 id="2-EC2-instance-응용"><a href="#2-EC2-instance-응용" class="headerlink" title="2) EC2 instance 응용"></a>2) EC2 instance 응용</h3><ul><li>key pair = ID</li><li>monitoring으로 CPU 상태 파악</li><li><code>template</code>: template은 job 순서 보관<ul><li><code>create template from instance</code> &gt; <code>launch template</code></li></ul></li><li><code>AMI</code>: Drive를 image 형태로 보관 -&gt; 인스턴스 생성<ul><li><code>create image</code></li></ul></li><li><code>spot instance</code>: on demand 가격보다 저렴하게 사용가능한 미사용 EC2 instance<ul><li><code>launch instance</code> &gt; <code>configure</code> &gt; purchaseing option: Request Spot Instance</li><li>terminate 위험 있음. <strong>항상 image 만들어 둘것</strong></li></ul></li></ul><h3 id="용어"><a href="#용어" class="headerlink" title="용어"></a>용어</h3><ul><li>하이퍼바이저(hypervisor): host컴퓨터에서 다수의 운영 체제(operating system )를 동시에 실행하기 위한 논리적 platform</li><li>VM(virtual machine)</li></ul><h1 id="2-Object-storage-S3-파일-단위로-데이터-저장"><a href="#2-Object-storage-S3-파일-단위로-데이터-저장" class="headerlink" title="2. Object storage(S3): 파일 단위로 데이터 저장"></a>2. Object storage(S3): 파일 단위로 데이터 저장</h1><ul><li>파일 단위로 데이터 저장하는 data store</li><li>HTTP/HTTPS protocol사용하는 파일 서버와 비슷<ul><li>내부에 HTTP 서버를 내장</li><li>즉, 오브젝트 storage가 HTTP 서버/파일시스템/마운트기능 등 모두 포함</li><li>vs 서버-블록 storage: 서버 resource - 블록 storage 연결필요<ul><li>사용해서 웹사이트 구성시, 서버의 OS에 Apache,Nginx, IIS 등의 웹 서버 설치/공개할 파일 필요</li></ul></li></ul></li><li><strong>버킷</strong>: S3에 저장된 객체에 대한 컨테이너. $\approx$ Root 폴더<ul><li>모든 객체는 어떤 버킷에 포함됨</li><li>버킷 이름은 globally unique</li></ul></li><li><strong>객체</strong>: 버킷 안에 저장되는 파일<ul><li>크기: 1Byte ~ 5TB</li><li>객체마다 URL 존재 $\rightarrow$ 각각의 접근 권한 설정 가능 &amp; <code>wget</code>으로 다운 가능</li></ul></li></ul><h3 id="1-특징"><a href="#1-특징" class="headerlink" title="1) 특징"></a>1) 특징</h3><ul><li>tenant(관리자 계정 또는 IAM 사용자/그룹)는 자신에게 속한 S3 버킷을 <strong>모든 region/가용영역(AZ, AvailabilityZone: 데이터센터)</strong> 사용할 수 있음</li><li><strong>계층구조 지원 안함</strong>, 단 가상의 directory 별명을 덧붙여 파일명 수식(prefix)<ul><li><code>dir02/file01</code>: <code>idr02</code>는 수식어에 불과함</li></ul></li><li>덮어쓰기 지원 안함(삭제 후 재생성 필요)</li><li>정적 컨텐츠 저장(동영상, 파일, ..)</li></ul><h3 id="2-Class"><a href="#2-Class" class="headerlink" title="2) Class"></a>2) Class</h3><ul><li>이용빈도에 따라 class&amp;과금이 달라짐</li><li>S3 standard: Disk 깨질 위험 없음 $\rightarrow$ S3 IA(Infrequently Accessed) $\rightarrow$ S3 one Zone IA</li></ul><h3 id="3-생성"><a href="#3-생성" class="headerlink" title="3) 생성"></a>3) 생성</h3><ul><li><code>Properties</code><ul><li><code>versioning</code>: 저장된 obj에 버전 번호 붙어 관리. 같은 이름의 파일은 덮어쓰기 없이, 새로운 버전 번호로 저장됨</li><li><code>static website hosting</code>: 오브젝트 storage를 간이 웹 서버처럼 사용</li></ul></li><li><code>Permission</code><ul><li><code>bucket policy</code>: resource 접근 권한. (특정 회사에 log 공개 등)<br>(<a href="https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/example-walkthroughs-managing-access.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/example-walkthroughs-managing-access.html</a>)<ul><li>Example 1: Bucket Owner Granting Its Users Bucket Permissions</li><li>Example 2: Bucket Owner Granting Cross-Account Bucket Permissions</li><li>Managing object permissions when the object and bucket owners are not the same</li></ul></li><li><code>CORS</code>: Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain.<br>(<a href="https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/cors.html#example-scenarios-cors" target="_blank" rel="noopener">https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/cors.html#example-scenarios-cors</a>)</li></ul></li><li><code>Management</code><ul><li><code>Lifecycle</code>: 오브젝트 삭제주기/ S3 class 자동 trainsition 등</li></ul></li></ul><h3 id="4-사용"><a href="#4-사용" class="headerlink" title="4) 사용"></a>4) 사용</h3><ul><li><code>select</code>: 데이터 select. return data용량에 따라 과금.<ul><li><strong>정말 급할 때만 사용</strong></li></ul></li></ul><h3 id="cf-Storage-종류"><a href="#cf-Storage-종류" class="headerlink" title="cf. Storage 종류"></a>cf. Storage 종류</h3><ul><li>블록 storage(EBS)<ul><li>storage 관점에서는 block 단위로 데이터 인식</li><li>서버 관점에서는 storage를 디바이스로 인식</li><li>볼륨: 실제 서버에 연결되는 디스크, 영속(vs ehemeral 휘발성 디스크)</li><li>스냅샷: 볼륨을 복제. 사용하려면 다시 볼륨으로 복원 후, 서버에 연결.</li></ul></li><li>네트워크 storage</li><li>오브젝트 storage</li></ul><h1 id="3-Ec2-s3-버킷-mount"><a href="#3-Ec2-s3-버킷-mount" class="headerlink" title="3. Ec2 s3(버킷) mount"></a>3. Ec2 s3(버킷) mount</h1><ul><li>물리적 분리되어 있으나, 논리적으로 연결</li><li>resource 간 연결은 <code>IAM</code>으로 권한 설정</li><li><strong>mount 전에 꼭 <code>IAM</code> 권한 설정 할 것!</strong></li></ul><p><img src="/img/ec2mount.png" width="500px"></p><ul><li><p>s3 mount code</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sudo yum update -y</span><br><span class="line">sudo yum install golang fuse -y</span><br><span class="line">vi .bash_profile</span><br><span class="line">export GOROOT=/usr/lib/golang</span><br><span class="line">export GOBIN=$GOROOT/bin</span><br><span class="line">export GOPATH=/usr/local/golang</span><br><span class="line">export PATH=$PATH:$GOROOT/bin</span><br><span class="line">source .bash_profile</span><br><span class="line">1. goofys 설치</span><br><span class="line">$ sudo yum install git -y</span><br><span class="line">$ sudo go get github.com/kahing/goofys</span><br><span class="line">$ sudo go install github.com/kahing/goofys</span><br><span class="line">$ sudo su -</span><br><span class="line"># mkdir s3Temp</span><br><span class="line"># /root/go/bin/goofys &lt;bucket&gt; &lt;mountpoint&gt;</span><br><span class="line"># /root/go/bin/goofys &lt;bucket:prefix&gt; &lt;mountpoint&gt;</span><br><span class="line"># GOPATH/bin/goofys &lt;bucket&gt; &lt;mountpoint&gt;</span><br><span class="line"># GOPATH/bin/goofys &lt;bucket:prefix&gt; &lt;mountpoint&gt;</span><br></pre></td></tr></table></figure></li><li><p>test code</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[ec2-user@ip-172-31-1-106 ~]$ sudo go get github.com/kahing/goofys</span><br><span class="line">[ec2-user@ip-172-31-1-106 ~]$ sudo go install github.com/kahing/goofys</span><br><span class="line">[ec2-user@ip-172-31-1-106 ~]$ sudo su -</span><br><span class="line">[root@ip-172-31-1-106 ~]# mkdir s3Temp</span><br><span class="line">[root@ip-172-31-1-106 ~]# /root/go/bin/goofys bhr-dee2 s3Temp</span><br><span class="line">2019/02/26 13:18:57.203981 main.FATAL Unable to mount file system, see syslog for details</span><br><span class="line">[root@ip-172-31-1-106 ~]# GOPATH/bin/goofys bhr-dee2 s3Temp</span><br><span class="line">-bash: GOPATH/bin/goofys: No such file or directory</span><br><span class="line">[root@ip-172-31-1-106 ~]# cd s3Temp/</span><br><span class="line">[root@ip-172-31-1-106 s3Temp]# ls</span><br><span class="line">apart.json  movies.csv</span><br><span class="line">[root@ip-172-31-1-106 s3Temp]# ls -la</span><br><span class="line">total 502</span><br><span class="line">drwxr-xr-x 2 root root   4096 Feb 26 13:18 .</span><br><span class="line">dr-xr-x--- 5 root root    127 Feb 26 13:15 ..</span><br><span class="line">-rw-r--r-- 1 root root  50402 Feb 26 13:00 apart.json</span><br><span class="line">-rw-r--r-- 1 root root 458390 Feb 26 12:55 movies.csv</span><br><span class="line">[root@ip-172-31-1-106 ~] # umount s3Temp</span><br><span class="line">[root@ip-172-31-1-106 ~]# /root/go/bin/goofys bhr-dee2:new1 s3Temp</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> 버킷 </tag>
            
            <tag> S3 </tag>
            
            <tag> EC2 </tag>
            
            <tag> block_strage </tag>
            
            <tag> object_storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[AWS_1] 기본 용어</title>
      <link href="/2019/02/28/aws1/"/>
      <url>/2019/02/28/aws1/</url>
      
        <content type="html"><![CDATA[<h2 id="1-용어-기타"><a href="#1-용어-기타" class="headerlink" title="1.용어(기타)"></a>1.용어(기타)</h2><ul><li>meta data: 효율적 search 위해, 일정한 규칙에 따라 Data에 부여하는 정보(a data of the data)<br><img src="/img/metadata.png" width="300px"></li><li>ETL: 데이터 Extract, Transform, Load</li><li>Computer Cluster: (여러 대 컴퓨터 묶음) = 1대 처럼 사용</li><li>Scale up/down: 서버 증/감</li><li>Scale out/in: CPU, memory 증/감<a id="more"></a></li></ul><h2 id="2-1-용어-네트워크-AWS"><a href="#2-1-용어-네트워크-AWS" class="headerlink" title="2.1 용어(네트워크, AWS)"></a>2.1 용어(네트워크, AWS)</h2><p><img src="/img/subnets-diagram.png" alt=""></p><ul><li>리소스: AWS에서 제공하는 각종 서비스</li><li>Subnet: split IP addr block<ul><li><strong>Private</strong>: doesn’t have a route to <strong>the internet gateway</strong></li><li><strong>VPN-only-subnet</strong>: has its traffic routed to a virtual private gateway for a <strong>Site-to-Site VPN connection</strong></li></ul></li><li>VPC: Virtual Private Cloud $\approx$ 자사내 네트워크 구성</li><li>IDC: Internet Data Center</li><li>IP addr 구성<ul><li>네트워크 번호: 네트워크 식별</li><li>서브넷 주소: 서브넷은 어떤 네트워크에 종속된 네트워크. 일반적으로 하나의 지역 또는 빌딩 내의 모든 컴퓨터를 represent</li><li>호스트 번호: 네트워크 내, 특정 컴퓨터나 호스트 식별</li></ul></li><li>Route Tables: 네트워크 트래픽 전달 위치 결정에 사용할 라우팅(규칙) 집합</li></ul><h2 id="2-2-용어-추가-네트워크"><a href="#2-2-용어-추가-네트워크" class="headerlink" title="2.2 용어(추가, 네트워크)"></a>2.2 용어(추가, 네트워크)</h2><ul><li>WAN: 광역통신망Wide Area Network</li><li>Gateway: $\approx$ Router, 서로 다른 네트워크 구역을 연결 eg.공유기<ul><li>기본 gateway=공유기</li><li>공유기 $\rightarrow$ 인터넷 서비스 업체 라우터 $\rightarrow$ 인터넷</li><li>default gateway: 랜카드별 각기 다른 gateway 주소 가짐</li></ul></li><li>DNS: Domain Nmae Service 복잡한 IP주소를 문자로 치환(한국 최상위 DNS서버:KT 서울 혜화동 소재, 전 세계 모든 DNS 서버와 웹사이트 정보 동기화)<ul><li>DNS 서버에서 search: <code>.com</code> $\rightarrow$ <code>donga</code> $\rightarrow$ <code>it</code> $\rightarrow$ <code>it.donga.com</code> IP 주소 발견</li></ul></li><li>DHCP 환경: Dynamic Host Configuration Protocol. IP주소를 자동으로 할당받는 환경, DNS 서버 IP주소 정보도 자동 설정</li><li>Protocol: 통신규약<ul><li>TCP/IP protocol: 컴퓨터, 기기가 인터넷을 통해 상호 연결되기 위한 통신 규약</li><li>http protocol: 웹 페이지 접속 위한 규약</li><li>FTP protocol: 빠른 파일 전송을 위한 규약</li><li>POP(+IMAP)/SMTP protocol: 메일 수/송신 규약.<ul><li>eg. 메일수신용 POP서버주소: pop.naver.com</li><li>발신용 SMTP 서버 주소: smtp.naver.com</li></ul></li></ul></li></ul><h2 id="2-3-용어-추가-네트워크-장비"><a href="#2-3-용어-추가-네트워크-장비" class="headerlink" title="2.3 용어(추가, 네트워크 장비)"></a>2.3 용어(추가, 네트워크 장비)</h2><p><img src="/img/net_device.jpg" width="200px"></p><ul><li>LAN vs WAN: 대역 차이<ul><li>LAN: Local Arera Network, 집안, 사무실 내 네트워크 연결(Using <code>hub</code>&amp;<code>switch</code>)</li><li>WAN: Wide Area Network, 지역/국가 간 네트워크 연결(Using <code>Router</code>)</li></ul></li><li>허브 / 스위치: 네트워크 분배. 한 공간에 배치된 컴퓨터를 연결<ul><li>허브: 단순 분배 중계기. 전송대역10Mbps $rightarrow$ 5대 연결 $rightarrow$ 각 2Mbps</li><li>스위치: 5대 모두 10Mbps</li></ul></li><li>Router: 다른 장소의 컴퓨터를 연결. 최적의 경로를 찾아 데이터 전송(기점/종점 명확하게 연결: Route)<ul><li>기업용 전산 시스템 환경</li><li>인터넷 유무선 공유기: 스위치, 라우터, 방화벽 등 농축됨<ul><li>4개 유선 LAN port</li><li>1개 유선 WAN port</li><li>switch: 4개 LAN port에 기기 연결</li></ul></li></ul></li></ul><h2 id="3-VPC-생성"><a href="#3-VPC-생성" class="headerlink" title="3. VPC 생성"></a>3. VPC 생성</h2><h3 id="3-1-순서"><a href="#3-1-순서" class="headerlink" title="3.1 순서"></a>3.1 순서</h3><ul><li>VPC &gt; Create VPC &gt; CIDR block 설정</li><li>Subnets &gt; VPC 선택 &gt; CIDR block(11.0.{ }.0/24, { }: 2개 고유번호 부여); Availability Zone(물리장소 2개로 나눌 것)<ul><li>Public &amp; Private subnet 각 하나씩 생성</li></ul></li><li>Internet gateway &gt; Create - &gt; Attach to VPC</li><li>Route Tables &gt; Create - &gt; select VPC</li><li>Route Tables &gt; Edit - &gt; set Internet Gate</li><li>Route Tables &gt; Edit - &gt; select Public Subnet</li><li>Subnets &gt; Actions &gt; select auto-assign IP settings</li><li>Create EC2 &gt; Configure Instance &gt; Network: customized VPC</li><li>Advanced Details: save <code>bash script</code> to execute right after launching instance</li></ul><h3 id="질문"><a href="#질문" class="headerlink" title="질문"></a>질문</h3><ul><li>왜 subnet 2개 이상? 보안문제. 보안의 기본은 접근 어렵게</li></ul><h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul><li><a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html#vpc-subnet-basics" target="_blank" rel="noopener">https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html#vpc-subnet-basics</a></li><li><a href="http://it.donga.com/3126/" target="_blank" rel="noopener">http://it.donga.com/3126/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> subnet </tag>
            
            <tag> WAN </tag>
            
            <tag> VPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Stat] 결정계수(Coefficient of Determination, r squared)</title>
      <link href="/2019/02/23/Recap_rsquareok/"/>
      <url>/2019/02/23/Recap_rsquareok/</url>
      
        <content type="html"><![CDATA[<h1 id="결정계수-R-2-Coefficient-of-Determination"><a href="#결정계수-R-2-Coefficient-of-Determination" class="headerlink" title="결정계수($R^2$, Coefficient of Determination)"></a>결정계수($R^2$, Coefficient of Determination)</h1><a id="more"></a><script type="math/tex; mode=display">R^2 = 1 - \dfrac{RSS}{TSS}=\dfrac{ESS}{TSS} \\TSS = RSS + ESS\\RSS = \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 \\TSS = \sum_{i=1}^N (y_i - \bar{y})^2</script><ul><li>y값이 퍼진 정도보다, $\hat{y}$가 퍼진 정도가 클 수는 없음<ul><li>직관적으로 생각해보면, $\hat{y}$이 산점한 y의 중앙을 뚫고 지나가기 때문에 이해가능</li></ul></li><li>기하학적으로 보면, <strong>$\hat{y}$는 잔차$e$를 최소화</strong>하는 값을 찾았기 때문에(OLS) 아래와 같이 설명 가능</li></ul><script type="math/tex; mode=display">||y||^2 = ||\hat{y}||^2 + ||e||^2</script><ul><li>아래 그림에서는:<ul><li>$||y||^2 = ||b||^2$</li><li>$||\hat{y}||^2 = ||A\hat{x}||$</li><li>$||e||^2 = ||b-A \hat{x}||^2$</li></ul></li></ul><p style="text-align:center">    <img src="/Recap_rsquared_files/OLS.png" width="500">    (https://slideplayer.com/slide/2342847/)</p>    <h1 id="조정결정계수-adjusted-R-2"><a href="#조정결정계수-adjusted-R-2" class="headerlink" title="조정결정계수 (adjusted $R^2$)"></a>조정결정계수 (adjusted $R^2$)</h1><ul><li>독립변수 갯수에 따라 결정 계수의 값을 조정</li></ul><h3 id="질문"><a href="#질문" class="headerlink" title="질문"></a>질문</h3><ul><li>상수항 없을 때 결정계수값이 높은 이유?<ul><li>계산시 TSS가 커짐 -&gt; $R^2$가 커짐</li></ul></li><li>with intercept<script type="math/tex; mode=display">R^2 = 1 - \frac{\sum_i (y_i - \hat y_i)^2}{\sum_i (y_i - \bary)^2}</script></li><li>without intercept<script type="math/tex; mode=display">R_0^2 = 1 - \frac{\sum_i (y_i - \hat y_i)^2}{\sum_i y_i^2}</script></li><li>reference:<br>  <a href="https://stats.stackexchange.com/questions/26176/removal-of-statistically-significant-intercept-term-increases-r2-in-linear-mo" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/26176/removal-of-statistically-significant-intercept-term-increases-r2-in-linear-mo</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Regression </tag>
            
            <tag> Stat </tag>
            
            <tag> r_squared </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] Command Cheat Sheet(on going)</title>
      <link href="/2019/02/17/linuxchaet/"/>
      <url>/2019/02/17/linuxchaet/</url>
      
        <content type="html"><![CDATA[<pre><code>1) show only dir. whithin current dir: ls -d */</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> cmd </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] netstat to check network status</title>
      <link href="/2019/02/17/netstat/"/>
      <url>/2019/02/17/netstat/</url>
      
        <content type="html"><![CDATA[<p><code>netstat</code> is used to check port status.<br><a id="more"></a><br><code>net-tools</code> pkg includes <code>netstat</code><br>1) install<br>    $ sudo apt update<br>    $ sudo apt install net-tools</p><p>current status of port</p><p>2)<br>    $ sudo netstat —program —listening —numeric  —tcp</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> netstat </tag>
            
            <tag> net-tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Math] Covariance and Correlation</title>
      <link href="/2019/02/16/Recap_covandcorr/"/>
      <url>/2019/02/16/Recap_covandcorr/</url>
      
        <content type="html"><![CDATA[<h1 id="공분산-covariance-amp-상관계수-correlation-coefficient"><a href="#공분산-covariance-amp-상관계수-correlation-coefficient" class="headerlink" title="공분산(covariance) &amp; 상관계수(correlation coefficient)"></a>공분산(covariance) &amp; 상관계수(correlation coefficient)</h1><a id="more"></a><h2 id="다변수-확률변수-간의-상관관계-표현"><a href="#다변수-확률변수-간의-상관관계-표현" class="headerlink" title="- 다변수 확률변수 간의 상관관계 표현"></a>- <strong>다변수 확률변수 간의 상관관계 표현</strong></h2><h2 id="1-공분산"><a href="#1-공분산" class="headerlink" title="1. 공분산"></a>1. 공분산</h2><script type="math/tex; mode=display">Cov[X, Y] = E[(X-E[X])(Y-E[Y])]</script><h3 id="표본공분산-sample-covariance"><a href="#표본공분산-sample-covariance" class="headerlink" title="표본공분산(sample covariance)"></a>표본공분산(sample covariance)</h3><ul><li>절대값: 무의미</li><li>부호: <strong>데이터 간 상관관계 방향</strong>(x의 $\bar{x}$ 대비 증감에 따른 y의 $\bar{y}$ 대비 증감)</li></ul><script type="math/tex; mode=display">s_{xy} = \dfrac{1}{N} \sum_{i=1}^N(x_i - \bar{x})(y_i - \bar{y})</script><ul><li>$(\bar{x}, \bar{y})$를 원점으로 $(x-\bar{x}) \times (y-\bar{y})$ 사각형의 면적으로 계산<ul><li>음수 면적 존재</li></ul></li></ul><h2 id="2-상관계수"><a href="#2-상관계수" class="headerlink" title="2. 상관계수"></a>2. 상관계수</h2><ul><li>공분산 normalize<script type="math/tex; mode=display">\rho[X, Y] = \dfrac{Cov[X, Y]} {\sqrt{Var[X] \cdot Var[Y]}}</script></li></ul><h3 id="표본상관계수-correlation-coefficient"><a href="#표본상관계수-correlation-coefficient" class="headerlink" title="표본상관계수(correlation coefficient)"></a>표본상관계수(correlation coefficient)</h3><ul><li>절대값: 변수 간 <strong>(의존)크기=선형(직선)관계 크기</strong> 표현(scatter_plot 선형 정도)<ul><li>즉, x알면 y를 알 수 있는 정도</li><li>비선형은 catch 불완전<ul><li>eg. 2차함수: x알면 y 100% 맞출 수 있지만(완전한 상관관계 존재), corr값은 0 가능</li></ul></li></ul></li><li>부호: 데이터 상관관계 방향<ul><li><strong>중요</strong>: scatter plot의 <strong>기울기</strong> 절대값 크기는 <strong>상관계수와 아무런 의미 없음</strong><script type="math/tex; mode=display">r_{xy} = \dfrac{s_{xy}}{\sqrt{s_x^2 s_y^2}}</script></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 상관계수의 예</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">corrs = [<span class="number">1</span>, <span class="number">.7</span>, <span class="number">.3</span>, <span class="number">-.3</span>, <span class="number">-.7</span>, <span class="number">-1</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">mean = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i, r <span class="keyword">in</span> enumerate(corrs):</span><br><span class="line">    cov = [[<span class="number">1</span>, r], [r, <span class="number">1</span>]]</span><br><span class="line">    x, y = np.random.multivariate_normal(mean, cov, size=<span class="number">1000</span>).T</span><br><span class="line">    plt.subplot(<span class="number">1</span>, len(corrs), i+<span class="number">1</span>)</span><br><span class="line">    plt.plot(x, y, <span class="string">'ro'</span>, ms=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#     plt.axis('equal')</span></span><br><span class="line">    plt.title(<span class="string">r"$\rho=&#123;&#125;$"</span>.format(r))</span><br><span class="line">    plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.suptitle(<span class="string">"corr and scatter_plot"</span>, y=<span class="number">1.1</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_covandcorr_files/Recap_covandcorr_1_0.png" alt=""></p><p>reference</p><ul><li><a href="https://datascienceschool.net/view-notebook/4cab41c0d9cd4eafaff8a45f590592c5/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/4cab41c0d9cd4eafaff8a45f590592c5/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> covariance </tag>
            
            <tag> correlation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] ARIMA 모델 모수추정 일반</title>
      <link href="/2019/02/14/Recap_TimeSeries(0)_ok/"/>
      <url>/2019/02/14/Recap_TimeSeries(0)_ok/</url>
      
        <content type="html"><![CDATA[<h1 id="확률과정-모형-추정"><a href="#확률과정-모형-추정" class="headerlink" title="확률과정 모형 추정"></a>확률과정 모형 추정</h1><a id="more"></a><h3 id="1-결정론적-추세-Deterministic-Trend-제거"><a href="#1-결정론적-추세-Deterministic-Trend-제거" class="headerlink" title="1. 결정론적 추세(Deterministic Trend) 제거"></a>1. 결정론적 추세(Deterministic Trend) 제거</h3><pre><code>- 다항식 추세</code></pre><h3 id="2-확률적-추세-Stochastic-Trend-제거"><a href="#2-확률적-추세-Stochastic-Trend-제거" class="headerlink" title="2. 확률적 추세(Stochastic Trend) 제거"></a>2. 확률적 추세(Stochastic Trend) 제거</h3><pre><code>- ARIMA- ADF 사용    - H0: 단위근 존재 -&gt; Integration 존재 -&gt; 차분필요</code></pre><h3 id="3-정규성-확인"><a href="#3-정규성-확인" class="headerlink" title="3. 정규성 확인"></a>3. 정규성 확인</h3><pre><code>- 정규성을 띠면 백색잡음 -&gt; ARMA 모형 적용가능- 일반 선형확률과정은 가우시안 정규분포 따름(백색잡음의 선형조합)- 정규성 개선을 위한 방법    - Box-Cox    - 로그변환</code></pre><h3 id="4-ARMA-모형의-차수-결정"><a href="#4-ARMA-모형의-차수-결정" class="headerlink" title="4.  ARMA 모형의 차수 결정"></a>4.  ARMA 모형의 차수 결정</h3><pre><code>- MA: ACF가 특정차수이상에서 사라짐(cut-off)- AR: PACF가 특정차수이상에서 사라짐- ARMA: ACF/PACF가 특정차수이상에서 사라지지 않음    - 모수추정: AIC/BIC, MML/LM/MLE 등 사용    - bootstrapping으로 모수의 표준오차 추정</code></pre><h3 id="5-모형-진단"><a href="#5-모형-진단" class="headerlink" title="5. 모형 진단"></a>5. 모형 진단</h3><pre><code>- 잔차 정규성 검정- 잔차에 ACF/PACF/Ljung-Box(H0: k=0이외 상관계수0) Q검정으로 모형 차수 재확인</code></pre><hr><h1 id="Tip"><a href="#Tip" class="headerlink" title="Tip"></a>Tip</h1><h3 id="1-로그변환-및-Box-Cox-변환"><a href="#1-로그변환-및-Box-Cox-변환" class="headerlink" title="1) 로그변환 및 Box-Cox 변환"></a>1) 로그변환 및 Box-Cox 변환</h3><h4 id="왜-사용-to-get-constant-variance-rightarrow-and-then-detrend-rightarrow-stationary-process"><a href="#왜-사용-to-get-constant-variance-rightarrow-and-then-detrend-rightarrow-stationary-process" class="headerlink" title="왜 사용? to get constant variance $\rightarrow$ and then detrend $\rightarrow$ stationary process"></a>왜 사용? to get constant variance $\rightarrow$ and then detrend $\rightarrow$ stationary process</h4><ul><li>비정상확률 과정 중 시간t에 의존하여 기댓값 및 분산이 변하는 경우</li><li>eg. 기댓값은 t에 의존, 표준편차는 $\mu$에 의존<script type="math/tex; mode=display">E[Y_t] = \mu_t = f(t) \\\sqrt{Var[Y_t]} = \mu_t \sigma \\E[\log{Y_t}] = \log{\mu_t} \\Var[\log{Y_t}] \approx \sigma^2 \rightarrow \text{constant}</script></li><li>cf. log는 차분 후에도 trend가 잡히지 않을 경우에도 사용<ul><li>즉, 시점이 변함에 따라 증가하다가, 일정 시점 이후부터 급격히 증가하는 자료의 경우, 차분을 여러번 해도 trend가 안 잡힘 $/rightarrow$ log변환 후 차분</li></ul></li></ul><h3 id="2-모형구분"><a href="#2-모형구분" class="headerlink" title="2) 모형구분"></a>2) 모형구분</h3><ul><li>AR vs MA: 모두 백색잡음 $\epsilon$의 선형 조합. ACF &amp; PACF로 구분 가능</li><li>ARMA(Stationary) vs ARIMA(Non-Stationary): 특성방정식이 다름. ADF로 구분 가능<ul><li>ARMA(p, q)<script type="math/tex; mode=display">Y_t = \phi_1Y_{t-1}+ \cdots + \phi_p Y_{t-p} + \cdots</script></li><li>ARIMA(p, 1, q):<script type="math/tex; mode=display">Y_t = (1+\phi_1)Y_t + (\phi_2 - \phi_1)Y_{t-1} + \cdots + (\phi_p - \phi_{p-1})Y_{t-p} - \phi_p Y_{t-p-1} + \cdots</script></li></ul></li></ul><h3 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h3><p><img src="/Recap_TimeSeries%280%29_ok_files\acfvspacf.png" alt="http://stat.snu.ac.kr/time/download/%EC%8B%9C%EA%B3%84%EC%97%B4%EB%B6%84%EC%84%9D6%EC%9E%A5%EA%B0%95%EC%9D%98.pdf"></p><h1 id="예제-MA-amp-AR의-ACF-amp-PACF-비교"><a href="#예제-MA-amp-AR의-ACF-amp-PACF-비교" class="headerlink" title="예제) MA &amp; AR의 ACF &amp; PACF 비교"></a>예제) MA &amp; AR의 ACF &amp; PACF 비교</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ma</span></span><br><span class="line">theta = <span class="number">0.6</span></span><br><span class="line">ar = [<span class="number">1</span>]</span><br><span class="line">ma = [<span class="number">1</span>, theta]</span><br><span class="line">a = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">s = a.generate_sample(<span class="number">20</span>, burnin=<span class="number">240</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>,<span class="number">7</span>))</span><br><span class="line">plt.subplot(<span class="number">411</span>)</span><br><span class="line">plt.stem(a.acf(<span class="number">20</span>))</span><br><span class="line">plt.subplot(<span class="number">412</span>)</span><br><span class="line">plt.stem(a.pacf(<span class="number">20</span>))</span><br><span class="line"></span><br><span class="line">ax=plt.subplot(<span class="number">413</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(s, ax=ax)</span><br><span class="line">ax=plt.subplot(<span class="number">414</span>)</span><br><span class="line">sm.tsa.graphics.plot_pacf(s, method=<span class="string">'ywm'</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_4_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AR</span></span><br><span class="line">phi = <span class="number">0.6</span></span><br><span class="line">ar = [<span class="number">1</span>, phi]</span><br><span class="line">ma = [<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">a = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">s = a.generate_sample(<span class="number">20</span>, burnin=<span class="number">240</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>,<span class="number">7</span>))</span><br><span class="line">plt.subplot(<span class="number">411</span>)</span><br><span class="line">plt.stem(a.acf(<span class="number">20</span>))</span><br><span class="line">plt.subplot(<span class="number">412</span>)</span><br><span class="line">plt.stem(a.pacf(<span class="number">20</span>))</span><br><span class="line"></span><br><span class="line">ax=plt.subplot(<span class="number">413</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(s, ax=ax)</span><br><span class="line">ax=plt.subplot(<span class="number">414</span>)</span><br><span class="line">sm.tsa.graphics.plot_pacf(s, method=<span class="string">'ywm'</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_5_0.png" alt=" "></p><h2 id="예제-Shampoo-Sales-Dataset"><a href="#예제-Shampoo-Sales-Dataset" class="headerlink" title="예제) Shampoo Sales Dataset"></a>예제) Shampoo Sales Dataset</h2><ul><li><ol><li>Deterministic Trend &amp; Seasonality</li></ol></li><li><ol><li>Stochastic Trend &amp; Seasonality: Multiplicative SARIMA</li></ol></li></ul><h3 id="Original-data"><a href="#Original-data" class="headerlink" title="Original data"></a>Original data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'shampoo.csv'</span>)</span><br><span class="line">df.dropna(inplace=<span class="keyword">True</span>)</span><br><span class="line">X = df.values[:, <span class="number">1</span>]</span><br><span class="line">plt.plot(X)</span><br><span class="line">plt.show()</span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_8_0.png" alt=" "></p><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 36 entries, 0 to 35Data columns (total 2 columns):Month                                        36 non-null objectSales of shampoo over a three year period    36 non-null float64dtypes: float64(1), object(1)memory usage: 864.0+ bytes</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parser</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> datetime.strptime(<span class="string">'190'</span> + x[<span class="string">'Month'</span>], <span class="string">'%Y-%m'</span>)</span><br><span class="line"></span><br><span class="line">df[<span class="string">'Month'</span>] = df.apply(parser, axis=<span class="number">1</span>)</span><br><span class="line">df = df.rename_axis(<span class="string">'order'</span>).reset_index()</span><br><span class="line">df.columns = [<span class="string">'order'</span>, <span class="string">'date'</span>, <span class="string">'val'</span>]</span><br><span class="line">df[<span class="string">'order'</span>] = df[<span class="string">'order'</span>] + <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MA 아님</span></span><br><span class="line">sm.tsa.graphics.plot_acf(df[<span class="string">'val'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_11_0.png" alt=" "></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AR(2) 가능성</span></span><br><span class="line">sm.tsa.graphics.plot_pacf(df[<span class="string">'val'</span>], method=<span class="string">'ywm'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_12_0.png" alt=" "></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sm.tsa.adfuller(df[<span class="string">'val'</span>])</span><br></pre></td></tr></table></figure><pre><code>(3.060142083641183, 1.0, 10, 25, {&#39;1%&#39;: -3.7238633119999998, &#39;5%&#39;: -2.98648896, &#39;10%&#39;: -2.6328004}, 278.9972644263031)</code></pre><hr><h2 id="1-Deterministic-Trend-amp-Seasonality"><a href="#1-Deterministic-Trend-amp-Seasonality" class="headerlink" title="1. Deterministic Trend &amp; Seasonality"></a>1. Deterministic Trend &amp; Seasonality</h2><h3 id="1-결정론적-추세-확인-linear"><a href="#1-결정론적-추세-확인-linear" class="headerlink" title="1) 결정론적 추세 확인: linear"></a>1) 결정론적 추세 확인: linear</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">f = <span class="string">"val ~ order"</span></span><br><span class="line">mod = sm.OLS.from_formula(f, df)</span><br><span class="line">res = mod.fit()</span><br><span class="line">print(res.summary())</span><br></pre></td></tr></table></figure><pre><code>                            OLS Regression Results                            ==============================================================================Dep. Variable:                    val   R-squared:                       0.730Model:                            OLS   Adj. R-squared:                  0.722Method:                 Least Squares   F-statistic:                     91.97Date:                Thu, 14 Feb 2019   Prob (F-statistic):           3.37e-11Time:                        22:07:16   Log-Likelihood:                -207.13No. Observations:                  36   AIC:                             418.3Df Residuals:                      34   BIC:                             421.4Df Model:                           1                                         Covariance Type:            nonrobust                                         ==============================================================================                 coef    std err          t      P&gt;|t|      [0.025      0.975]------------------------------------------------------------------------------Intercept     89.1371     26.723      3.336      0.002      34.829     143.445order         12.0791      1.260      9.590      0.000       9.519      14.639==============================================================================Omnibus:                        3.174   Durbin-Watson:                   1.937Prob(Omnibus):                  0.205   Jarque-Bera (JB):                2.703Skew:                           0.666   Prob(JB):                        0.259Kurtosis:                       2.827   Cond. No.                         43.4==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">t = df.order; y = df.val</span><br><span class="line">trend1 = res.params[<span class="number">0</span>] + res.params[<span class="number">1</span>]*t</span><br><span class="line">plt.plot(t, y, <span class="string">'-'</span>)</span><br><span class="line">plt.plot(t, trend1, <span class="string">'-'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_18_0.png" alt=" "></p><h3 id="2-결정론적-추세-확인-quadratic"><a href="#2-결정론적-추세-확인-quadratic" class="headerlink" title="2) 결정론적 추세 확인: quadratic"></a>2) 결정론적 추세 확인: quadratic</h3><ul><li>r sqaure 더 높음</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">f = <span class="string">"val ~ order + I(order**2)"</span></span><br><span class="line">mod = sm.OLS.from_formula(f, df)</span><br><span class="line">res = mod.fit()</span><br><span class="line">print(res.summary())</span><br></pre></td></tr></table></figure><pre><code>                            OLS Regression Results                            ==============================================================================Dep. Variable:                    val   R-squared:                       0.832Model:                            OLS   Adj. R-squared:                  0.821Method:                 Least Squares   F-statistic:                     81.51Date:                Thu, 14 Feb 2019   Prob (F-statistic):           1.71e-13Time:                        22:07:24   Log-Likelihood:                -198.63No. Observations:                  36   AIC:                             403.3Df Residuals:                      33   BIC:                             408.0Df Model:                           2                                         Covariance Type:            nonrobust                                         =================================================================================                    coef    std err          t      P&gt;|t|      [0.025      0.975]---------------------------------------------------------------------------------Intercept       202.8789     33.300      6.092      0.000     135.129     270.629order            -5.8801      4.150     -1.417      0.166     -14.324       2.563I(order ** 2)     0.4854      0.109      4.461      0.000       0.264       0.707==============================================================================Omnibus:                        2.850   Durbin-Watson:                   3.055Prob(Omnibus):                  0.241   Jarque-Bera (JB):                2.222Skew:                           0.608   Prob(JB):                        0.329Kurtosis:                       2.971   Cond. No.                     1.92e+03==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 1.92e+03. This might indicate that there arestrong multicollinearity or other numerical problems.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">trend2 = res.params[<span class="number">0</span>] + res.params[<span class="number">1</span>] * t + res.params[<span class="number">2</span>] * (t**<span class="number">2</span>)</span><br><span class="line">plt.plot(t, y, <span class="string">'-'</span>)</span><br><span class="line">plt.plot(t, trend2, <span class="string">'-'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_21_0.png" alt=" "></p><h3 id="3-remove-determinstic-trend-only"><a href="#3-remove-determinstic-trend-only" class="headerlink" title="3) remove determinstic trend only"></a>3) remove determinstic trend only</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'diff'</span>] = df[<span class="string">'val'</span>] - trend1</span><br><span class="line">df[<span class="string">'diff2'</span>] = df[<span class="string">'val'</span>] - trend2</span><br><span class="line">df[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>order</th>      <th>date</th>      <th>val</th>      <th>diff</th>      <th>diff2</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>1901-01-01</td>      <td>266.0</td>      <td>164.783784</td>      <td>68.515884</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>1901-02-01</td>      <td>145.9</td>      <td>32.604710</td>      <td>-47.160121</td>    </tr>    <tr>      <th>2</th>      <td>3</td>      <td>1901-03-01</td>      <td>183.1</td>      <td>57.725637</td>      <td>-6.506894</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>1901-04-01</td>      <td>119.3</td>      <td>-18.153436</td>      <td>-67.824437</td>    </tr>    <tr>      <th>4</th>      <td>5</td>      <td>1901-05-01</td>      <td>180.3</td>      <td>30.767490</td>      <td>-5.312748</td>    </tr>  </tbody></table></div><h3 id="4-1-plotting-linear-vs-quadratic"><a href="#4-1-plotting-linear-vs-quadratic" class="headerlink" title="4.1) plotting: linear vs quadratic"></a>4.1) plotting: linear vs quadratic</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(df.order, df[<span class="string">'val'</span>], label=<span class="string">'original'</span>)</span><br><span class="line">plt.plot(df.order, df[<span class="string">'diff'</span>], label=<span class="string">'trend: linear'</span>)</span><br><span class="line">plt.plot(df.order, df[<span class="string">'diff2'</span>], label=<span class="string">'trend: quadratic'</span>)</span><br><span class="line">plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_25_0.png" alt=" "></p><h3 id="4-2-plotting-resid-linear-vs-quadratic"><a href="#4-2-plotting-resid-linear-vs-quadratic" class="headerlink" title="4.2) plotting resid: linear vs quadratic"></a>4.2) plotting resid: linear vs quadratic</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(df.order - df[<span class="string">'diff'</span>], label=<span class="string">'trend: linear'</span>)</span><br><span class="line">plt.plot(df.order - df[<span class="string">'diff2'</span>], label=<span class="string">'trend: quadratic'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_27_0.png" alt=" "></p><h3 id="5-remove-Trend-amp-Seasonality"><a href="#5-remove-Trend-amp-Seasonality" class="headerlink" title="5) remove Trend &amp; Seasonality"></a>5) remove Trend &amp; Seasonality</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'cat'</span>] = df[<span class="string">'order'</span>] % <span class="number">15</span></span><br><span class="line">df[<span class="string">'cat'</span>].astype(<span class="string">'category'</span>)</span><br><span class="line">f = <span class="string">'val ~ C(cat) + order + I(order**2) - 1'</span></span><br><span class="line">mod = sm.OLS.from_formula(f, df)</span><br><span class="line">res = mod.fit()</span><br><span class="line">print(res.summary())</span><br></pre></td></tr></table></figure><pre><code>                            OLS Regression Results                            ==============================================================================Dep. Variable:                    val   R-squared:                       0.958Model:                            OLS   Adj. R-squared:                  0.924Method:                 Least Squares   F-statistic:                     27.41Date:                Thu, 14 Feb 2019   Prob (F-statistic):           8.58e-10Time:                        22:07:43   Log-Likelihood:                -173.44No. Observations:                  36   AIC:                             380.9Df Residuals:                      19   BIC:                             407.8Df Model:                          16                                         Covariance Type:            nonrobust                                         =================================================================================                    coef    std err          t      P&gt;|t|      [0.025      0.975]---------------------------------------------------------------------------------C(cat)[0]       174.7258     39.418      4.433      0.000      92.224     257.228C(cat)[1]       262.7115     30.125      8.721      0.000     199.658     325.765C(cat)[2]       128.9006     30.535      4.221      0.000      64.990     192.811C(cat)[3]       253.1511     30.877      8.199      0.000     188.526     317.776C(cat)[4]       130.1963     31.149      4.180      0.001      65.000     195.392C(cat)[5]       198.3030     31.355      6.324      0.000     132.676     263.930C(cat)[6]       197.2711     31.498      6.263      0.000     131.346     263.196C(cat)[7]       277.3137     37.662      7.363      0.000     198.485     356.142C(cat)[8]       186.0607     38.172      4.874      0.000     106.167     265.955C(cat)[9]       199.0857     38.599      5.158      0.000     118.298     279.874C(cat)[10]      151.8388     38.942      3.899      0.001      70.333     233.345C(cat)[11]      297.0200     39.200      7.577      0.000     214.974     379.066C(cat)[12]      146.5293     39.374      3.722      0.001      64.119     228.939C(cat)[13]      198.5167     39.465      5.030      0.000     115.915     281.118C(cat)[14]      142.2322     39.478      3.603      0.002      59.603     224.861order            -5.5256      3.059     -1.806      0.087     -11.928       0.877I(order ** 2)     0.4860      0.081      6.027      0.000       0.317       0.655==============================================================================Omnibus:                        0.957   Durbin-Watson:                   2.711Prob(Omnibus):                  0.620   Jarque-Bera (JB):                0.508Skew:                           0.290   Prob(JB):                        0.776Kurtosis:                       3.053   Cond. No.                     8.31e+03==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 8.31e+03. This might indicate that there arestrong multicollinearity or other numerical problems.</code></pre><h3 id="6-plotting"><a href="#6-plotting" class="headerlink" title="6) plotting"></a>6) plotting</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.plot(df[<span class="string">'val'</span>], label=<span class="string">'orginal'</span>)</span><br><span class="line">plt.plot(res.fittedvalues, label=<span class="string">'seasonality+deterministic trend'</span>, lw=<span class="number">3</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># residual</span></span><br><span class="line">plt.subplot(<span class="number">212</span>)</span><br><span class="line">plt.plot(res.resid, label=<span class="string">'residuals'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.legend.Legend at 0x7f4c44182240&gt;</code></pre><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_31_1.png" alt=" "></p><h3 id="7-1-잔차검정-정규성-pass"><a href="#7-1-잔차검정-정규성-pass" class="headerlink" title="7.1) 잔차검정: 정규성 pass"></a>7.1) 잔차검정: 정규성 pass</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.probplot(res.resid, plot=plt)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_33_0.png" alt=" "></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.shapiro(res.resid)</span><br></pre></td></tr></table></figure><pre><code>(0.986703634262085, 0.9349536895751953)</code></pre><h3 id="7-2-잔차검정-이분산성"><a href="#7-2-잔차검정-이분산성" class="headerlink" title="7.2) 잔차검정: 이분산성"></a>7.2) 잔차검정: 이분산성</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(res.fittedvalues, res.resid)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x7f4c428741d0&gt;</code></pre><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_36_1.png" alt=" "></p><h3 id="7-3-잔차검정-자기상관계수-ACF"><a href="#7-3-잔차검정-자기상관계수-ACF" class="headerlink" title="7.3) 잔차검정: 자기상관계수 ACF"></a>7.3) 잔차검정: 자기상관계수 ACF</h3><ul><li>lag=0 이외에 상관관계 존재 -&gt; 잔차 독립조건 위배</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(<span class="number">211</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(res.resid, ax=ax1, lags=<span class="number">15</span>)</span><br><span class="line">ax2 = plt.subplot(<span class="number">212</span>)</span><br><span class="line">sm.tsa.graphics.plot_pacf(res.resid, ax=ax2, lags=<span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_38_0.png" alt=" "></p><h3 id="7-3-Ljung-Box-검정"><a href="#7-3-Ljung-Box-검정" class="headerlink" title="7.3) Ljung-Box 검정"></a>7.3) Ljung-Box 검정</h3><ul><li>잔차가 독립적이라면, 귀무가설(ACF값이 lag=k까지 모두 0) 성립해야 함</li><li>아래는 기각</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val, pval = sm.stats.diagnostic.acorr_ljungbox(res.resid)</span><br><span class="line">plt.stem(pval)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_40_0.png" alt=" "></p><h2 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h2><ul><li>결정론적 모델 부적합</li></ul><hr><ul><li>reference<ul><li><a href="https://www.ltrr.arizona.edu/webhome/dmeko/geos585a.html#cdownload" target="_blank" rel="noopener">https://www.ltrr.arizona.edu/webhome/dmeko/geos585a.html#cdownload</a></li><li><a href="https://datascienceschool.net/view-notebook/e4b52228ac5749418d51409fdc4f9cef/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/e4b52228ac5749418d51409fdc4f9cef/</a></li><li><a href="https://machinelearningmastery.com/time-series-trends-in-python/" target="_blank" rel="noopener">https://machinelearningmastery.com/time-series-trends-in-python/</a></li><li><a href="http://stat.snu.ac.kr/time/download/%EC%8B%A4%EC%8A%B5%EA%B0%95%EC%9D%983.pdf" target="_blank" rel="noopener">http://stat.snu.ac.kr/time/download/%EC%8B%A4%EC%8A%B5%EA%B0%95%EC%9D%983.pdf</a></li></ul></li></ul><h2 id="자가질문"><a href="#자가질문" class="headerlink" title="자가질문"></a>자가질문</h2><ul><li>pacf lag=0에서 1이 안되는 이유: 자료가 작아서 lag이 너무 크면 계산에 오류 발생? No, method=’ywm’(biased method)</li><li>How to know if a model is deterministic or stochastic model?<ul><li>detrend 후 잔차가 백색잡음이면 stochastic model</li></ul></li><li>determinisitic &amp; stochastic trend &amp; seasonality 동시에 존재 가능?</li><li>왜 detrend하고 나서 regression으로 seasonality 찾으면 안되는지?</li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 시계열모수추정 </tag>
            
            <tag> Timeseries_process </tag>
            
            <tag> Timeseries_log_transform </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] Restart ubuntu wifi without reboot</title>
      <link href="/2019/02/14/restartwifi/"/>
      <url>/2019/02/14/restartwifi/</url>
      
        <content type="html"><![CDATA[<p>Wifi under Ubuntu env often fail to find signal.<br>Here is how to restart Wifi setting without reboot.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lshw -C network 2&gt;&amp;1 | grep wireless | grep driver</span><br></pre></td></tr></table></figure></p><pre><code># need &quot;driver=&#39;name&#39;&quot; for a next step&gt;&gt; configuration: broadcast=yes driver=iwlwifi driverversion=4.15.0-45-generic firmware=18.168.6.1 latency=0 link=no multicast=yes wireless=IEEE 802.11</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo modprobe -r iwlwifi &amp;&amp; sudo modprobe iwlwifi</span><br></pre></td></tr></table></figure><p>Clear.</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> network </tag>
            
            <tag> wifi </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[ML] 차원의 저주 (Curse of Dimensionality)</title>
      <link href="/2019/02/13/Recap_Curse_of_dimensionalityok/"/>
      <url>/2019/02/13/Recap_Curse_of_dimensionalityok/</url>
      
        <content type="html"><![CDATA[<h1 id="차원의-저주-Curse-of-Dimensionality"><a href="#차원의-저주-Curse-of-Dimensionality" class="headerlink" title="차원의 저주 Curse of Dimensionality"></a>차원의 저주 Curse of Dimensionality</h1><a id="more"></a><h3 id="1-의미-차원이-커서-분석에-어려움을-겪음"><a href="#1-의미-차원이-커서-분석에-어려움을-겪음" class="headerlink" title="1) 의미: 차원이 커서 분석에 어려움을 겪음"></a>1) 의미: 차원이 커서 분석에 어려움을 겪음</h3><h3 id="2-문제"><a href="#2-문제" class="headerlink" title="2) 문제:"></a>2) 문제:</h3><h4 id="A-Computational-Problem"><a href="#A-Computational-Problem" class="headerlink" title="A. Computational Problem"></a>A. Computational Problem</h4><h4 id="B-Sparse-Matrices"><a href="#B-Sparse-Matrices" class="headerlink" title="B. Sparse Matrices"></a>B. Sparse Matrices</h4><ul><li>데이터 간의 거리 증가<ul><li>eg. n차원 상의 점 $p(p_1, \cdots, p_n), q(q_1, \cdots, q_n)$ 의 거리<script type="math/tex; mode=display">d(p, q) = \sqrt{\sum_{i=1}^n (p_i - q_i)^2}</script></li></ul></li><li><p>데이터 간 평균 거리(avg distance, euclidean distance) 유지하려면, 기하급수적으로 많은 데이터 필요($\text{dim}^n$)</p></li><li><p>Poor Prediction</p><ul><li>hard to find pattern $\rightarrow$ cannot train similar features</li><li>lots of Params, but almost useless $\rightarrow$ likely to overtif to noise</li></ul></li></ul><h3 id="2-해결책"><a href="#2-해결책" class="headerlink" title="2) 해결책"></a>2) 해결책</h3><ul><li>Feature Selection</li><li>PCA(주성분, 잠재변수latent variable)<ul><li>데이터 분포에서 variance가 큰 방향의 벡터에 데이터를 정사영</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 차원의저주 </tag>
            
            <tag> Curse_of_Dimensionality </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Math] 고유값 분해 (Eigen Value Decomposition)</title>
      <link href="/2019/02/13/Recap_evdok/"/>
      <url>/2019/02/13/Recap_evdok/</url>
      
        <content type="html"><![CDATA[<h1 id="고유값-분해-Eigen-Value-Decomposition"><a href="#고유값-분해-Eigen-Value-Decomposition" class="headerlink" title="고유값 분해(Eigen Value Decomposition)"></a>고유값 분해(Eigen Value Decomposition)</h1><a id="more"></a><ul><li>정방행렬 B에 대해$Bv = \lambda v$ 를 만족하는 고유값$\lambda$, 벡터$v$를 찾는 작업</li><li>즉, 선형변환B에 의한 결과가 자기자신의 상수배가 되는, 0이 아닌 벡터(고유벡터)를 구하는 작업<ul><li>고유벡터 $v$: 선형변환 B에 대해 방향이 보존되는 방향벡터<ul><li>고유벡터간 orthogonal</li></ul></li><li>고유값 $\lambda$: 벡터 크기 스케일링 정도</li></ul></li></ul><h2 id="대각화"><a href="#대각화" class="headerlink" title="대각화"></a>대각화</h2><ul><li>고유벡터행렬V로 행렬A를 표현<script type="math/tex; mode=display">A = V \Lambda V^T</script></li></ul><h3 id="예제-아래-행렬B를-고유값-분해-하시오"><a href="#예제-아래-행렬B를-고유값-분해-하시오" class="headerlink" title="예제: 아래 행렬B를 고유값 분해 하시오"></a>예제: 아래 행렬B를 고유값 분해 하시오</h3><script type="math/tex; mode=display">B =\begin{bmatrix}2 & 3 \\2 & 1\end{bmatrix}</script><ul><li>$Bv = \lambda v$ 증명하시오</li></ul><h3 id="1-np-linalg-eig"><a href="#1-np-linalg-eig" class="headerlink" title="1) np.linalg.eig"></a>1) <code>np.linalg.eig</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">B = np.array([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">             [<span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line">B</span><br></pre></td></tr></table></figure><pre><code>array([[2, 3],       [2, 1]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w, v = np.linalg.eig(B)</span><br></pre></td></tr></table></figure><h3 id="2-eigen-val-amp-vec"><a href="#2-eigen-val-amp-vec" class="headerlink" title="2) eigen val &amp; vec"></a>2) eigen val &amp; vec</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># eigen values</span></span><br><span class="line">w</span><br></pre></td></tr></table></figure><pre><code>array([ 4., -1.])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lambda1 = w[<span class="number">0</span>]</span><br><span class="line">lambda2 = w[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># eigen vectors: normalized</span></span><br><span class="line">v</span><br></pre></td></tr></table></figure><pre><code>array([[ 0.83205029, -0.70710678],       [ 0.5547002 ,  0.70710678]])</code></pre><h3 id="3-manually-calculated-eigen-vec"><a href="#3-manually-calculated-eigen-vec" class="headerlink" title="3) manually calculated eigen vec"></a>3) manually calculated eigen vec</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">v1 = np.array([[<span class="number">3</span>],</span><br><span class="line">               [<span class="number">2</span>]])</span><br><span class="line">v2 = np.array([[<span class="number">-1</span>],</span><br><span class="line">               [<span class="number">1</span>]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">norm1 = np.sqrt(np.dot(v1.T,v1))</span><br><span class="line">norm1 = np.squeeze(norm1)</span><br><span class="line">norm2 = np.sqrt(np.dot(v2.T, v2))</span><br><span class="line">norm2 = np.squeeze(norm2)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">normal_v1 = v1 / norm1</span><br><span class="line">normal_v2 = v2 / norm2</span><br><span class="line">normal_v1</span><br></pre></td></tr></table></figure><pre><code>array([[0.83205029],       [0.5547002 ]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.concatenate([normal_v1, normal_v2], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>array([[ 0.83205029, -0.70710678],       [ 0.5547002 ,  0.70710678]])</code></pre><h3 id="4-Bv-lambda-v"><a href="#4-Bv-lambda-v" class="headerlink" title="4) $Bv = \lambda v$"></a>4) $Bv = \lambda v$</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Bv = lambda v</span></span><br><span class="line">np.dot(B, normal_v1) == lambda1 * normal_v1</span><br><span class="line">np.dot(B, normal_v2) == lambda2 * normal_v2</span><br></pre></td></tr></table></figure><pre><code>array([[ True],       [ True]])</code></pre>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 고유값분해 </tag>
            
            <tag> eigenvalue </tag>
            
            <tag> eigenvector </tag>
            
            <tag> 대각화 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] Make alias</title>
      <link href="/2019/02/11/alias/"/>
      <url>/2019/02/11/alias/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Execute-application-on-Linux"><a href="#1-Execute-application-on-Linux" class="headerlink" title="1) Execute application on Linux"></a>1) Execute application on Linux</h1><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ path/application_name</span><br></pre></td></tr></table></figure><h1 id="2-Execute-app-by-alias"><a href="#2-Execute-app-by-alias" class="headerlink" title="2) Execute app by alias"></a>2) Execute app by alias</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ alias shortcut_key=&quot;path/app&quot;</span><br></pre></td></tr></table></figure><p>eg.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ alias Typora=&quot;/home/henry/Documents/app/Typora-linux-x64/Typora&quot;</span><br></pre></td></tr></table></figure></p><h1 id="3-Use-alias-permanently"><a href="#3-Use-alias-permanently" class="headerlink" title="3) Use alias permanently"></a>3) Use alias permanently</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ gedit ~/.bashrc</span><br><span class="line">~~</span><br><span class="line">and add `alias Typora=&quot;/home/henry/Documents/app/Typora-linux-x64/Typora&quot;`</span><br><span class="line">at the bottom.</span><br><span class="line">After then,</span><br></pre></td></tr></table></figure><p>$ source ~/.bashrc<br>~~~</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> alias </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Math] Singular Value Decomposition, SVD</title>
      <link href="/2019/02/11/Recap_SVD/"/>
      <url>/2019/02/11/Recap_SVD/</url>
      
        <content type="html"><![CDATA[<h1 id="특이값-분해-Singular-Value-Decomposition-SVD"><a href="#특이값-분해-Singular-Value-Decomposition-SVD" class="headerlink" title="특이값 분해(Singular Value Decomposition, SVD)"></a>특이값 분해(Singular Value Decomposition, SVD)</h1><a id="more"></a><ul><li>활용: 1) 차원감소 2) 압축 3) 잠재변수 분석 4) PCA보다 계산 속도 빠름<script type="math/tex; mode=display">A = U \Sigma V^T ( m \times n)</script></li><li>$U: \text{left singular vector}, orthogonal, m \times m, \text{eigen-vector of } AA^T$</li><li>$V: \text{right singular vector}, orthogonal, n \times n, \text{eigen-vector of } A^TA$</li><li>$\text{The diagonal entries of } \Sigma: \text{singular values of A} A$<ul><li>$\text{singular-value}^2$ = eigen-value</li></ul></li></ul><h2 id="예제-영화-평점"><a href="#예제-영화-평점" class="headerlink" title="예제) 영화 평점"></a>예제) 영화 평점</h2><ul><li>A ~ E 영화 5편(column)에 관객 7명(index)이 평점 부여</li><li>영화는 SF, Romance 두가지 부류</li><li>관객들은 SF, Romance에 대한 기호가 확실</li></ul><h3 id="1-SVD"><a href="#1-SVD" class="headerlink" title="1) SVD"></a>1) SVD</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">             [<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">             [<span class="number">4</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">             [<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">             [<span class="number">0</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">             [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">5</span>,<span class="number">5</span>],</span><br><span class="line">             [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">2</span>]])</span><br><span class="line">A</span><br></pre></td></tr></table></figure><pre><code>array([[1, 1, 1, 0, 0],       [3, 3, 3, 0, 0],       [4, 4, 4, 0, 0],       [5, 5, 5, 0, 0],       [0, 2, 0, 4, 4],       [0, 0, 0, 5, 5],       [0, 1, 0, 2, 2]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">idx1 = [<span class="string">'SF'</span>] * <span class="number">4</span></span><br><span class="line">idx2 = [<span class="string">'Romance'</span>] * <span class="number">3</span></span><br><span class="line">idx = idx1 + idx2</span><br><span class="line">idx_ = [idx + <span class="string">" lover"</span> + str(i) <span class="keyword">for</span> i, idx <span class="keyword">in</span> enumerate(idx, <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">col = list(<span class="string">'ABCDE'</span>)</span><br><span class="line">col_ = [<span class="string">"movie_"</span> + idx <span class="keyword">for</span> idx <span class="keyword">in</span> col]</span><br><span class="line">col_</span><br></pre></td></tr></table></figure><pre><code>[&#39;movie_A&#39;, &#39;movie_B&#39;, &#39;movie_C&#39;, &#39;movie_D&#39;, &#39;movie_E&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mov = pd.DataFrame(A,columns=col_, index=idx_)</span><br><span class="line">mov</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A</th>      <th>movie_B</th>      <th>movie_C</th>      <th>movie_D</th>      <th>movie_E</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>1</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>SF lover2</th>      <td>3</td>      <td>3</td>      <td>3</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>SF lover3</th>      <td>4</td>      <td>4</td>      <td>4</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>SF lover4</th>      <td>5</td>      <td>5</td>      <td>5</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>0</td>      <td>2</td>      <td>0</td>      <td>4</td>      <td>4</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>0</td>      <td>0</td>      <td>0</td>      <td>5</td>      <td>5</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>0</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>2</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">left_s, v, right_s = np.linalg.svd(A)</span><br><span class="line">print(<span class="string">" Original Matrix A: &#123;&#125; \n Left_SV: &#123;&#125; \n Right_SV: &#123;&#125; \n Singualr Values: &#123;&#125;"</span>\</span><br><span class="line">      .format(A.shape, left_s.shape, right_s.shape, v.shape))</span><br></pre></td></tr></table></figure><pre><code> Original Matrix A: (7, 5) Left_SV: (7, 7) Right_SV: (5, 5) Singualr Values: (5,)</code></pre><hr><h3 id="2-Number-of-Singular-Values"><a href="#2-Number-of-Singular-Values" class="headerlink" title="2) Number of Singular Values"></a>2) Number of Singular Values</h3><ul><li>주성분1, 2가 data의 94% 설명</li><li>영화 5편을 2개 부류로 나눌 수 있음</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SVD = pd.DataFrame(v, columns=[<span class="string">'Singular values'</span>], index=np.arange(<span class="number">1</span>,<span class="number">6</span>))</span><br><span class="line">SVD[<span class="string">'Portion'</span>] = round(SVD / SVD.sum(), <span class="number">3</span>)</span><br><span class="line">SVD[<span class="string">'Portion_cum'</span>] = SVD[<span class="string">'Portion'</span>].cumsum()</span><br><span class="line">SVD</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Singular values</th>      <th>Portion</th>      <th>Portion_cum</th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>1.248101e+01</td>      <td>0.535</td>      <td>0.535</td>    </tr>    <tr>      <th>2</th>      <td>9.508614e+00</td>      <td>0.407</td>      <td>0.942</td>    </tr>    <tr>      <th>3</th>      <td>1.345560e+00</td>      <td>0.058</td>      <td>1.000</td>    </tr>    <tr>      <th>4</th>      <td>3.046427e-16</td>      <td>0.000</td>      <td>1.000</td>    </tr>    <tr>      <th>5</th>      <td>0.000000e+00</td>      <td>0.000</td>      <td>1.000</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(SVD[<span class="string">'Portion_cum'</span>])</span><br><span class="line">plt.scatter(<span class="number">2</span>, <span class="number">0.942</span>, marker=<span class="string">'o'</span>, c=<span class="string">'red'</span>, s=<span class="number">100</span>)</span><br><span class="line">plt.xticks(np.arange(<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line">plt.xlabel(<span class="string">'Num of PC'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Cumulative Portion'</span>)</span><br><span class="line">plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="Recap_SVD_files/Recap_SVD_9_0.png" alt="png"></p><h3 id="3-Compared-with-Original-data"><a href="#3-Compared-with-Original-data" class="headerlink" title="3) Compared with Original data"></a>3) Compared with Original data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PC: 2</span></span><br><span class="line">left_s[:,:<span class="number">2</span>]</span><br></pre></td></tr></table></figure><pre><code>array([[-0.13759913, -0.02361145],       [-0.41279738, -0.07083435],       [-0.5503965 , -0.09444581],       [-0.68799563, -0.11805726],       [-0.15277509,  0.59110096],       [-0.07221651,  0.73131186],       [-0.07638754,  0.29555048]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.diag(v)[:<span class="number">2</span>, :<span class="number">2</span>]</span><br></pre></td></tr></table></figure><pre><code>array([[12.48101469,  0.        ],       [ 0.        ,  9.50861406]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">right_s[:<span class="number">2</span>, :]</span><br></pre></td></tr></table></figure><pre><code>array([[-0.56225841, -0.5928599 , -0.56225841, -0.09013354, -0.09013354],       [-0.12664138,  0.02877058, -0.12664138,  0.69537622,  0.69537622]])</code></pre><h4 id="3-1-retored-by-PCA2"><a href="#3-1-retored-by-PCA2" class="headerlink" title="3.1) retored by PCA2"></a>3.1) retored by PCA2</h4><ul><li>if Original Matrix is too sparse, this restored Matrix would be used</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">col_pc2 = [x + <span class="string">'_reversed'</span> <span class="keyword">for</span> x <span class="keyword">in</span> col_]</span><br><span class="line">restore_PC2 = pd.DataFrame(np.linalg.multi_dot([left_s[:,:<span class="number">2</span>], np.diag(v)[:<span class="number">2</span>, :<span class="number">2</span>], right_s[:<span class="number">2</span>, :]]), columns=col_pc2, index=idx_,)</span><br><span class="line">restore_PC2</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A_reversed</th>      <th>movie_B_reversed</th>      <th>movie_C_reversed</th>      <th>movie_D_reversed</th>      <th>movie_E_reversed</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>0.994042</td>      <td>1.011704</td>      <td>0.994042</td>      <td>-0.001327</td>      <td>-0.001327</td>    </tr>    <tr>      <th>SF lover2</th>      <td>2.982126</td>      <td>3.035113</td>      <td>2.982126</td>      <td>-0.003982</td>      <td>-0.003982</td>    </tr>    <tr>      <th>SF lover3</th>      <td>3.976168</td>      <td>4.046818</td>      <td>3.976168</td>      <td>-0.005309</td>      <td>-0.005309</td>    </tr>    <tr>      <th>SF lover4</th>      <td>4.970210</td>      <td>5.058522</td>      <td>4.970210</td>      <td>-0.006636</td>      <td>-0.006636</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>0.360313</td>      <td>1.292165</td>      <td>0.360313</td>      <td>4.080263</td>      <td>4.080263</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>-0.373851</td>      <td>0.734429</td>      <td>-0.373851</td>      <td>4.916721</td>      <td>4.916721</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>0.180157</td>      <td>0.646082</td>      <td>0.180157</td>      <td>2.040132</td>      <td>2.040132</td>    </tr>  </tbody></table></div><h4 id="3-2-Comparing-Original-data-with-Restored-PC2"><a href="#3-2-Comparing-Original-data-with-Restored-PC2" class="headerlink" title="3.2) Comparing Original_data with Restored_PC2"></a>3.2) Comparing Original_data with Restored_PC2</h4><ul><li>Similar with Original data</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.concat([mov, restore_PC2], axis=<span class="number">1</span>)</span><br><span class="line">df.columns=col_ + col_pc2</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A</th>      <th>movie_B</th>      <th>movie_C</th>      <th>movie_D</th>      <th>movie_E</th>      <th>movie_A_reversed</th>      <th>movie_B_reversed</th>      <th>movie_C_reversed</th>      <th>movie_D_reversed</th>      <th>movie_E_reversed</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>1</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0.994042</td>      <td>1.011704</td>      <td>0.994042</td>      <td>-0.001327</td>      <td>-0.001327</td>    </tr>    <tr>      <th>SF lover2</th>      <td>3</td>      <td>3</td>      <td>3</td>      <td>0</td>      <td>0</td>      <td>2.982126</td>      <td>3.035113</td>      <td>2.982126</td>      <td>-0.003982</td>      <td>-0.003982</td>    </tr>    <tr>      <th>SF lover3</th>      <td>4</td>      <td>4</td>      <td>4</td>      <td>0</td>      <td>0</td>      <td>3.976168</td>      <td>4.046818</td>      <td>3.976168</td>      <td>-0.005309</td>      <td>-0.005309</td>    </tr>    <tr>      <th>SF lover4</th>      <td>5</td>      <td>5</td>      <td>5</td>      <td>0</td>      <td>0</td>      <td>4.970210</td>      <td>5.058522</td>      <td>4.970210</td>      <td>-0.006636</td>      <td>-0.006636</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>0</td>      <td>2</td>      <td>0</td>      <td>4</td>      <td>4</td>      <td>0.360313</td>      <td>1.292165</td>      <td>0.360313</td>      <td>4.080263</td>      <td>4.080263</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>0</td>      <td>0</td>      <td>0</td>      <td>5</td>      <td>5</td>      <td>-0.373851</td>      <td>0.734429</td>      <td>-0.373851</td>      <td>4.916721</td>      <td>4.916721</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>0</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>2</td>      <td>0.180157</td>      <td>0.646082</td>      <td>0.180157</td>      <td>2.040132</td>      <td>2.040132</td>    </tr>  </tbody></table></div><h3 id="4-applying-PC1-PC2"><a href="#4-applying-PC1-PC2" class="headerlink" title="4) applying PC1, PC2"></a>4) applying PC1, PC2</h3><ul><li>U(left singular vectors M): user to PCA similarity M</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SVD2 = pd.DataFrame(left_s[:,:<span class="number">2</span>] ,columns=[<span class="string">'PC1'</span>, <span class="string">'PC2'</span>,], index=idx_)</span><br><span class="line">SVD2</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PC1</th>      <th>PC2</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>-0.137599</td>      <td>-0.023611</td>    </tr>    <tr>      <th>SF lover2</th>      <td>-0.412797</td>      <td>-0.070834</td>    </tr>    <tr>      <th>SF lover3</th>      <td>-0.550397</td>      <td>-0.094446</td>    </tr>    <tr>      <th>SF lover4</th>      <td>-0.687996</td>      <td>-0.118057</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>-0.152775</td>      <td>0.591101</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>-0.072217</td>      <td>0.731312</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>-0.076388</td>      <td>0.295550</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 비교: user</span></span><br><span class="line">df2 = pd.concat([mov, SVD2], axis=<span class="number">1</span>)</span><br><span class="line">df2.columns = col_ + list(SVD2.columns)</span><br><span class="line">df2</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A</th>      <th>movie_B</th>      <th>movie_C</th>      <th>movie_D</th>      <th>movie_E</th>      <th>PC1</th>      <th>PC2</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>1</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>-0.137599</td>      <td>-0.023611</td>    </tr>    <tr>      <th>SF lover2</th>      <td>3</td>      <td>3</td>      <td>3</td>      <td>0</td>      <td>0</td>      <td>-0.412797</td>      <td>-0.070834</td>    </tr>    <tr>      <th>SF lover3</th>      <td>4</td>      <td>4</td>      <td>4</td>      <td>0</td>      <td>0</td>      <td>-0.550397</td>      <td>-0.094446</td>    </tr>    <tr>      <th>SF lover4</th>      <td>5</td>      <td>5</td>      <td>5</td>      <td>0</td>      <td>0</td>      <td>-0.687996</td>      <td>-0.118057</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>0</td>      <td>2</td>      <td>0</td>      <td>4</td>      <td>4</td>      <td>-0.152775</td>      <td>0.591101</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>0</td>      <td>0</td>      <td>0</td>      <td>5</td>      <td>5</td>      <td>-0.072217</td>      <td>0.731312</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>0</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>2</td>      <td>-0.076388</td>      <td>0.295550</td>    </tr>  </tbody></table></div><h3 id="5-applying-PC1-PC2"><a href="#5-applying-PC1-PC2" class="headerlink" title="5) applying PC1, PC2"></a>5) applying PC1, PC2</h3><ul><li>movie to PC<ul><li>movie_A heavily corresponds to PC</li><li>movie_B heavily corresponds to PC</li><li>$\dots$</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">col_pca = [x + <span class="string">"_PC2"</span> <span class="keyword">for</span> x <span class="keyword">in</span> col_]</span><br><span class="line">df3 = pd.DataFrame(right_s[:<span class="number">2</span>,:], index=[<span class="string">'PC1'</span>, <span class="string">'PC2'</span>], columns=col_pca)</span><br><span class="line">df3</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A_PC2</th>      <th>movie_B_PC2</th>      <th>movie_C_PC2</th>      <th>movie_D_PC2</th>      <th>movie_E_PC2</th>    </tr>  </thead>  <tbody>    <tr>      <th>PC1</th>      <td>-0.562258</td>      <td>-0.592860</td>      <td>-0.562258</td>      <td>-0.090134</td>      <td>-0.090134</td>    </tr>    <tr>      <th>PC2</th>      <td>-0.126641</td>      <td>0.028771</td>      <td>-0.126641</td>      <td>0.695376</td>      <td>0.695376</td>    </tr>  </tbody></table></div><h4 id="4-Wrap-up"><a href="#4-Wrap-up" class="headerlink" title="4) Wrap-up"></a>4) Wrap-up</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># user to PC</span></span><br><span class="line">SVD2</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PC1</th>      <th>PC2</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>-0.137599</td>      <td>-0.023611</td>    </tr>    <tr>      <th>SF lover2</th>      <td>-0.412797</td>      <td>-0.070834</td>    </tr>    <tr>      <th>SF lover3</th>      <td>-0.550397</td>      <td>-0.094446</td>    </tr>    <tr>      <th>SF lover4</th>      <td>-0.687996</td>      <td>-0.118057</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>-0.152775</td>      <td>0.591101</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>-0.072217</td>      <td>0.731312</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>-0.076388</td>      <td>0.295550</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># movie to PC</span></span><br><span class="line">df3</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A_PC2</th>      <th>movie_B_PC2</th>      <th>movie_C_PC2</th>      <th>movie_D_PC2</th>      <th>movie_E_PC2</th>    </tr>  </thead>  <tbody>    <tr>      <th>PC1</th>      <td>-0.562258</td>      <td>-0.592860</td>      <td>-0.562258</td>      <td>-0.090134</td>      <td>-0.090134</td>    </tr>    <tr>      <th>PC2</th>      <td>-0.126641</td>      <td>0.028771</td>      <td>-0.126641</td>      <td>0.695376</td>      <td>0.695376</td>    </tr>  </tbody></table></div><hr><p>reference</p><ul><li><a href="https://datascienceschool.net/view-notebook/30055dc68e8f4db0b7f6e4b56a571d52/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/30055dc68e8f4db0b7f6e4b56a571d52/</a></li><li><a href="https://www.youtube.com/watch?v=P5mlg91as1c&amp;t=490s" target="_blank" rel="noopener">https://www.youtube.com/watch?v=P5mlg91as1c&amp;t=490s</a></li></ul><p>질문</p><ul><li>왜 고유값이 설명력의 ‘양’을 대변하는지</li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SVD </tag>
            
            <tag> 압축 </tag>
            
            <tag> 차원감소 </tag>
            
            <tag> 잠재변수분석LAV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Stat]누적밀도함수cdf &amp; 확률밀도함수pdf</title>
      <link href="/2019/02/08/cdf-pdf/"/>
      <url>/2019/02/08/cdf-pdf/</url>
      
        <content type="html"><![CDATA[<h1 id="1-확률모형-probability-model"><a href="#1-확률모형-probability-model" class="headerlink" title="1. 확률모형 probability model"></a>1. 확률모형 probability model</h1><a id="more"></a><ul><li>Mathmatical representation of a random phenomenon</li><li>be defined by its <strong>sample space</strong>, <strong>events</strong> within the sample spaace, and <strong>probabilities</strong> associated with each event</li><li>Data generator<ul><li>분포distribution 특성이 같은 데이터를 만듦</li><li>데이터 생성과정이 수학적으로 기술될 수 있음</li></ul></li></ul><h1 id="2-확률변수"><a href="#2-확률변수" class="headerlink" title="2. 확률변수"></a>2. 확률변수</h1><ul><li>$\omega \in \Omega \xrightarrow{Random Variable} x \in R$</li><li>$X_{Random Variable}(\omega) = x (x \in R)$<ul><li>확률이 정의된 <strong>표본공간의 모든 표본</strong>을 <strong>실수인 숫자</strong>로 바꾸는 <strong>함수</strong></li></ul></li><li>cf 참고<ul><li>표본공간Sample space: 가능한 모든 표본의 집합</li><li>확률표본Probabilistic/Random sample: 확률적 문제에서 발생가능한 하나의 현상/경우<ul><li>eg. 동전 앞면 또는 뒷면</li></ul></li></ul></li></ul><h1 id="3-확률분포함수"><a href="#3-확률분포함수" class="headerlink" title="3. 확률분포함수"></a>3. 확률분포함수</h1><ul><li>확률분포probability distribution: 어떤 사건에 어느 정도의 <strong>확률이 할당</strong>되어있는지 묘사한 정보</li><li>기술하는 방법: <strong>1) 누적분포함수cdf 2) 확률밀도함수pdf 3) 확률질량함수pmf</strong></li></ul><h2 id="1-누적분포함수-cumulative-distribution-function-cdf"><a href="#1-누적분포함수-cumulative-distribution-function-cdf" class="headerlink" title="1) 누적분포함수 cumulative distribution function, cdf"></a>1) 누적분포함수 cumulative distribution function, cdf</h2><ul><li>$F(x) = P(S_x) = P(\{ X \le x\ \})$<ul><li>$S_x = \{ -\infty \le X \le x\}$</li></ul></li><li>단조증가</li><li><strong>y</strong>: 확률</li><li>참고<ul><li>단순구간사건: $A = \{a \le x \le b \}$</li><li>확률: $P(A) = P(\{a \le x \le b \}) = P(a, b) = P(-\infty, b) - P(-\infty, a)$</li></ul></li></ul><h2 id="2-확률밀도함수-probability-denstiy-function-pdf"><a href="#2-확률밀도함수-probability-denstiy-function-pdf" class="headerlink" title="2) 확률밀도함수 probability denstiy function, pdf"></a>2) 확률밀도함수 probability denstiy function, pdf</h2><ul><li>cdf의 미분: $f(x) = \dfrac{dF(x)}{dx} $</li><li><strong>y</strong>: cdf 특정 구간의 기울기 = 특정한 구간 확률의 상대적 높이</li></ul><p>reference</p><ul><li><a href="https://datascienceschool.net/view-notebook/c46ce2d2a60d48edbc7c3e6e71394c26/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/c46ce2d2a60d48edbc7c3e6e71394c26/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> cdf </tag>
            
            <tag> pdf </tag>
            
            <tag> random_variable </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Stat] p-value</title>
      <link href="/2019/02/08/pvalue/"/>
      <url>/2019/02/08/pvalue/</url>
      
        <content type="html"><![CDATA[<h1 id="1-p-value-유의확률"><a href="#1-p-value-유의확률" class="headerlink" title="1. p-value(유의확률)"></a>1. p-value(유의확률)</h1><a id="more"></a><ul><li><strong>귀무가설이 맞다고 가정했을 떄</strong>, 현재의 검정 통계량과 같은 표본 데이터가 발생할 확률</li><li>즉, 현재 검정통계량과 같거나, <strong>더 극단적인(extrem), 더 희귀한(are) 값</strong>이 나올 확률<ul><li><strong>유의확률이 매우 작으면</strong>, 귀무가설이 맞다는 가정하에서는, 현재 검정 통계량이 발생할 가능성이 매우 낮다는 의미 $\rightarrow$ <strong>귀무가설 기각</strong></li></ul></li></ul><h1 id="2-회귀계수-가중치의-신뢰구간-or-오차범위"><a href="#2-회귀계수-가중치의-신뢰구간-or-오차범위" class="headerlink" title="2. 회귀계수 가중치의 신뢰구간 or 오차범위"></a>2. 회귀계수 가중치의 신뢰구간 or 오차범위</h1><ul><li><p>1) 단일계수 t-test(Single Coefficient t-test)</p><ul><li>검정 통계량: 정규화된 모수오차$\dfrac{\hat{w}_i - 0}{se_i}$</li><li>$H_{0} : 회귀계수 w_i = 0$</li></ul></li><li><p>2) F-검정: 전체 회귀 계수가 모두 의미 있는지 확인</p><ul><li>$H_0 : w_1, \cdots, w_i = 0$</li></ul></li></ul><h1 id="3-표준오차"><a href="#3-표준오차" class="headerlink" title="3. 표준오차"></a>3. 표준오차</h1><ul><li><strong>표본평균의 표준편차</strong>: 모평균과 표본평균 사이에 얼마나 오차가 발생하는가</li><li>모집단에 대한 정보 제공 없음<ul><li>표본표준편차: $s_x = \dfrac{1}{n-1} \sqrt{\sum_{i=1}^n (x_i - \bar{x})^2}$</li><li>표준오차: $s.e(\hat{x}) = \dfrac{s_x}{\sqrt{n}}$</li></ul></li></ul><h1 id="3-p-value-유의할-점"><a href="#3-p-value-유의할-점" class="headerlink" title="3. p-value: 유의할 점"></a>3. p-value: 유의할 점</h1><ul><li>데이터가 많아지면, 표준오차는 작아짐</li><li>p-value는 data와 null hypothesis의 거리를 측정하는 것이므로 데이터가 많아지면 p-value는 siginificant로 나옴<ul><li>예컨대, $\hat{\beta} = 1, SE( \beta ) = 0.2$라면 $\hat{beta}$은 0으로부터 SE단위(0.2) 5만큼 떨어져 있는 것  </li></ul></li></ul><hr><p>reference</p><ul><li><a href="http://www.galitshmueli.com/system/files/Largesample-12-6-2012.pdf" target="_blank" rel="noopener">http://www.galitshmueli.com/system/files/Largesample-12-6-2012.pdf</a></li><li><a href="https://stats.stackexchange.com/questions/197676/why-do-t-test-use-standard-error-and-not-standard-deviation" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/197676/why-do-t-test-use-standard-error-and-not-standard-deviation</a></li><li><a href="https://datascienceschool.net/view-notebook/743cdedec523447a907b2b0abda45533/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/743cdedec523447a907b2b0abda45533/</a><br>질문</li><li>pvalue문제 어떻게 해결</li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Stat </tag>
            
            <tag> Study </tag>
            
            <tag> p-value </tag>
            
            <tag> 표준오차 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] 일반 선형확률과정 AR(4)</title>
      <link href="/2019/02/04/Recap_TimeSeries_AR(4)ok/"/>
      <url>/2019/02/04/Recap_TimeSeries_AR(4)ok/</url>
      
        <content type="html"><![CDATA[<h2 id="일반-선형확률과정-모형-general-linear-process-model"><a href="#일반-선형확률과정-모형-general-linear-process-model" class="headerlink" title="일반 선형확률과정 모형(general linear process model)"></a>일반 선형확률과정 모형(general linear process model)</h2><a id="more"></a><h3 id="2-AR모형"><a href="#2-AR모형" class="headerlink" title="2) AR모형"></a>2) AR모형</h3><ul><li>MA모형 사용시, lag이 증가해도 $acf \ne 0$인 상태가 너무 오래 지속되는 경우(즉, q가 너무 커짐)</li><li>현재 값이, <strong>과거 자기 자신</strong>의 영향 <strong>직접</strong> 받음 + <strong>먼 과거의 백색잡음</strong> 영향 지속<ul><li>cf. MA모형: White noise를 통한 간접 관계</li></ul></li></ul><script type="math/tex; mode=display">Y_t = -\phi_1 Y_{t-1} - \phi_2 Y_{t-2} - \cdots</script><ul><li><strong>단, 계수$\phi$의 제한 조건 존재(에 따라 다름)</strong></li></ul><h3 id="예-AR-1"><a href="#예-AR-1" class="headerlink" title="예) AR(1)"></a>예) AR(1)</h3><p>$\phi(L)Y_t =  \epsilon_t$</p><p>$Y_t = -\phi Y_{t-1} + \epsilon_t$</p><p>$Y_t = \epsilon_t - \phi \epsilon_{t-1} - \phi^2 \epsilon_{t-2} - \cdots$</p><ul><li><p>$-1&lt;\phi&lt;1$</p><ul><li>cf. MA(1): $Y_t = \epsilon_t + \theta_1 \epsilon_{t-1}$</li></ul></li><li>$E[Y_t] = 0$</li><li>$Var[Y_t] = \gamma_0 = \dfrac{\sigma_{\epsilon}^2}{1-\phi^2}$</li><li>$\gamma_k = (- \phi)^k \dfrac{\sigma_{\epsilon^2}}{1-\phi^2}$ <strong>즉, AR(1)모델에서, lag=k일 때 자기공분산함수</strong><ul><li>$\rightarrow$ MA와 달리 <strong>먼 과거의 백색잡음 영향 계속 남아있음</strong></li><li>cf. <strong>MA(q)는 lag=k &gt; q이면 무조건 0</strong></li></ul></li><li>acf $\rho_k=\dfrac{\gamma_k}{\gamma_0}=(-\phi)^k \rightarrow \phi&lt;0$ 그래프는 진동</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># acf rho 예시</span></span><br><span class="line">lag_k = np.arange(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">phi = <span class="number">0.9</span></span><br><span class="line">acf = phi ** lag_k</span><br><span class="line">plt.stem(acf)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">phi = <span class="number">0.2</span></span><br><span class="line">acf = phi ** lag_k</span><br><span class="line">plt.stem(acf)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">phi = - <span class="number">0.9</span></span><br><span class="line">acf = phi ** lag_k</span><br><span class="line">plt.stem(acf)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">phi = - <span class="number">0.2</span></span><br><span class="line">acf = phi ** lag_k</span><br><span class="line">plt.stem(acf)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_AR%284%29ok_files/Recap_TimeSeries_AR%284%29ok_1_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AR(1) 샘플링</span></span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">phi = <span class="number">-0.9</span></span><br><span class="line">ar = [<span class="number">1</span>, -phi]; ma = [<span class="number">1</span>]</span><br><span class="line">p1 = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">y1 = p1.generate_sample(<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(y1, <span class="string">'o-'</span>)</span><br><span class="line">plt.title(<span class="string">"AR(1)"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_AR%284%29ok_files/Recap_TimeSeries_AR%284%29ok_2_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AR(1) acf (phi: -0.9)</span></span><br><span class="line">plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.stem(p1.acf(<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">212</span>)</span><br><span class="line">sm.graphics.tsa.plot_acf(y1, lags=<span class="number">100</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_AR%284%29ok_files/Recap_TimeSeries_AR%284%29ok_3_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AR(2) acf</span></span><br><span class="line"><span class="comment"># 자기상관 계수 0 나올 수 있음 -&gt; 진동 중 부호 바뀌는 지점</span></span><br><span class="line">phi1 = <span class="number">0.9</span>; phi2 = <span class="number">-0.6</span></span><br><span class="line">ar=[<span class="number">1</span>, -phi1, -phi2]; ma=[<span class="number">1</span>]</span><br><span class="line">p1 = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">y1 = p1.generate_sample(<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.stem(p1.acf(<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">212</span>)</span><br><span class="line">sm.graphics.tsa.plot_acf(y1, lags=<span class="number">100</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_AR%284%29ok_files/Recap_TimeSeries_AR%284%29ok_4_0.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 일반선형확률과정 </tag>
            
            <tag> AR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] 일반 선형확률과정 ARMA / ARIMA(5)</title>
      <link href="/2019/02/04/Recap_TimeSeries_ARMA_ARIMA(5)ok/"/>
      <url>/2019/02/04/Recap_TimeSeries_ARMA_ARIMA(5)ok/</url>
      
        <content type="html"><![CDATA[<h2 id="일반-선형확률과정-모형-general-linear-process-model"><a href="#일반-선형확률과정-모형-general-linear-process-model" class="headerlink" title="일반 선형확률과정 모형(general linear process model)"></a>일반 선형확률과정 모형(general linear process model)</h2><a id="more"></a><h3 id="3-ARMA-p-q"><a href="#3-ARMA-p-q" class="headerlink" title="3) ARMA(p, q)"></a>3) ARMA(p, q)</h3><ul><li>AR과 구분 불가 cf. AR 간에도 p차 구분불가</li><li>MA &amp; AR은 구분 가능</li></ul><script type="math/tex; mode=display">Y_t = -\phi_1 Y_{t-1} -\phi_2 Y_{t-2} - \phi_3 Y_{t-3} - \cdots + \epsilon_t \\+ \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}</script><ul><li><p>AR(p)와 MA(q) 성질 모두 가지는 모형</p><ul><li>$AR(p): Y_t = -\phi_1 Y_{t-1} - \phi_2 Y_{t-2} - \cdots$</li><li>$MA(q): Y_t = \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}$</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">ARMA(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment">#샘플링</span></span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">phi = <span class="number">0.7</span>; theta = <span class="number">-0.4</span></span><br><span class="line">ar=[<span class="number">1</span>, -phi];ma=[<span class="number">1</span>, theta]</span><br><span class="line">p1 = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">y1 = p1.generate_sample(<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">411</span>)</span><br><span class="line">plt.plot(y1, <span class="string">'o-'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">412</span>)</span><br><span class="line">plt.stem(p1.acf(<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">413</span>)</span><br><span class="line">sm.graphics.tsa.plot_acf(y1, lags=<span class="number">100</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">414</span>)</span><br><span class="line">sm.graphics.tsa.plot_pacf(y1, lags=<span class="number">100</span>, ax=ax, method=<span class="string">'ywm'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_ARMA_ARIMA%285%29ok_files/Recap_TimeSeries_ARMA_ARIMA%285%29ok_1_0.png" alt=""><br><img src="/Recap_TimeSeries_ARMA_ARIMA%285%29ok_files/pacf.png" alt=""></p><h3 id="4-ARIMA-모형-비정상과정"><a href="#4-ARIMA-모형-비정상과정" class="headerlink" title="4) ARIMA 모형: 비정상과정"></a>4) ARIMA 모형: 비정상과정</h3><ul><li>차분한 결과 $\nabla Y_t = Y_t - Y_{t-1}$가 ARMA 모형</li><li>ARIMA(p, d, q): $\nabla^d Y_t = ARMA(p, q) \rightarrow$ d번 차분 후 ARMA</li><li>특징: 자기상관계수 빠르게 감소하지 않음</li><li>ARMA VS ARIMA<ul><li>특성방정식의 해 X=1 유무</li><li>ARMA는 과거 데이터를 반영, ARIMA는 과거 데이터 + 그 추세까지 반 (<a href="https://m.blog.naver.com/bluefish850/220749045909" target="_blank" rel="noopener">참고</a>)<h3 id="4-1-단위근-특성"><a href="#4-1-단위근-특성" class="headerlink" title="4.1) 단위근 특성"></a>4.1) 단위근 특성</h3></li></ul></li><li>$(Y_t - Y_{t-1}) + \phi_1(Y_{t-1} - Y_{t-2}) + \cdots + \phi_p (Y_{t-p} - Y_{t-p-1}) =\\<br>  \epsilon_t + \theta_1 \epsilon_{t-1} + \cdots + \theta_q \epsilon_{t-q}$</li><li>ARIMA(p, 1, q)모형은 특성 방정식 해가 x=1 단위근 가짐</li><li>특성방정식: $(1-x)(1 + \phi_1 x + \cdots + \phi_p x^p)=0$</li></ul><h3 id="4-2-단위근-검정-ADF-Augmented-Dickey-Fuller-test"><a href="#4-2-단위근-검정-ADF-Augmented-Dickey-Fuller-test" class="headerlink" title="4.2) 단위근 검정: ADF(Augmented Dickey-Fuller) test"></a>4.2) 단위근 검정: ADF(Augmented Dickey-Fuller) test</h3><ul><li>DF 일반화</li><li>H0: 적분차수1 이상<ul><li><code>sm.tsa.adfuller</code><ul><li>adf: test statistic</li><li>pvalue: float</li></ul></li></ul></li></ul><h3 id="예-IMA-1-1"><a href="#예-IMA-1-1" class="headerlink" title="예) IMA(1, 1)"></a>예) IMA(1, 1)</h3><ul><li>$Y_t - Y_{t-1} = \epsilon_t - \theta \epsilon_{t-1}$</li><li>$Y_t = \epsilon_t + (1-\theta) \epsilon_{t-1} + (1 - \theta) \epsilon_{t-2} + (1-\theta) \epsilon_{t-3} \cdots +$</li><li>백색잡음의 누적 cumulation</li></ul><h3 id="예-IMA-2-2"><a href="#예-IMA-2-2" class="headerlink" title="예) IMA(2, 2)"></a>예) IMA(2, 2)</h3><ul><li>$(Y_t - Y _{t-1}) - (Y_{t-1} - Y_{t-2}) = \epsilon_t - \theta_1 \epsilon_{t-1} - \theta_2 \epsilon_{t-2}$</li></ul><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#IMA(2,2): theta1 = 1, theta2 = -0.6</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">theta1 = <span class="number">1</span>; theta2 = <span class="number">-0.6</span></span><br><span class="line">ar = [<span class="number">1</span>]; ma=[<span class="number">1</span>, theta1, theta2]</span><br><span class="line">p = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">sample = p.generate_sample(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">y2 = sample.cumsum().cumsum()</span><br><span class="line">y1 = np.diff(y2)</span><br><span class="line">y0 = np.diff(y1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># y0 = sample</span></span><br><span class="line"><span class="comment"># y1 = y0.cumsum()</span></span><br><span class="line"><span class="comment"># y2 = y1.cumsum()</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">313</span>)</span><br><span class="line">plt.title(<span class="string">'IMA(2,1): diff(2)'</span>)</span><br><span class="line">plt.plot(y0, <span class="string">'o-'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">312</span>)</span><br><span class="line">plt.title(<span class="string">'IMA(2,1): diff(1)'</span>)</span><br><span class="line">plt.plot(y1, <span class="string">'o-'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">311</span>)</span><br><span class="line">plt.title(<span class="string">'IMA(2,1): diff(0)'</span>)</span><br><span class="line">plt.plot(y2, <span class="string">'o-'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_ARMA_ARIMA%285%29ok_files/Recap_TimeSeries_ARMA_ARIMA%285%29ok_4_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">ax1 = plt.subplot(<span class="number">313</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(y0, lags=<span class="number">90</span>, ax=ax1)</span><br><span class="line">ax1.set_title(<span class="string">'ACF: IMA(2, 1): diff(2)'</span>)</span><br><span class="line"></span><br><span class="line">ax2 = plt.subplot(<span class="number">312</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(y1, lags=<span class="number">90</span>, ax=ax2)</span><br><span class="line">ax2.set_title(<span class="string">'ACF: IMA(2, 1): diff(1)'</span>)</span><br><span class="line"></span><br><span class="line">ax3 = plt.subplot(<span class="number">311</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(y2, lags=<span class="number">90</span>, ax=ax3)</span><br><span class="line">ax3.set_title(<span class="string">'ACF: IMA(2, 1): diff(0)'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_ARMA_ARIMA%285%29ok_files/Recap_TimeSeries_ARMA_ARIMA%285%29ok_5_0.png" alt=""></p><hr><ul><li>ADF test 예시: y0 -&gt; 귀무가설 기각</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sm.tsa.adfuller(y2)</span><br></pre></td></tr></table></figure><pre><code>(-2.251162211352469, 0.1882029374890175, 8, 91, {&#39;1%&#39;: -3.50434289821397,  &#39;5%&#39;: -2.8938659630479413,  &#39;10%&#39;: -2.5840147047458037}, 307.88958150914243)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sm.tsa.adfuller(y1)</span><br></pre></td></tr></table></figure><pre><code>(-1.7069994687237129, 0.42750979630229596, 12, 86, {&#39;1%&#39;: -3.5087828609430614,  &#39;5%&#39;: -2.895783561573195,  &#39;10%&#39;: -2.5850381719848565}, 307.69019010591194)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sm.tsa.adfuller(y0)</span><br></pre></td></tr></table></figure><pre><code>(-2.5363882098874595, 0.10686979989276602, 6, 91, {&#39;1%&#39;: -3.50434289821397,  &#39;5%&#39;: -2.8938659630479413,  &#39;10%&#39;: -2.5840147047458037}, 305.82342887519786)</code></pre><hr><p>질문</p><ul><li>특성방정식 - 이해 부족</li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 일반선형확률과정 </tag>
            
            <tag> ARMA </tag>
            
            <tag> ARIMA </tag>
            
            <tag> Intergragted </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] 확률과정 및 시계열 이론(1)</title>
      <link href="/2019/02/04/Recap_Time%20series_theory(1)ok/"/>
      <url>/2019/02/04/Recap_Time%20series_theory(1)ok/</url>
      
        <content type="html"><![CDATA[<h1 id="확률과정-Random-process-Stochastic-process"><a href="#확률과정-Random-process-Stochastic-process" class="headerlink" title="확률과정(Random process, Stochastic process):"></a>확률과정(Random process, Stochastic process):</h1><a id="more"></a><ul><li>의미: 확률변수의 순서열(sequence of infinit random variables)</li><li>확률과정$Y = \{\cdots, Y_{-1}, Y_0, Y_{1}, \cdots\}$<ul><li>확률변수$Y_t$는 평행우주 t시간의 표본 generator</li></ul></li><li>시계열 자료는 확률 과정의 표본</li><li>앙상블 평균$E[Y_t]$: <strong>복수의 시계열 자료 표본</strong>에서 특정한 시간 t의 값만 평균(평행우주에서 $y_t$시간 값만 추출)<ul><li>현실세계는 불가능: 현실세계가 표본 하나</li><li>앙상블 평균 추정의 조건<ul><li>정상과정(stationary process) &amp; 에르고딕 과정(ergodic process)</li></ul></li></ul></li></ul><h2 id="1-확률과정의-기댓값-자기공분산-자기상관계수"><a href="#1-확률과정의-기댓값-자기공분산-자기상관계수" class="headerlink" title="1. 확률과정의 기댓값, 자기공분산, 자기상관계수"></a>1. 확률과정의 기댓값, 자기공분산, 자기상관계수</h2><ul><li>‘자기(auto)’: <strong>표본 하나의 set 내</strong>에서의 cov &amp; cor</li><li>확률과정 기댓값: $\mu_t = E[Y_t]$</li><li>자기공분산(auto-covariance): 방향 &amp; 거리<ul><li>$\gamma_{t, s}=Cov[Y_t, Y_s]=E[(Y_t - E[Y_t]) \cdot (Y_s - E[Y_s])]$</li></ul></li><li>자기상관계수(auto-correlation): 방향<ul><li>$\rho_{t,s} = \dfrac{\gamma_{t,s}}{\sqrt{\gamma_t \gamma_s}}= Corr[Y_t, Y_s] = \dfrac{Cov[Y_t, Y_s]}{\sqrt{Var[Y_t] \cdot Var[Y_s]}} \leq 1$</li></ul></li></ul><h2 id="2-정상확률과정"><a href="#2-정상확률과정" class="headerlink" title="2. 정상확률과정"></a>2. 정상확률과정</h2><ul><li>$Y_1, Y_2, \cdots$의 평균, 표준오차 등이 변하지 않음.</li><li><strong>쉽게 말하자면, 평균, 분산 등 모멘트 공식에 절대시간 t변수가 없고, 시차 k변수가 존재(이후 MA, AR 모델 등에서 확인)</strong></li><li>즉, 에르고딕 성질에 의해, 표본들이 하나의 generator에서 생성됨</li></ul><h3 id="2-1-자기공분산-시간-변수의-차이lag-k-에만-의존"><a href="#2-1-자기공분산-시간-변수의-차이lag-k-에만-의존" class="headerlink" title="2.1. 자기공분산: 시간 변수의 차이lag $k$에만 의존"></a>2.1. 자기공분산: 시간 변수의 차이lag $k$에만 의존</h3><p>$\gamma_{t, t+k} = \gamma_{0,k} \triangleq \gamma_k$</p><h3 id="2-2-자기상관계수-시간-변수의-차이lag-k-에만-의존"><a href="#2-2-자기상관계수-시간-변수의-차이lag-k-에만-의존" class="headerlink" title="2.2. 자기상관계수: 시간 변수의 차이lag $k$에만 의존"></a>2.2. 자기상관계수: 시간 변수의 차이lag $k$에만 의존</h3><p>$\rho_{t, t+k} = \rho_{0,k} \triangleq \rho_k = \dfrac{\gamma_k}{\gamma_0}$</p><ul><li>eg) ACF of AR(1): $\rho_k=\dfrac{\gamma_k}{\gamma_0}=(-\phi)^k \rightarrow \phi&lt;0$ 그래프는 진동</li></ul><h3 id="2-3-정상확률과정-특징"><a href="#2-3-정상확률과정-특징" class="headerlink" title="2.3 정상확률과정 특징"></a>2.3 정상확률과정 특징</h3><ul><li>확률과정 특성은 확률변수$Y_t$의 결합확률밀도함수 사용</li><li>협의의 정상확률과정(strictly stationary process): 모든 모멘트가 ‘절대시간’에 의존하지 않고 시차lag에만 의존<ul><li>$E[Y_t Y_{t+k_1} \cdots] = E[Y_s Y_{s+k_1 \cdots}]$</li></ul></li><li>광의의 정상확률과정(weak stationary process)<ul><li>1, 2차 모멘텀에 대해서만 ‘절대시간’ 의존하지 않음</li><li>$E[Y_t] = E[Y_s] = \mu$</li><li>$E[Y_t Y_{t+k}] = E[Y_s Y_{s+k}]$</li></ul></li><li>순수하게 백색잡음이라면, 어떤 시차lag에서도 자기상관$\rho$는 1</li></ul><h2 id="3-에르고딕-성질"><a href="#3-에르고딕-성질" class="headerlink" title="3. 에르고딕 성질"></a>3. 에르고딕 성질</h2><ul><li>정상확률 과정의 확률변수들($Y_t, Y_{t+1}, \cdots$)은 무조건부 분포 동일</li><li>따라서 현실 시계열 데이터를 <strong>하나의 분포</strong>에서 나온 <strong>표본 데이터</strong>로 간주</li><li>moment method(점 추정)에 따라 모수추정 가능: $\mu = E[X] = \bar{x}$</li></ul><h2 id="4-백색-잡음-white-noise"><a href="#4-백색-잡음-white-noise" class="headerlink" title="4. 백색 잡음 white noise"></a>4. 백색 잡음 white noise</h2><ul><li>확률과정 $\epsilon = \{\epsilon_1, \epsilon_2, \cdots\}$</li><li>$\epsilon_t \sim i.i.d$(independent and identically distributed)</li></ul><h2 id="5-랜덤-워크-Random-walk"><a href="#5-랜덤-워크-Random-walk" class="headerlink" title="5. 랜덤 워크 Random walk"></a>5. 랜덤 워크 Random walk</h2><ul><li>IMA(1,0)</li><li>과거 백색잡음의 cumsum</li></ul><hr><h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><h1 id="A1-Non-stationarity"><a href="#A1-Non-stationarity" class="headerlink" title="A1. Non-stationarity"></a>A1. Non-stationarity</h1><h2 id="Trend-amp-Seasonality"><a href="#Trend-amp-Seasonality" class="headerlink" title="Trend &amp; Seasonality"></a>Trend &amp; Seasonality</h2><ul><li>Trend</li><li>Seasonality: additive or multiplicative</li></ul><h1 id="A2-Stationarity"><a href="#A2-Stationarity" class="headerlink" title="A2. Stationarity"></a>A2. Stationarity</h1><h2 id="A-white-noise-series-sequence-of-random-numbers"><a href="#A-white-noise-series-sequence-of-random-numbers" class="headerlink" title="A white noise series(sequence of random numbers)"></a>A white noise series(sequence of random numbers)</h2><ul><li>a flat looking series</li><li>no trend</li><li>no constant variance over time</li><li>no a constant autocorrelation structure over time</li><li>no periodic fluctuations</li></ul><h1 id="A3-STL-Seasonal-and-Trend-Decomposition-using-Loess"><a href="#A3-STL-Seasonal-and-Trend-Decomposition-using-Loess" class="headerlink" title="A3. STL(Seasonal and Trend Decomposition using Loess)"></a>A3. STL(Seasonal and Trend Decomposition using Loess)</h1><h1 id="A4-Application"><a href="#A4-Application" class="headerlink" title="A4. Application"></a>A4. Application</h1><ul><li>explanation</li><li>control: identify anomal</li><li>forecasting</li></ul><h1 id="A5-Remove-trend-and-seasonality"><a href="#A5-Remove-trend-and-seasonality" class="headerlink" title="A5. Remove trend and seasonality"></a>A5. Remove trend and seasonality</h1><script type="math/tex; mode=display">X_t = \mu_t + S_t + Z_t</script><ul><li>$\mu_t$ trend component: 추정 방법 3가지<ul><li><strong>LSE</strong>: deterministic $\mu_t = f(t)$</li><li><strong>Smoothing by rolling mean</strong>: stocahstic, ARIMA</li><li><strong>Differencing</strong>: stocahstic, ARIMA</li></ul></li><li>$S_t$: seasonal component</li><li>$Z_t$: random noise component</li></ul><hr><h2 id="예시-CO2-Data"><a href="#예시-CO2-Data" class="headerlink" title="예시) CO2 Data"></a>예시) CO2 Data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">data = sm.datasets.get_rdataset(<span class="string">"CO2"</span>, package=<span class="string">"datasets"</span>)</span><br><span class="line">df = data.data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yearfraction2datetime</span><span class="params">(yearfraction, startyear=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> datetime</span><br><span class="line">    <span class="keyword">import</span> dateutil</span><br><span class="line">    year = int(yearfraction) + startyear</span><br><span class="line">    month = int(round(<span class="number">12</span> * (yearfraction - year)))</span><br><span class="line">    delta = dateutil.relativedelta.relativedelta(months=month)</span><br><span class="line">    date = datetime.datetime(year, <span class="number">1</span>, <span class="number">1</span>) + delta</span><br><span class="line">    <span class="keyword">return</span> date</span><br><span class="line"></span><br><span class="line">df[<span class="string">"datetime"</span>] = df.time.map(yearfraction2datetime)</span><br><span class="line">df[<span class="string">"month"</span>] = df.datetime.dt.month</span><br><span class="line">df.tail()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>time</th>      <th>value</th>      <th>datetime</th>      <th>month</th>    </tr>  </thead>  <tbody>    <tr>      <th>463</th>      <td>1997.583333</td>      <td>362.57</td>      <td>1997-08-01</td>      <td>8</td>    </tr>    <tr>      <th>464</th>      <td>1997.666667</td>      <td>360.24</td>      <td>1997-09-01</td>      <td>9</td>    </tr>    <tr>      <th>465</th>      <td>1997.750000</td>      <td>360.83</td>      <td>1997-10-01</td>      <td>10</td>    </tr>    <tr>      <th>466</th>      <td>1997.833333</td>      <td>362.49</td>      <td>1997-11-01</td>      <td>11</td>    </tr>    <tr>      <th>467</th>      <td>1997.916667</td>      <td>364.34</td>      <td>1997-12-01</td>      <td>12</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(df[<span class="string">'value'</span>])</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7ff3474934e0&gt;]</code></pre><p><img src="/Recap_Time%20series_theory%281%29ok_files/Recap_Time%20series_theory%281%29ok_6_1.png" alt="png"></p><p>질문</p><ul><li>Moving Average, Smoothing, differencing 관계</li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 확률과정 </tag>
            
            <tag> 정상확률과정 </tag>
            
            <tag> 랜덤워크 </tag>
            
            <tag> 백색잡음 </tag>
            
            <tag> ACF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] 비정상 확률과정(2)</title>
      <link href="/2019/02/04/Recap_TimeSeires(2)/"/>
      <url>/2019/02/04/Recap_TimeSeires(2)/</url>
      
        <content type="html"><![CDATA[<h2 id="비정상-확률과정"><a href="#비정상-확률과정" class="headerlink" title="비정상 확률과정"></a>비정상 확률과정</h2><a id="more"></a><ul><li>평균수준이 시간대에 따라 다름<ul><li>-&gt; 결정적Deterministic 추세: regression</li><li>-&gt; 확률적Stochastic 추세: 차분 &amp; ADF</li></ul></li><li>추세Trend 지님<ul><li>-&gt; 결정적 계절추세: regression</li><li>-&gt; 확률적 계절추세: 계절 차분</li></ul></li><li>계절성Seasonality 지님</li><li>분산 변함</li></ul><h3 id="Type-of-Non-stationary-Process"><a href="#Type-of-Non-stationary-Process" class="headerlink" title="Type of Non-stationary Process"></a>Type of Non-stationary Process</h3><ul><li>$E[y_t] \neq 0$ and change with time: 평균수준이</li><li>$Var[y_t]$ change with time -&gt; Ranom Walk</li></ul><h3 id="Random-Walk"><a href="#Random-Walk" class="headerlink" title="Random Walk"></a>Random Walk</h3><ul><li>확률과정</li><li>$\epsilon = \text{white noise}, \alpha = intercept$</li><li>1) $W_t = W_{t-1} + \epsilon_t$: Pure Random Walk</li><li>2) ST: $W_t = \alpha + W_{t-1}+\epsilon_t$: Random Walk with Drift</li><li>3) $W_t = \alpha + W_{t-1} + \beta t + \epsilon_t$: Random Walk with Drift and Derministic Trend  </li><li>cf) DT: $Y_t = \alpha + \beta t + \epsilon_t$: Deterministic Trend<br><img src="time1.gif" alt=""></li></ul><h3 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h3><h4 id="1-A-Random-Walk-with-or-without-a-drift"><a href="#1-A-Random-Walk-with-or-without-a-drift" class="headerlink" title="1. A Random Walk with or without a drift"></a>1. A Random Walk with or without a drift</h4><ul><li>Differencing: $\nabla W_t = W_t - W_{t-1}=\epsilon_t$ or $\alpha + \epsilon_t$</li><li>Detrending:<ul><li>$Y_t = \alpha + \beta t + \epsilon_t \rightarrow \nabla Y_t=$</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">df = sm.datasets.get_rdataset(<span class="string">"CanPop"</span>, package=<span class="string">"carData"</span>).data</span><br><span class="line">df.plot(x=<span class="string">'year'</span>, y=<span class="string">'population'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeires%282%29_files/Recap_TimeSeires%282%29_2_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># df = df.set_index('year')</span></span><br><span class="line">df_diff1 = df - df.shift()</span><br><span class="line">df_diff1.plot()</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f8892339390&gt;</code></pre><p><img src="/Recap_TimeSeires%282%29_files/Recap_TimeSeires%282%29_3_1.png" alt="png"></p><p>reference</p><ul><li>이론: <a href="http://www.irealism.org/xe/datascience/3226" target="_blank" rel="noopener">http://www.irealism.org/xe/datascience/3226</a></li><li>시계열 전반: <a href="https://otexts.com/fpp2/lag-plots.html" target="_blank" rel="noopener">https://otexts.com/fpp2/lag-plots.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 확률과정 </tag>
            
            <tag> 비정상확률과정 </tag>
            
            <tag> 추세 </tag>
            
            <tag> 계절성 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] 일반 선형확률과정 MA(3)</title>
      <link href="/2019/02/04/Recap_TimeSeries_MA(3)ok/"/>
      <url>/2019/02/04/Recap_TimeSeries_MA(3)ok/</url>
      
        <content type="html"><![CDATA[<h2 id="일반-선형확률과정-모형-general-linear-process-model"><a href="#일반-선형확률과정-모형-general-linear-process-model" class="headerlink" title="일반 선형확률과정 모형(general linear process model)"></a>일반 선형확률과정 모형(general linear process model)</h2><a id="more"></a><ul><li>정상확률과정stationary process</li><li><strong>가우시안 백색 잡음</strong>의 <strong>선형 조합</strong><br>$Y_t = \epsilon_t + \psi \epsilon_{t-1} + \cdots$</li><li>과거의 영향력 $\psi_n$은 계속 작아짐: $\sum_{i=1}^{\infty} \psi^2 &lt; \infty$<h3 id="1-MA-모형-과거와-간접적-관련-by-White-noise"><a href="#1-MA-모형-과거와-간접적-관련-by-White-noise" class="headerlink" title="1) MA 모형: 과거와 간접적 관련(by White noise)"></a>1) MA 모형: 과거와 간접적 관련(by White noise)</h3></li><li>MA(q)모형: 백색잡음 현재부터, <strong>q시간 지연된</strong> $\epsilon_{t-q}$까지 q+1개 항의 <strong>선형 가중합</strong><script type="math/tex; mode=display">Y_t = \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}</script></li></ul><h3 id="예-MA-1"><a href="#예-MA-1" class="headerlink" title="예) MA(1)"></a>예) MA(1)</h3><p>$Y_t = \theta(L) \epsilon_t$</p><p>$Y_t = \epsilon_t + \theta_1 \epsilon_{t-1}$</p><p>$Y_{t-1} = \epsilon_{t-1} + \theta_1 \epsilon_{t-2}$</p><ul><li>MA(1)모델<ul><li>$Y_{t}, Y_{t-1}$은 $\epsilon_{t-1}$로 <strong>간접적</strong>연결되어있음</li><li>lag=1 $\rightarrow$ 이므로 $Y_t, Y_{t-1}$ 만 상관관계 존재</li><li>$E[Y_t]=0$</li><li>$Var[Y_t]=\sigma_{\epsilon}^2(1+\theta^2)$</li><li>$Cov[Y_t, Y_{t-1}]=\theta \sigma_{\epsilon}^2$</li><li>$\rightarrow$ <strong>Indepent of “t”: Stationary</strong></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MA(1) 샘플링</span></span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">theta = <span class="number">0.9</span></span><br><span class="line">ar = [<span class="number">1</span>];ma = [<span class="number">1</span>, theta]</span><br><span class="line">p1 =  sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">y1 = p1.generate_sample(<span class="number">100</span>, burnin=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.plot(y1, <span class="string">'o-'</span>)</span><br><span class="line">plt.title(<span class="string">"MA(1)"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_MA%283%29ok_files/Recap_TimeSeries_MA%283%29ok_1_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MA(1) 자기상관계수</span></span><br><span class="line"><span class="comment"># lag=1에서 상관계수 0.5</span></span><br><span class="line">y_t_sample = y1[<span class="number">1</span>:]</span><br><span class="line">y_t_minus1_sample = y1[:<span class="number">-1</span>]</span><br><span class="line">r, p = sp.stats.pearsonr(y_t_sample, y_t_minus1_sample)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>,<span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">311</span>)</span><br><span class="line">sns.scatterplot(y_t_sample, y_t_minus1_sample)</span><br><span class="line">plt.xlabel(<span class="string">"$Y_&#123;t&#125;$"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"$Y_&#123;t-1&#125;$"</span>)</span><br><span class="line">plt.title(<span class="string">"MA(1); lag=1;\n(r=&#123;0:.3f&#125;; p=&#123;1:.3f&#125;)"</span>.format(r, p))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이론적 ACF: lag=1, 2, ..., 11 case</span></span><br><span class="line">plt.subplot(<span class="number">312</span>)</span><br><span class="line">plt.stem(p1.acf(<span class="number">11</span>))</span><br><span class="line">plt.title(<span class="string">'theoretical ACF'</span>)</span><br><span class="line"><span class="comment"># 샘플의 ACF</span></span><br><span class="line">ax = plt.subplot(<span class="number">313</span>)</span><br><span class="line">sm.graphics.tsa.plot_acf(y1, lags=<span class="number">10</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_MA%283%29ok_files/Recap_TimeSeries_MA%283%29ok_2_0.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 일반선형확률과정 </tag>
            
            <tag> MA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] &quot;Brackets&quot;(Snippets) Install(Trouble shooting)</title>
      <link href="/2019/01/31/brack-install/"/>
      <url>/2019/01/31/brack-install/</url>
      
        <content type="html"><![CDATA[<h1 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h1><a id="more"></a><p>Download Brackets file from: <a href="https://github.com/adobe/brackets/releases" target="_blank" rel="noopener">https://github.com/adobe/brackets/releases</a><br>my Brackets ver. : 1.13.64-bit<br><em>It has problem with libcurl3 module which should be replaced with libcurl4.</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp ~/Downloads/Brackets.Release.1.13.64-bit.deb ~/[path]/ #path: dir you wanna install Brackets in</span><br><span class="line">$ cd [path]</span><br></pre></td></tr></table></figure></p><h1 id="Replace-libcurl3-with-liburl4"><a href="#Replace-libcurl3-with-liburl4" class="headerlink" title="Replace libcurl3 with liburl4"></a>Replace libcurl3 with liburl4</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ dpkg-deb -R ./Brackets.Release.1.13.64-bit.deb Brackets</span><br><span class="line">$ vi Brackets/DEBIAN/control</span><br></pre></td></tr></table></figure><p>and <strong>replace <code>libcurl3</code> with <code>libcurl4</code></strong></p><h1 id="Rebuild"><a href="#Rebuild" class="headerlink" title="Rebuild"></a>Rebuild</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ dpkg-deb -b Brackets Brackets-fixed.deb</span><br><span class="line">$ sudo dpkg -i Brackets-fixed.deb</span><br></pre></td></tr></table></figure><p>Maybe you encounter a warning message, but it doesn’t matter.<br>Brackets works well.</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bracket </tag>
            
            <tag> Snippets </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Math] 모수추정</title>
      <link href="/2019/01/30/Recap_%EB%AA%A8%EC%88%98%EC%B6%94%EC%A0%95%EC%9D%98%EB%AF%B8/"/>
      <url>/2019/01/30/Recap_%EB%AA%A8%EC%88%98%EC%B6%94%EC%A0%95%EC%9D%98%EB%AF%B8/</url>
      
        <content type="html"><![CDATA[<h2 id="검정test과-모수추정parameter-estimation"><a href="#검정test과-모수추정parameter-estimation" class="headerlink" title="검정test과 모수추정parameter-estimation"></a>검정test과 모수추정parameter-estimation</h2><a id="more"></a><ul><li>데이터 분석은 확률변수를 파악해가는 과정</li><li><strong>분포검정(distribution test)</strong>: 확률변수가 예상한 확률분포를 따르는지 검정<ul><li>eg. 정규성 검정(normarlity test)</li></ul></li><li><strong>모수검정(parameter test)</strong>: 분포를 정했을 때, 해당 pdf의 계수(coefficient, parameter)이 특정값을 가지는지, 또는 큰지 작은지 확인</li></ul><ul><li><strong>모수추정(parameter-estimation)</strong>: 모수가 어떤 값을 가질 확률이 가장 높은지 추정<ul><li>LSM(Least Squared Method): 가능성이 가장 큰 값 하나만 구함</li><li>MLE(Maximum Likelihood Estimation): 상동</li><li><strong>Bayesian Estimation</strong>: 가능한 모든 모수에 대해 확률 구함<ul><li>모수적(parametric) 방법: 모수 분포를 확률분포로 나타냄. Hyper Prams필요.<ul><li>데이터가 베르누이 분포 -&gt; 모수는 베타분포 따른다고 가정</li><li>데이터가 카테고리 분포 -&gt; 모수는 디리클레 분포 따른다고 가정</li></ul></li><li>비모수적(non-parametric) 방법: 모수의 분포와 동일한 분포를 가지는 숫자 집합 생성. eg. MCMC</li></ul></li></ul></li></ul><hr><h2 id="모수추정parameter-estimation"><a href="#모수추정parameter-estimation" class="headerlink" title="모수추정parameter-estimation"></a>모수추정parameter-estimation</h2><h2 id="1-최소자승법-LSM-least-squre-method"><a href="#1-최소자승법-LSM-least-squre-method" class="headerlink" title="1. 최소자승법 LSM(least squre method)"></a>1. 최소자승법 LSM(least squre method)</h2><ul><li>근사적으로 <strong>구하려는 해</strong>와, <strong>실제 해의 오차의 제곱의 합이 최소</strong>가 되는 해를 구하는 것</li><li><strong>minimizing the sum of squares of the residulas</strong></li></ul><h3 id="1-역행렬-존재"><a href="#1-역행렬-존재" class="headerlink" title="1) 역행렬 존재"></a>1) 역행렬 존재</h3><p>$Xw = y \rightarrow w=X^{-1}y$</p><ul><li>X: 계수행렬</li><li>w: 가중치 벡터(미지수벡터)</li><li>y: 상수벡터</li></ul><h3 id="2-역행렬-존재하지-않음"><a href="#2-역행렬-존재하지-않음" class="headerlink" title="2) 역행렬 존재하지 않음"></a>2) 역행렬 존재하지 않음</h3><p>$Ax=b$</p><ul><li>A: 계수 행렬</li><li>x: 미지수 벡터</li><li>b: 상수벡터<ul><li>선형 연립방정식의 해가 존재하지 않는 경우</li><li>data(방정식) &gt; Dim(미지수 갯수)</li></ul></li><li><strong>2.1) solution: 최소자승법</strong><ul><li>목표:  $Ax \approx b$ 최소화하는 $x$(미지수 벡터) 구하기</li><li>방법:</li><li>2.1.1) $\text{minimize L2 norm}$<ul><li>$Ax-b=e \rightarrow e^Te = ||e||^2=(Ax-b)^T(Ax-b)$</li><li>$x = \text{arg} \min_x e^Te$    </li></ul></li><li>2.1.2) $x = A^+b$ (pseudo inverse)<ul><li>e: 잔차(residual)</li><li>잔차벡터e L2 norm 최소화</li></ul></li></ul></li></ul><hr><h2 id="2-최대-가능도-모수-추정-Maximum-Likelihood-Estimation"><a href="#2-최대-가능도-모수-추정-Maximum-Likelihood-Estimation" class="headerlink" title="2. 최대 가능도 모수 추정(Maximum Likelihood Estimation)"></a>2. 최대 가능도 모수 추정(Maximum Likelihood Estimation)</h2><h3 id="1-hat-theta-ML-arg-max-theta-log-L-theta-x-i"><a href="#1-hat-theta-ML-arg-max-theta-log-L-theta-x-i" class="headerlink" title="1) $\hat{\theta}_{ML} = \arg \max_{\theta} \log{L}(\theta; \{x_i\})$"></a>1) $\hat{\theta}_{ML} = \arg \max_{\theta} \log{L}(\theta; \{x_i\})$</h3><ul><li>추정한 pdf의 변수: $\theta$(params), 상수:$x$(sample)</li><li>표본: <strong>같은 확률분포</strong>에서 나온 독립적 값</li></ul><h3 id="2-가능도-함수-mathcal-L-theta-p-x-vert-theta"><a href="#2-가능도-함수-mathcal-L-theta-p-x-vert-theta" class="headerlink" title="2) 가능도 함수$\mathcal{L}(\theta)=p(x \vert \theta)$"></a>2) 가능도 함수$\mathcal{L}(\theta)=p(x \vert \theta)$</h3><h3 id="3-결합확률밀도함수-mathcal-L-theta-x-1-dots-x-N-prod-i-1-N-p-x-i-theta"><a href="#3-결합확률밀도함수-mathcal-L-theta-x-1-dots-x-N-prod-i-1-N-p-x-i-theta" class="headerlink" title="3) 결합확률밀도함수 $\mathcal{L}(\theta; x_1, \dots, x_N)=\prod_{i=1}^N p(x_i;\theta)$"></a>3) 결합확률밀도함수 $\mathcal{L}(\theta; x_1, \dots, x_N)=\prod_{i=1}^N p(x_i;\theta)$</h3><ul><li>예) $N(\mu, \sigma)$ 표본 x=1이라면, $\mu$=1일 때 pdf가 가장 높음</li></ul><hr><h2 id="3-베이지안-모수-추정"><a href="#3-베이지안-모수-추정" class="headerlink" title="3. 베이지안 모수 추정"></a>3. 베이지안 모수 추정</h2><ul><li><strong>tartget: 모수의 사후 분포 $p_{posterior}(\mu| x_1, \dots, x_N)$</strong></li><li>모수의 값이 가질 수 있는 모든 가능성의 분포를 계산</li><li>Hyper prams: 모수$\theta$의 확률분포를 표현<h3 id="p-posterior-mu-x-1-dots-x-N-dfrac-p-likelihood-x-1-dots-x-N-mu-cdot-p-prior-mu-p-x-1-cdots-x-N"><a href="#p-posterior-mu-x-1-dots-x-N-dfrac-p-likelihood-x-1-dots-x-N-mu-cdot-p-prior-mu-p-x-1-cdots-x-N" class="headerlink" title="$p_{posterior}(\mu| x_1, \dots, x_N) = \dfrac{p_{likelihood}(x_1, \dots, x_N| \mu) \cdot p_{prior}(\mu)}{p(x_1, \cdots, x_N)}$"></a>$p_{posterior}(\mu| x_1, \dots, x_N) = \dfrac{p_{likelihood}(x_1, \dots, x_N| \mu) \cdot p_{prior}(\mu)}{p(x_1, \cdots, x_N)}$</h3></li><li>$p_{prior}(\mu)$: <em>모수</em>의 사전분포. 모수 분포 사전지식 없으면, uniform dist. $Beta(1,1)$ or Gaussian dist $N(0, 1)$</li><li>$p_{posterior}(\mu| x_1, \dots, x_N)$: 데이터(지식) 주어졌을 때 모수의 분포</li><li>$p_{likelihood}(x_1, \dots, x_N| \mu)$: 모수를 알 때, 데이터 $x_1, \dots, x_N$ 나올 수 있는 확률</li></ul><p>예제. 정규분포 기댓값 베이지안 모수 추정</p><ul><li>모수 $\mu$ 정규분포 따르는 것으로 가정</li><li>param $\sigma^2$은 알고 있다고 가정</li><li><p>$p_{posterior} \propto p_{likelihood} \cdot p_{prior} $</p></li><li><p><strong>prior</strong>: $p(\mu) = N(\mu_0, \sigma_0^2) = \dfrac{1}{\sqrt{2 \pi \sigma_0^2}}\exp(- \dfrac{(\mu - \mu_0)^2}{2 \sigma_0^2}) $</p><ul><li>$\mu_0$: unknown. $\mu_0$은 정규 분포(0, 1)를 따른다고 가정하고 시작.</li><li>즉, hyper param 초기값이 (0, 1) -&gt; 데이터 더할수록 갱신</li></ul></li><li><strong>likelihodd</strong>: $p(x_1, \cdots, x_N| \mu) = \prod_{i=1}^N N(x_i|\mu) = \prod_{i=1}^N\dfrac{1}{\sqrt{2 \pi \sigma_0^2}}\exp(- \dfrac{(x_i - \mu_0)^2}{2 \sigma_0^2}) $</li><li><strong>target:$p_{posterior}(\mu_0| x_1, \dots, x_N)$</strong><script type="math/tex; mode=display">\exp \left( -\dfrac{(\mu - \mu_0^{'})^2}{2 \sigma_0^{'2}}  \right)</script></li><li>hyper param은 데이터를 먹으면서 계속 갱신됨</li><li>즉, 아래의 $x_i$와 N에 따라 갱신</li><li><strong>다음 스텝에서는 $\mu’_0$이 $\mu_0$자리로 치환 -&gt; 새로운 데이터 바로바로 적용가능</strong><ul><li>$\mu_o^{‘}$</li><li>$\sigma_o^{‘}$<script type="math/tex; mode=display">\begin{eqnarray}\mu'_0 &=& \dfrac{\sigma^2}{N\sigma_0^2 + \sigma^2}\mu_0 + \dfrac{N\sigma_0^2}{N\sigma_0^2 + \sigma^2} \dfrac{\sum x_i}{N} \\\dfrac{1}{\sigma_0^{'2}} &=& \dfrac{1}{\sigma_0^{2}} + \dfrac{N}{\sigma^{'2}}\end{eqnarray}</script></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.norm(mu).rvs(N)</span><br></pre></td></tr></table></figure><pre><code>array([ 2.52106488,  1.42421203,  2.14195316,  1.68067158,  2.69153875,        2.69474914,  1.27440262,  0.61663604,  0.4170616 ,  2.61037938,        0.81114074,  1.49318365,  1.40368596,  1.9474327 ,  0.06372019,        2.1887786 ,  2.52389102,  2.08842209,  1.68911383,  2.09740017,        2.39904635, -0.77259276,  3.95591231,  2.39009332,  1.34759142,        1.60904662,  2.49374178,  1.88389606, -0.03068447,  4.06449286,        1.88945934,  3.02017271,  1.30795015,  3.53637705,  2.28634369,        2.60884383,  0.95474663,  3.21114529,  2.68981816,  3.30184623,        1.37191244,  1.51897288,  4.3039167 ,  0.93998418,  1.8640503 ,        3.13689136,  2.09772497,  2.58295368,  1.60055097,  2.37005589])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sample generator</span></span><br><span class="line">mu, sigma2 = <span class="number">2</span>, <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># target: hyperparam</span></span><br><span class="line">mu0, sigma20 = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"></span><br><span class="line">xx = np.linspace(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1000</span>)</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터(지식)을 50개씩 늘려갔을 때, Posterior는 어떻게 변하는가</span></span><br><span class="line">line = [<span class="string">":"</span>, <span class="string">"-."</span>, <span class="string">"--"</span>, <span class="string">"-"</span>]</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> line:</span><br><span class="line">    N = <span class="number">50</span></span><br><span class="line">    x = sp.stats.norm(mu).rvs(N)</span><br><span class="line"></span><br><span class="line">    mu0 = sigma2 / (N*sigma20 + sigma2) * mu0 + \</span><br><span class="line">    (N * sigma20) / (N * sigma20 + sigma2) * x.mean()</span><br><span class="line">    sigma20 = <span class="number">1</span>/(<span class="number">1</span>/sigma20+ N/sigma2)</span><br><span class="line">    print(mu0)</span><br><span class="line"></span><br><span class="line">    ax.plot(xx, sp.stats.norm(mu0, sigma20).pdf(xx), ls=l, label=<span class="string">"&#123;&#125;th"</span>.format(i))</span><br><span class="line">    ax.legend()</span><br><span class="line">ax.axis([<span class="number">1.75</span>, <span class="number">2.25</span>, <span class="number">0</span>, <span class="number">25</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>1.98199932621583151.98058463032162012.07017885429149472.0303044050403543</code></pre><p><img src="/Recap_%EB%AA%A8%EC%88%98%EC%B6%94%EC%A0%95%EC%9D%98%EB%AF%B8_files/Recap_%EB%AA%A8%EC%88%98%EC%B6%94%EC%A0%95%EC%9D%98%EB%AF%B8_5_1.png" alt="png"></p><p>reference:</p><ul><li><a href="https://github.com/WillKoehrsen/probabilistic-programming/blob/master/Estimating%20Probabilities%20with%20Bayesian%20Inference.ipynb" target="_blank" rel="noopener">https://github.com/WillKoehrsen/probabilistic-programming/blob/master/Estimating%20Probabilities%20with%20Bayesian%20Inference.ipynb</a></li><li><a href="https://datascienceschool.net/view-notebook/ae35a40deb884cf88e85135b4b5a1130/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/ae35a40deb884cf88e85135b4b5a1130/</a></li></ul><p>질문</p><ul><li>00확률분포의 모수, 의 확률분포는 00를 따르는가?<ul><li>아니다. 드물다. 이러한 사전분포는 conjugate prior이며 베타분포가 그러하다</li></ul></li><li>예제에서 hyper param 공식 유도시, 최대 가능도 함수 사용?</li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Math </tag>
            
            <tag> 모수추정 </tag>
            
            <tag> 베이지안 모수 추정 </tag>
            
            <tag> 최대가능도 </tag>
            
            <tag> 최소자승법 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Hexo] Customize hexo-cactus theme using .ejs</title>
      <link href="/2019/01/29/theme-tweak/"/>
      <url>/2019/01/29/theme-tweak/</url>
      
        <content type="html"><![CDATA[<h2 id="Example-Picture"><a href="#Example-Picture" class="headerlink" title="Example Picture"></a>Example Picture</h2><p><img src="/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_files/modifyejs.png" alt=""><br><a id="more"></a></p><h2 id="1-Change-‘Writing’-to-‘Recent-Posts’"><a href="#1-Change-‘Writing’-to-‘Recent-Posts’" class="headerlink" title="1. Change ‘Writing’ to ‘Recent Posts’"></a>1. Change ‘Writing’ to ‘Recent Posts’</h2><p><code>index.articles</code> indicates “writing”.<br>Need to change variable <code>index.articles</code> to “Recent Post”<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#path: themes&gt;cactus&gt;layout&gt;index.ejs</span><br><span class="line">&lt;section id=&quot;writing&quot;&gt;</span><br><span class="line">  &lt;span class=&quot;h1&quot;&gt;&lt;a href=&quot;&lt;%- url_for(&quot;archives&quot;) %&gt;&quot;&gt;&lt;%= __(&apos;index.articles&apos;) %&gt;&lt;/a&gt;&lt;/span&gt;</span><br><span class="line">  &lt;% if (theme.tags_overview &amp;&amp; site.tags.length) &#123; %&gt;</span><br></pre></td></tr></table></figure></p><p> <code>default.yml</code> save variables.<br> modified code:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#path: themes&gt;cactus&gt;languages&gt;default.yml</span><br><span class="line"> index:</span><br><span class="line">   find_me_on: Find me on</span><br><span class="line">   enum_comma: &apos;,&apos;</span><br><span class="line">   enum_and: and</span><br><span class="line">   articles: wrting # change to -&gt; Recent Posts</span><br><span class="line">   projects: Projects</span><br><span class="line">   topics: Topics</span><br><span class="line">   most_recent: Most recent</span><br></pre></td></tr></table></figure></p><h2 id="2-Display-Categories-on-the-first-page"><a href="#2-Display-Categories-on-the-first-page" class="headerlink" title="2. Display Categories on the first page"></a>2. Display Categories on the first page</h2><p>Note. prerequisite: categories page</p><pre><code>$ hexo new page categories</code></pre><p>and adding <code>type:categories</code> to <code>source&gt;categories&gt;index.md</code></p><p>Need to insert following code:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#path: themes&gt;cactus&gt;layout&gt;index.ejs</span><br><span class="line">&lt;section id=&quot;categories&quot; class=&quot;left&quot;&gt;</span><br><span class="line">  &lt;div class=&quot;category-list-title&quot;&gt;</span><br><span class="line">      &lt;span class=&quot;h1&quot;&gt;&lt;a href=&quot;&lt;%- url_for(&quot;categories&quot;) %&gt;&quot;&gt;&lt;%= __(&apos;nav.category&apos;) %&gt;&lt;/a&gt;&lt;/span&gt;</span><br><span class="line">      &lt;% var visibleCategories = 0 %&gt;</span><br><span class="line">      &lt;% site.categories.each(function(cat)&#123; %&gt;</span><br><span class="line">        &lt;% if (cat.length) &#123; %&gt;</span><br><span class="line">          &lt;% visibleCategories += 1 %&gt;</span><br><span class="line">        &lt;% &#125; %&gt;</span><br><span class="line">      &lt;% &#125;) %&gt;</span><br><span class="line">      &lt;%- _p(&apos;counter.categories&apos;, visibleCategories) %&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line">  &lt;div class=&quot;category-list&quot;&gt;</span><br><span class="line">    &lt;%- list_categories() %&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line">&lt;/section&gt;</span><br></pre></td></tr></table></figure></p><p>after the code below:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&lt;section id=&quot;writing&quot;&gt;</span><br><span class="line">  &lt;span class=&quot;h1&quot;&gt;&lt;a href=&quot;&lt;%- url_for(&quot;archives&quot;) %&gt;&quot;&gt;&lt;%= __(&apos;index.articles&apos;) %&gt;&lt;/a&gt;&lt;/span&gt;</span><br><span class="line">  &lt;% if (theme.tags_overview &amp;&amp; site.tags.length) &#123; %&gt;</span><br><span class="line">  &lt;span class=&quot;h2&quot;&gt;&lt;%= __(&apos;index.topics&apos;) %&gt;&lt;/span&gt;</span><br><span class="line">  &lt;span class=&quot;widget tagcloud&quot;&gt;</span><br><span class="line">    &lt;%- tagcloud(theme.tags_overview) %&gt;</span><br><span class="line">  &lt;/span&gt;</span><br><span class="line">  &lt;span class=&quot;h2&quot;&gt;&lt;%= __(&apos;index.most_recent&apos;) %&gt;&lt;/span&gt;</span><br><span class="line">  &lt;% &#125; %&gt;</span><br><span class="line">  &lt;ul class=&quot;post-list&quot;&gt;</span><br><span class="line">    &lt;% var field_sort = theme.posts_overview.sort_updated ? &apos;updated&apos; : &apos;date&apos; %&gt;</span><br><span class="line">    &lt;% if (theme.posts_overview.show_all_posts) &#123; %&gt;</span><br><span class="line">      &lt;% var show_posts = page.posts.sort(field_sort, &apos;desc&apos;) %&gt;</span><br><span class="line">    &lt;% &#125; else &#123; %&gt;</span><br><span class="line">      &lt;% var show_posts = site.posts.sort(field_sort, &apos;desc&apos;).limit(theme.posts_overview.post_count || 5) %&gt;</span><br><span class="line">    &lt;% &#125; %&gt;</span><br><span class="line">    &lt;% show_posts.each(function(post, i)&#123; %&gt;</span><br><span class="line">      &lt;li class=&quot;post-item&quot;&gt;</span><br><span class="line">        &lt;%- partial(&apos;_partial/post/date&apos;, &#123; post: post, class_name: &apos;meta&apos; &#125;) %&gt;</span><br><span class="line">        &lt;span&gt;&lt;%- partial(&apos;_partial/post/title&apos;, &#123; post: post, index: true, class_name: &apos;&apos; &#125;) %&gt;&lt;/span&gt;</span><br><span class="line">      &lt;/li&gt;</span><br><span class="line">    &lt;% &#125;); %&gt;</span><br><span class="line">  &lt;/ul&gt;</span><br><span class="line">  &lt;% if (theme.posts_overview.show_all_posts) &#123; %&gt;</span><br><span class="line">    &lt;%- partial(&apos;_partial/pagination&apos;) %&gt;</span><br><span class="line">  &lt;% &#125; %&gt;</span><br><span class="line">&lt;/section&gt;</span><br></pre></td></tr></table></figure></p><h2 id="3-Make-the-logo-stay-bright"><a href="#3-Make-the-logo-stay-bright" class="headerlink" title="3. Make the logo stay bright"></a>3. Make the logo stay bright</h2><p>Corret the code as below<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#path: theme&gt;cactus&gt;source&gt;css&gt;_partial&gt;header.styl</span><br><span class="line">#logo</span><br><span class="line">  display: inline-block</span><br><span class="line">  float: left</span><br><span class="line">  margin-right: 20px</span><br><span class="line">  width: $logo-width</span><br><span class="line">  height: $logo-height</span><br><span class="line">  border-radius: 5px</span><br><span class="line">  # delete -&gt; filter: grayscale(100%)</span><br><span class="line">  background-size: $logo-width $logo-height</span><br><span class="line">  background-repeat: no-repeat</span><br><span class="line">  # delete -&gt; -webkit-filter: grayscale(100%)</span><br></pre></td></tr></table></figure></p><p>and delete the code below:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#header:hover</span><br><span class="line">  #logo</span><br><span class="line">    filter: none</span><br><span class="line">    -webkit-filter: none</span><br></pre></td></tr></table></figure></p><h2 id="4-Place-Categoy-amp-Recent-Posts-side-by-side"><a href="#4-Place-Categoy-amp-Recent-Posts-side-by-side" class="headerlink" title="4. Place Categoy &amp; Recent Posts side by side"></a>4. Place Categoy &amp; Recent Posts side by side</h2><p>prerequisite: add class ‘.left’, ‘right’ to each section&lt;/br&gt;<br>Correct the code <code>.content</code> as below:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#path: themes&gt;cactus&gt;source&gt;CSS&gt;style.styl</span><br><span class="line">.content</span><br><span class="line">  position: relative</span><br><span class="line">  flex-wrap: wrap</span><br><span class="line">  flex-direction: row</span><br><span class="line">  min-height: 100%</span><br><span class="line">.left</span><br><span class="line">  float: left</span><br><span class="line">.right</span><br><span class="line">  float: right</span><br></pre></td></tr></table></figure></p><h2 id="5-Mange-font-color"><a href="#5-Mange-font-color" class="headerlink" title="5. Mange font color"></a>5. Mange font color</h2><p>path: themes&gt;cactus&gt;source&gt;css&gt;style.styl</p>]]></content>
      
      
      <categories>
          
          <category> Github </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] Install virtual python env</title>
      <link href="/2019/01/28/insatlling_virtual_env/"/>
      <url>/2019/01/28/insatlling_virtual_env/</url>
      
        <content type="html"><![CDATA[<h3 id="1-1-pyenv-설치"><a href="#1-1-pyenv-설치" class="headerlink" title="1.1 pyenv 설치"></a>1.1 pyenv 설치</h3><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install curl git-core gcc make zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev libssl-dev</span><br><span class="line">$ git clone https://github.com/pyenv/pyenv.git $HOME/.pyenv</span><br><span class="line">$ vim $HOME/.bashrc</span><br></pre></td></tr></table></figure><h3 id="1-2-configs-setting"><a href="#1-2-configs-setting" class="headerlink" title="1.2 configs setting"></a>1.2 configs setting</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ vi /.bash_profile</span><br><span class="line"></span><br><span class="line">export PYENV_ROOT=&quot;$HOME/.pyenv&quot;</span><br><span class="line">export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;</span><br><span class="line"></span><br><span class="line">eval &quot;$(pyenv init -)&quot;</span><br><span class="line">eval &quot;$(pyenv virtualenv-init -)&quot;</span><br></pre></td></tr></table></figure><h3 id="1-3-update"><a href="#1-3-update" class="headerlink" title="1.3 update"></a>1.3 update</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone git://github.com/pyenv/pyenv-update.git ~/.pyenv/plugins/pyenv-update</span><br></pre></td></tr></table></figure><h3 id="1-4-python-설치"><a href="#1-4-python-설치" class="headerlink" title="1.4 python 설치"></a>1.4 python 설치</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pyenv install 3.5.2</span><br></pre></td></tr></table></figure><hr><h3 id="2-1-pyenv-virtualenv-설치"><a href="#2-1-pyenv-virtualenv-설치" class="headerlink" title="2.1 pyenv-virtualenv 설치"></a>2.1 pyenv-virtualenv 설치</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenv</span><br></pre></td></tr></table></figure><h3 id="2-2-virtualenv-환경변수-추가"><a href="#2-2-virtualenv-환경변수-추가" class="headerlink" title="2.2 virtualenv 환경변수 추가"></a>2.2 virtualenv 환경변수 추가</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ echo &apos;eval &quot;$(pyenv virtualenv-init -)&quot;&apos; &gt;&gt; ~/.bash_profile</span><br><span class="line">$ source ~/.bash_profile</span><br></pre></td></tr></table></figure><h3 id="2-3-가상환경-설정"><a href="#2-3-가상환경-설정" class="headerlink" title="2.3 가상환경 설정"></a>2.3 가상환경 설정</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pyenv virtualenv 3.6.0 py3tensor</span><br></pre></td></tr></table></figure><h3 id="2-4-실행"><a href="#2-4-실행" class="headerlink" title="2.4 실행"></a>2.4 실행</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pyenv activate py3tensor</span><br></pre></td></tr></table></figure><h3 id="2-4-해제"><a href="#2-4-해제" class="headerlink" title="2.4 해제"></a>2.4 해제</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pyenv deactivate</span><br></pre></td></tr></table></figure><hr><h3 id="3-1-auto-env-설치"><a href="#3-1-auto-env-설치" class="headerlink" title="3.1 auto_env 설치"></a>3.1 auto_env 설치</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git clone git://github.com/kennethreitz/autoenv.git ~/.autoenv</span><br><span class="line">$ echo &apos;source ~/.autoenv/activate.sh&apos; &gt;&gt; ~/.bash_profile</span><br></pre></td></tr></table></figure><h3 id="3-2-local-지정"><a href="#3-2-local-지정" class="headerlink" title="3.2 local 지정"></a>3.2 local 지정</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir pyenv_test &amp;&amp; cd pyenv_test</span><br><span class="line">$ touch .env</span><br><span class="line">$ echo &quot;pyenv activate [virtualenv name]&quot; &gt; .env</span><br></pre></td></tr></table></figure><h3 id="3-3-global-해제"><a href="#3-3-global-해제" class="headerlink" title="3.3 global 해제"></a>3.3 global 해제</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vi ~/.env</span><br><span class="line">$ echo &quot;pyenv deactivate&quot; &gt; .env</span><br></pre></td></tr></table></figure><h3 id="4-1-Jupyter-notebook-for-virtual-env"><a href="#4-1-Jupyter-notebook-for-virtual-env" class="headerlink" title="4.1 Jupyter notebook for virtual env"></a>4.1 Jupyter notebook for virtual env</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ cd pyenv_test</span><br><span class="line">$ pip install ipykernel ipython</span><br><span class="line">$ mkdir /home/henry/.local/share/jupyter/kernels/py3ten</span><br><span class="line">$ vi kernel.jason</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"> &quot;argv&quot;: [ &quot;/Users/motta/.pyenv/versions/k_means/bin/python&quot;, &quot;-m&quot;, &quot;ipykernel&quot;,</span><br><span class="line">          &quot;-f&quot;, &quot;&#123;connection_file&#125;&quot;],</span><br><span class="line"> &quot;display_name&quot;: &quot;k_means&quot;,</span><br><span class="line"> &quot;language&quot;: &quot;python&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>reference:</p><p><a href="https://www.alfredo.motta.name/create-isolated-jupyter-ipython-kernels-with-pyenv-and-virtualenv/" target="_blank" rel="noopener">https://www.alfredo.motta.name/create-isolated-jupyter-ipython-kernels-with-pyenv-and-virtualenv/</a></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pyenv </tag>
            
            <tag> Python3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[ML] 자연어 처리(1)</title>
      <link href="/2019/01/28/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC(1)/"/>
      <url>/2019/01/28/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC(1)/</url>
      
        <content type="html"><![CDATA[<h2 id="index"><a href="#index" class="headerlink" title="index"></a>index</h2><p>자연어 처리(1)<br><a id="more"></a></p><ol><li>말뭉치(corpus)</li><li>토큰생성(tokenizing)</li></ol><ul><li>sentence unit<ul><li><code>sent_tokenize</code>: return sentence</li></ul></li><li>word unit<ul><li><code>word_tokenize</code><br>= <code>TreebankWordTokenizer</code></li><li><code>WordPunctTokenizer</code></li><li><code>RegexpTokenizer</code></li></ul></li></ul><ol><li>형태소 분석</li></ol><ul><li>어간 추출 stemming: 단순 어미 제거, 즉 정확한 어간 아님</li><li>원형 복원 lemmatizing: 같은 의미 지니는 여러 단어를 사전형으로 통일.<ul><li>품사 part of speech 지정시, 더 정확</li></ul></li><li>품사 부착 part-of-speech tagging</li></ul><p>cf. pos tagging</p><ul><li>품사 POS 구분: 낱말을 문법적 기능, 형태, 뜻에 따라 구분</li><li>NLTK는 Penn Treebank Tagset 채택<ul><li>NNP: 단수 고유명사</li><li>VB: 동사</li><li>VBP: 동사 현재형</li><li>TO: 전치사</li><li>NN: 명사</li><li>DT: 관형사</li></ul></li></ul><p>cf. pos tagging: text pre-processing 연습</p><ul><li>scikit-learn 자연어 분석시 “같은 토큰/다른 품사” = 다른 토큰</li><li>처리방법<ul><li>convert to “토큰/품사”</li></ul></li></ul><ol><li>text class</li></ol><ul><li><code>plot</code>: 단어token의 사용 빈도 그래프화</li><li><code>dispersion_plot</code>: 단어가 사용된 위치 시각화<ul><li>eg. 소설의 등장인물 등장 위치</li></ul></li><li><code>concordance</code>: lines 입력 갯수만큼 해당 문장 display</li><li><code>similar</code>: 해당 단어와 비슷한 문맥에서 사용된 단어</li></ul><ol><li>FreqDist</li></ol><ul><li><code>FreqDist</code>: 문서에 사용된 단어의 사용빈도 정보 담는 class</li><li>return: <code>{&#39;word&#39;: frequency}</code></li><li><code>N()</code>: 전체 단어수</li><li><code>freq(&quot;word&quot;)</code>: 확률</li><li><code>most_common</code>: 출현빈도 높은 단어</li></ul><p>5.1 사용법1)</p><ul><li><code>Text</code> class의 vocab으로 추출</li></ul><p>5.2 사용법2)</p><ul><li>말뭉치에서 추려낸 단어로 <code>FreqDist</code> class 객체 생성<ul><li>예) Emma.txt corpus에서 사람(NNP, 고유대명사)만 추출 &amp; apply stop words</li></ul></li><li><code>most_common</code>: 출현빈도 높은 단어</li></ul><ol><li>wordcloud</li></ol><ul><li><code>FreqDist</code> 활용</li><li>단어 빈도수에 따른 시각화</li></ul><hr><h2 id="Contents"><a href="#Contents" class="headerlink" title="Contents"></a>Contents</h2><h3 id="1-말뭉치-corpus"><a href="#1-말뭉치-corpus" class="headerlink" title="1. 말뭉치(corpus)"></a>1. 말뭉치(corpus)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">nltk.download(<span class="string">'book'</span>, quiet=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.book <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure><pre><code>*** Introductory Examples for the NLTK Book ***Loading text1, ..., text9 and sent1, ..., sent9Type the name of the text or sentence to view it.Type: &#39;texts()&#39; or &#39;sents()&#39; to list the materials.text1: Moby Dick by Herman Melville 1851text2: Sense and Sensibility by Jane Austen 1811text3: The Book of Genesistext4: Inaugural Address Corpustext5: Chat Corpustext6: Monty Python and the Holy Grailtext7: Wall Street Journaltext8: Personals Corpustext9: The Man Who Was Thursday by G . K . Chesterton 1908</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.corpus.gutenberg.fileids()</span><br></pre></td></tr></table></figure><pre><code>[&#39;austen-emma.txt&#39;, &#39;austen-persuasion.txt&#39;, &#39;austen-sense.txt&#39;, &#39;bible-kjv.txt&#39;, &#39;blake-poems.txt&#39;, &#39;bryant-stories.txt&#39;, &#39;burgess-busterbrown.txt&#39;, &#39;carroll-alice.txt&#39;, &#39;chesterton-ball.txt&#39;, &#39;chesterton-brown.txt&#39;, &#39;chesterton-thursday.txt&#39;, &#39;edgeworth-parents.txt&#39;, &#39;melville-moby_dick.txt&#39;, &#39;milton-paradise.txt&#39;, &#39;shakespeare-caesar.txt&#39;, &#39;shakespeare-hamlet.txt&#39;, &#39;shakespeare-macbeth.txt&#39;, &#39;whitman-leaves.txt&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">raw = nltk.corpus.gutenberg.raw(<span class="string">'bryant-stories.txt'</span>)</span><br><span class="line">print(raw[:<span class="number">300</span>])</span><br></pre></td></tr></table></figure><pre><code>[Stories to Tell to Children by Sara Cone Bryant 1918]TWO LITTLE RIDDLES IN RHYME     There&#39;s a garden that I ken,     Full of little gentlemen;     Little caps of blue they wear,     And green ribbons, very fair.           (Flax.)     From house to house he goes,     A me</code></pre><hr><h3 id="2-토큰생성-tokenizing"><a href="#2-토큰생성-tokenizing" class="headerlink" title="2. 토큰생성(tokenizing)"></a>2. 토큰생성(tokenizing)</h3><h4 id="sentence-unit"><a href="#sentence-unit" class="headerlink" title="sentence unit"></a>sentence unit</h4><ul><li><code>sent_tokenize</code>: return sentence</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> sent_tokenize</span><br><span class="line">sent_tokenize(raw[:<span class="number">300</span>])</span><br></pre></td></tr></table></figure><pre><code>[&quot;[Stories to Tell to Children by Sara Cone Bryant 1918] \r\n\r\n\r\nTWO LITTLE RIDDLES IN RHYME\r\n\r\n\r\n     There&#39;s a garden that I ken,\r\n     Full of little gentlemen;\r\n     Little caps of blue they wear,\r\n     And green ribbons, very fair.&quot;, &#39;(Flax.)&#39;, &#39;From house to house he goes,\r\n     A me&#39;]</code></pre><h4 id="word-unit"><a href="#word-unit" class="headerlink" title="word unit"></a>word unit</h4><ul><li><code>word_tokenize</code><br>= <code>TreebankWordTokenizer</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line">word_tokenize(<span class="string">"this's, a, test! ha."</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#39;this&#39;, &quot;&#39;s&quot;, &#39;,&#39;, &#39;a&#39;, &#39;,&#39;, &#39;test&#39;, &#39;!&#39;, &#39;ha&#39;, &#39;.&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> TreebankWordTokenizer</span><br><span class="line">tree = TreebankWordTokenizer()</span><br><span class="line">tree.tokenize(<span class="string">"this's, a, test! ha."</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#39;this&#39;, &quot;&#39;s&quot;, &#39;,&#39;, &#39;a&#39;, &#39;,&#39;, &#39;test&#39;, &#39;!&#39;, &#39;ha&#39;, &#39;.&#39;]</code></pre><ul><li><code>WordPunctTokenizer</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> WordPunctTokenizer</span><br><span class="line">punct = WordPunctTokenizer()</span><br><span class="line">punct.tokenize(<span class="string">"this's, a, test! ha."</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#39;this&#39;, &quot;&#39;&quot;, &#39;s&#39;, &#39;,&#39;, &#39;a&#39;, &#39;,&#39;, &#39;test&#39;, &#39;!&#39;, &#39;ha&#39;, &#39;.&#39;]</code></pre><ul><li><code>RegexpTokenizer</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> RegexpTokenizer</span><br><span class="line">pattern = <span class="string">"[\w]+"</span></span><br><span class="line">retokenize = RegexpTokenizer(pattern)</span><br><span class="line">retokenize.tokenize(raw[<span class="number">50</span>:<span class="number">100</span>])</span><br></pre></td></tr></table></figure><pre><code>[&#39;918&#39;, &#39;TWO&#39;, &#39;LITTLE&#39;, &#39;RIDDLES&#39;, &#39;IN&#39;, &#39;RHYME&#39;, &#39;T&#39;]</code></pre><hr><h3 id="3-형태소-분석"><a href="#3-형태소-분석" class="headerlink" title="3. 형태소 분석"></a>3. 형태소 분석</h3><ul><li>어간 추출 stemming: 단순 어미 제거, 즉 정확한 어간 아님</li><li>원형 복원 lemmatizing: 같은 의미 지니는 여러 단어를 사전형으로 통일.<ul><li>품사 part of speech 지정시, 더 정확</li></ul></li><li>품사 부착 part-of-speech tagging</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words = retokenize.tokenize(raw[<span class="number">1300</span>:<span class="number">2000</span>])</span><br></pre></td></tr></table></figure><h4 id="stemming"><a href="#stemming" class="headerlink" title="stemming"></a>stemming</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br><span class="line">st = PorterStemmer()</span><br><span class="line">[(w, st.stem(w)) <span class="keyword">for</span> w <span class="keyword">in</span> words][:<span class="number">15</span>]</span><br></pre></td></tr></table></figure><pre><code>[(&#39;said&#39;, &#39;said&#39;), (&#39;a&#39;, &#39;a&#39;), (&#39;little&#39;, &#39;littl&#39;), (&#39;soft&#39;, &#39;soft&#39;), (&#39;cheery&#39;, &#39;cheeri&#39;), (&#39;voice&#39;, &#39;voic&#39;), (&#39;and&#39;, &#39;and&#39;), (&#39;I&#39;, &#39;I&#39;), (&#39;want&#39;, &#39;want&#39;), (&#39;to&#39;, &#39;to&#39;), (&#39;come&#39;, &#39;come&#39;), (&#39;in&#39;, &#39;in&#39;), (&#39;N&#39;, &#39;N&#39;), (&#39;no&#39;, &#39;no&#39;), (&#39;said&#39;, &#39;said&#39;)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> LancasterStemmer</span><br><span class="line">st = LancasterStemmer()</span><br><span class="line">[(w, st.stem(w)) <span class="keyword">for</span> w <span class="keyword">in</span> words][:<span class="number">15</span>]</span><br></pre></td></tr></table></figure><pre><code>[(&#39;said&#39;, &#39;said&#39;), (&#39;a&#39;, &#39;a&#39;), (&#39;little&#39;, &#39;littl&#39;), (&#39;soft&#39;, &#39;soft&#39;), (&#39;cheery&#39;, &#39;cheery&#39;), (&#39;voice&#39;, &#39;voic&#39;), (&#39;and&#39;, &#39;and&#39;), (&#39;I&#39;, &#39;i&#39;), (&#39;want&#39;, &#39;want&#39;), (&#39;to&#39;, &#39;to&#39;), (&#39;come&#39;, &#39;com&#39;), (&#39;in&#39;, &#39;in&#39;), (&#39;N&#39;, &#39;n&#39;), (&#39;no&#39;, &#39;no&#39;), (&#39;said&#39;, &#39;said&#39;)]</code></pre><h4 id="lemmatizing"><a href="#lemmatizing" class="headerlink" title="lemmatizing"></a>lemmatizing</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line">lm = WordNetLemmatizer()</span><br><span class="line">[(w, lm.lemmatize(w)) <span class="keyword">for</span> w <span class="keyword">in</span> words][:<span class="number">15</span>]</span><br></pre></td></tr></table></figure><pre><code>[(&#39;said&#39;, &#39;said&#39;), (&#39;a&#39;, &#39;a&#39;), (&#39;little&#39;, &#39;little&#39;), (&#39;soft&#39;, &#39;soft&#39;), (&#39;cheery&#39;, &#39;cheery&#39;), (&#39;voice&#39;, &#39;voice&#39;), (&#39;and&#39;, &#39;and&#39;), (&#39;I&#39;, &#39;I&#39;), (&#39;want&#39;, &#39;want&#39;), (&#39;to&#39;, &#39;to&#39;), (&#39;come&#39;, &#39;come&#39;), (&#39;in&#39;, &#39;in&#39;), (&#39;N&#39;, &#39;N&#39;), (&#39;no&#39;, &#39;no&#39;), (&#39;said&#39;, &#39;said&#39;)]</code></pre><hr><h4 id="pos-tagging"><a href="#pos-tagging" class="headerlink" title="pos tagging"></a>pos tagging</h4><ul><li>품사 POS 구분: 낱말을 문법적 기능, 형태, 뜻에 따라 구분</li><li>NLTK는 Penn Treebank Tagset 채택<ul><li>NNP: 단수 고유명사</li><li>VB: 동사</li><li>VBP: 동사 현재형</li><li>TO: 전치사</li><li>NN: 명사</li><li>DT: 관형사</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tag <span class="keyword">import</span> pos_tag</span><br><span class="line">sentence = sent_tokenize(raw[<span class="number">203</span>:<span class="number">400</span>])[<span class="number">0</span>]</span><br><span class="line">sentence</span><br></pre></td></tr></table></figure><pre><code>&#39;And green ribbons, very fair.&#39;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">word = word_tokenize(sentence)</span><br><span class="line">word</span><br></pre></td></tr></table></figure><pre><code>[&#39;And&#39;, &#39;green&#39;, &#39;ribbons&#39;, &#39;,&#39;, &#39;very&#39;, &#39;fair&#39;, &#39;.&#39;]</code></pre><ul><li><code>pos_tag</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tagged_list = pos_tag(word)</span><br><span class="line">tagged_list</span><br></pre></td></tr></table></figure><pre><code>[(&#39;And&#39;, &#39;CC&#39;), (&#39;green&#39;, &#39;JJ&#39;), (&#39;ribbons&#39;, &#39;NNS&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;very&#39;, &#39;RB&#39;), (&#39;fair&#39;, &#39;JJ&#39;), (&#39;.&#39;, &#39;.&#39;)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.help.upenn_tagset(<span class="string">'JJ'</span>)</span><br></pre></td></tr></table></figure><pre><code>JJ: adjective or numeral, ordinal    third ill-mannered pre-war regrettable oiled calamitous first separable    ectoplasmic battery-powered participatory fourth still-to-be-named    multilingual multi-disciplinary ...</code></pre><ul><li>filtering</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cc_list = [t[<span class="number">0</span>] <span class="keyword">for</span> t <span class="keyword">in</span> tagged_list <span class="keyword">if</span> t[<span class="number">1</span>] == <span class="string">"CC"</span>]</span><br><span class="line">cc_list</span><br></pre></td></tr></table></figure><pre><code>[&#39;And&#39;]</code></pre><ul><li><code>untag</code>: return word</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tag <span class="keyword">import</span> untag</span><br><span class="line">untag(tagged_list)</span><br></pre></td></tr></table></figure><pre><code>[&#39;And&#39;, &#39;green&#39;, &#39;ribbons&#39;, &#39;,&#39;, &#39;very&#39;, &#39;fair&#39;, &#39;.&#39;]</code></pre><hr><h4 id="pos-tagging-text-pre-processing-연습"><a href="#pos-tagging-text-pre-processing-연습" class="headerlink" title="pos tagging: text pre-processing 연습"></a>pos tagging: text pre-processing 연습</h4><ul><li>scikit-learn 자연어 분석시 “같은 토큰/다른 품사” = 다른 토큰</li><li>처리방법<ul><li>convert to “토큰/품사”</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenizer</span><span class="params">(doc)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="string">"/"</span>.join(p) <span class="keyword">for</span> p <span class="keyword">in</span> tagged_list]</span><br><span class="line"></span><br><span class="line">tokenizer(sentence)</span><br></pre></td></tr></table></figure><pre><code>[&#39;And/CC&#39;, &#39;green/JJ&#39;, &#39;ribbons/NNS&#39;, &#39;,/,&#39;, &#39;very/RB&#39;, &#39;fair/JJ&#39;, &#39;./.&#39;]</code></pre><hr><h3 id="4-text-class"><a href="#4-text-class" class="headerlink" title="4. text class"></a>4. text class</h3><ul><li><code>plot</code>: 단어token의 사용 빈도 그래프화</li><li><code>dispersion_plot</code>: 단어가 사용된 위치 시각화<ul><li>eg. 소설의 등장인물 등장 위치</li></ul></li><li><code>concordance</code>: lines 입력 갯수만큼 해당 문장 display</li><li><code>similar</code>: 해당 단어와 비슷한 문맥에서 사용된 단어</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> Text</span><br><span class="line">text = Text(retokenize.tokenize(raw))</span><br></pre></td></tr></table></figure><ul><li><code>plot</code>: 단어token의 사용 빈도 그래프화</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">text.plot(<span class="number">30</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_files/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_43_0.png" alt="png"></p><ul><li><code>dispersion_plot</code>: 단어가 사용된 위치 시각화<ul><li>eg. 소설의 등장인물 등장 위치</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">raw = nltk.corpus.gutenberg.raw(<span class="string">'austen-emma.txt'</span>)</span><br><span class="line">text = Text(retokenize.tokenize(raw))</span><br><span class="line"></span><br><span class="line">text.dispersion_plot([<span class="string">'Emma'</span>, <span class="string">'Knightly'</span>, <span class="string">'Frank'</span>, <span class="string">'Jane'</span>, <span class="string">'Robert'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_files/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_45_0.png" alt="png"></p><ul><li><code>concordance</code>: lines 입력 갯수만큼 해당 문장 display</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text.concordance(<span class="string">'Emma'</span>, lines=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>Displaying 5 of 865 matches: Emma by Jane Austen 1816 VOLUME I CHAPTER Jane Austen 1816 VOLUME I CHAPTER I Emma Woodhouse handsome clever and rich wf both daughters but particularly of Emma Between _them_ it was more the intimnd friend very mutually attached and Emma doing just what she liked highly est by her own The real evils indeed of Emma s situation were the power of having</code></pre><ul><li><code>similar</code>: 해당 단어와 비슷한 문맥에서 사용된 단어</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text.similar(<span class="string">'Emma'</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><pre><code>she it he i harriet you her jane him that</code></pre><hr><h3 id="5-FreqDist"><a href="#5-FreqDist" class="headerlink" title="5. FreqDist"></a>5. FreqDist</h3><ul><li><code>FreqDist</code>: 문서에 사용된 단어의 사용빈도 정보 담는 class</li><li>return: <code>{&#39;word&#39;: frequency}</code></li></ul><h4 id="사용법1"><a href="#사용법1" class="headerlink" title="사용법1)"></a>사용법1)</h4><ul><li><code>Text</code> class의 vocab으로 추출</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fd = text.vocab()</span><br><span class="line">type(fd)</span><br></pre></td></tr></table></figure><pre><code>nltk.probability.FreqDist</code></pre><h4 id="사용법2"><a href="#사용법2" class="headerlink" title="사용법2)"></a>사용법2)</h4><ul><li>말뭉치에서 추려낸 단어로 <code>FreqDist</code> class 객체 생성<ul><li>예) Emma.txt corpus에서 사람(NNP, 고유대명사)만 추출 &amp; apply stop words</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.help.upenn_tagset(<span class="string">'NNP'</span>)</span><br></pre></td></tr></table></figure><pre><code>NNP: noun, proper, singular    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA    Shannon A.K.C. Meltex Liverpool ...</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">emma_tokens = pos_tag(retokenize.tokenize(raw))</span><br><span class="line">len(emma_tokens), emma_tokens[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>(161983, (&#39;Emma&#39;, &#39;NN&#39;))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> FreqDist</span><br><span class="line"></span><br><span class="line">stopwords = [<span class="string">'Mr.'</span>, <span class="string">'Mrs.'</span>, <span class="string">'Miss'</span>, <span class="string">'Mr'</span>, <span class="string">'Mrs'</span>, <span class="string">'Dear'</span>]</span><br><span class="line">names_list = [t[<span class="number">0</span>] <span class="keyword">for</span> t <span class="keyword">in</span> emma_tokens <span class="keyword">if</span> t[<span class="number">1</span>] == <span class="string">"NNP"</span> <span class="keyword">and</span> t[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br><span class="line">fd_names = FreqDist(names_list)</span><br><span class="line">fd_names</span><br></pre></td></tr></table></figure><pre><code>FreqDist({&#39;Emma&#39;: 830, &#39;Harriet&#39;: 491, &#39;Weston&#39;: 439, &#39;Knightley&#39;: 389, &#39;Elton&#39;: 385, &#39;Woodhouse&#39;: 304, &#39;Jane&#39;: 299, &#39;Fairfax&#39;: 241, &#39;Churchill&#39;: 223, &#39;Frank&#39;: 208, ...})</code></pre><hr><ul><li><code>N()</code>: 전체 단어수</li><li><code>freq(&quot;word&quot;)</code>: 확률</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fd_names.N(), fd_names[<span class="string">'Emma'</span>], fd_names.freq(<span class="string">'Emma'</span>)</span><br></pre></td></tr></table></figure><pre><code>(7863, 830, 0.10555767518758744)</code></pre><ul><li><code>most_common</code>: 출현빈도 높은 단어</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fd_names.most_common(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>[(&#39;Emma&#39;, 830), (&#39;Harriet&#39;, 491), (&#39;Weston&#39;, 439), (&#39;Knightley&#39;, 389), (&#39;Elton&#39;, 385)]</code></pre><hr><h3 id="6-wordcloud"><a href="#6-wordcloud" class="headerlink" title="6. wordcloud"></a>6. wordcloud</h3><ul><li><code>FreqDist</code> 활용</li><li>단어 빈도수에 따른 시각화</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line">wc = WordCloud(width=<span class="number">1000</span>, height=<span class="number">600</span>, background_color=<span class="string">'white'</span>, random_state=<span class="number">0</span>)</span><br><span class="line">plt.imshow(wc.generate_from_frequencies(fd_names))</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_files/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_65_0.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Text </tag>
            
            <tag> Preprocessing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] Create and post jupyter.md</title>
      <link href="/2019/01/28/how-to-create-jupyer/"/>
      <url>/2019/01/28/how-to-create-jupyer/</url>
      
        <content type="html"><![CDATA[<h3 id="See-the-example-below"><a href="#See-the-example-below" class="headerlink" title="See the example below:"></a>See the example below:</h3><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cd \path\to\file.md</span><br><span class="line">$ cp file.md \blog\soucre\_post\</span><br><span class="line">$ jupyer nbconvert --to markdown file.ipynb</span><br><span class="line">$ vi file.md</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># add following:</span><br><span class="line">title: &quot;jupyer notebook post&quot;</span><br><span class="line">date: 2019-01-28 00:00:00</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> Jupyter notebook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Hexo] Create hexo github page</title>
      <link href="/2019/01/26/how-to-create-hexo-github-page/"/>
      <url>/2019/01/26/how-to-create-hexo-github-page/</url>
      
        <content type="html"><![CDATA[<h3 id="install-Node-js"><a href="#install-Node-js" class="headerlink" title="install Node.js"></a>install Node.js</h3><a id="more"></a><pre><code>$ wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.11/install.sh</code></pre><h3 id="install-hexo"><a href="#install-hexo" class="headerlink" title="install hexo"></a>install hexo</h3><pre><code>$ npm install hexo-cli -g$ hexo init blog # blog = &lt;file name&gt;$ cd blog</code></pre><h3 id="set-theme"><a href="#set-theme" class="headerlink" title="set theme"></a>set theme</h3><pre><code>$ git clone https://github.com/probberechts/hexo-theme-cactus.git themes/cactus$ vi _config.yml</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theme: cactus</span><br></pre></td></tr></table></figure><h3 id="setting-deploy-config"><a href="#setting-deploy-config" class="headerlink" title="setting deploy config."></a>setting deploy config.</h3><pre><code>$ npm install hexo-deployer-git --save$ vi _config.yml</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: https://github.com/HenryPaik1/HenryPaik1.github.io.git</span><br></pre></td></tr></table></figure><h3 id="apply-modification-amp-run-hexo-server"><a href="#apply-modification-amp-run-hexo-server" class="headerlink" title="apply modification &amp; run hexo server"></a>apply modification &amp; run hexo server</h3><pre><code>$ hexo g$ hexo s</code></pre><h3 id="sync-github"><a href="#sync-github" class="headerlink" title="sync github"></a>sync github</h3><pre><code>$ hexo d</code></pre><p><strong>refernce:</strong><br><a href="https://github.com/probberechts/hexo-theme-cactus" target="_blank" rel="noopener">https://github.com/probberechts/hexo-theme-cactus</a><br><a href="https://hexo.io/docs/commands" target="_blank" rel="noopener">https://hexo.io/docs/commands</a></p>]]></content>
      
      
      <categories>
          
          <category> Github </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
