<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>&lt;How to create jupyter.md and post it&gt;</title>
      <link href="/2019/01/28/how-to-create-jupyer/"/>
      <url>/2019/01/28/how-to-create-jupyer/</url>
      
        <content type="html"><![CDATA[<h3 id="See-the-example-below"><a href="#See-the-example-below" class="headerlink" title="See the example below:"></a>See the example below:</h3><pre><code>$ cd \path\to\file.md$ cp file.md \blog\soucre\_post\$ jupyer nbconvert --to markdown file.ipynb$ vi file.md</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># add following:</span><br><span class="line">title: &quot;jupyer notebook post&quot;</span><br><span class="line">date: 2019-01-28 00:00:00</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> github </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>&lt;자연어 처리(1)&gt;</title>
      <link href="/2019/01/28/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC(1)/"/>
      <url>/2019/01/28/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC(1)/</url>
      
        <content type="html"><![CDATA[<h1 id="자연어-처리-1"><a href="#자연어-처리-1" class="headerlink" title="자연어 처리(1)"></a>자연어 처리(1)</h1><ol><li>말뭉치(corpus)</li><li>토큰생성(tokenizing)</li></ol><ul><li>sentence unit<ul><li><code>sent_tokenize</code>: return sentence</li></ul></li><li>word unit<ul><li><code>word_tokenize</code>= <code>TreebankWordTokenizer</code></li><li><code>WordPunctTokenizer</code></li><li><code>RegexpTokenizer</code></li></ul></li></ul><ol start="3"><li>형태소 분석</li></ol><ul><li>어간 추출 stemming: 단순 어미 제거, 즉 정확한 어간 아님</li><li>원형 복원 lemmatizing: 같은 의미 지니는 여러 단어를 사전형으로 통일.<ul><li>품사 part of speech 지정시, 더 정확</li></ul></li><li>품사 부착 part-of-speech tagging</li></ul><p>cf. pos tagging</p><ul><li>품사 POS 구분: 낱말을 문법적 기능, 형태, 뜻에 따라 구분</li><li>NLTK는 Penn Treebank Tagset 채택<ul><li>NNP: 단수 고유명사</li><li>VB: 동사</li><li>VBP: 동사 현재형</li><li>TO: 전치사</li><li>NN: 명사</li><li>DT: 관형사</li></ul></li></ul><p>cf. pos tagging: text pre-processing 연습</p><ul><li>scikit-learn 자연어 분석시 “같은 토큰/다른 품사” = 다른 토큰</li><li>처리방법<ul><li>convert to “토큰/품사”</li></ul></li></ul><ol start="4"><li>text class</li></ol><ul><li><code>plot</code>: 단어token의 사용 빈도 그래프화</li><li><code>dispersion_plot</code>: 단어가 사용된 위치 시각화<ul><li>eg. 소설의 등장인물 등장 위치</li></ul></li><li><code>concordance</code>: lines 입력 갯수만큼 해당 문장 display</li><li><code>similar</code>: 해당 단어와 비슷한 문맥에서 사용된 단어</li></ul><ol start="5"><li>FreqDist</li></ol><ul><li><code>FreqDist</code>: 문서에 사용된 단어의 사용빈도 정보 담는 class</li><li>return: <code>{&#39;word&#39;: frequency}</code></li><li><code>N()</code>: 전체 단어수</li><li><code>freq(&quot;word&quot;)</code>: 확률</li><li><code>most_common</code>: 출현빈도 높은 단어</li></ul><h4 id="사용법1"><a href="#사용법1" class="headerlink" title="사용법1)"></a>사용법1)</h4><ul><li><code>Text</code> class의 vocab으로 추출</li></ul><h4 id="사용법2"><a href="#사용법2" class="headerlink" title="사용법2)"></a>사용법2)</h4><ul><li>말뭉치에서 추려낸 단어로 <code>FreqDist</code> class 객체 생성<ul><li>예) Emma.txt corpus에서 사람(NNP, 고유대명사)만 추출 &amp; apply stop words</li></ul></li><li><code>most_common</code>: 출현빈도 높은 단어</li></ul><ol start="6"><li>wordcloud</li></ol><ul><li><code>FreqDist</code> 활용</li><li>단어 빈도수에 따른 시각화</li></ul><hr><h1 id="1-말뭉치-corpus"><a href="#1-말뭉치-corpus" class="headerlink" title="1. 말뭉치(corpus)"></a>1. 말뭉치(corpus)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">nltk.download(<span class="string">'book'</span>, quiet=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.book <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure><pre><code>*** Introductory Examples for the NLTK Book ***Loading text1, ..., text9 and sent1, ..., sent9Type the name of the text or sentence to view it.Type: &apos;texts()&apos; or &apos;sents()&apos; to list the materials.text1: Moby Dick by Herman Melville 1851text2: Sense and Sensibility by Jane Austen 1811text3: The Book of Genesistext4: Inaugural Address Corpustext5: Chat Corpustext6: Monty Python and the Holy Grailtext7: Wall Street Journaltext8: Personals Corpustext9: The Man Who Was Thursday by G . K . Chesterton 1908</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.corpus.gutenberg.fileids()</span><br></pre></td></tr></table></figure><pre><code>[&apos;austen-emma.txt&apos;, &apos;austen-persuasion.txt&apos;, &apos;austen-sense.txt&apos;, &apos;bible-kjv.txt&apos;, &apos;blake-poems.txt&apos;, &apos;bryant-stories.txt&apos;, &apos;burgess-busterbrown.txt&apos;, &apos;carroll-alice.txt&apos;, &apos;chesterton-ball.txt&apos;, &apos;chesterton-brown.txt&apos;, &apos;chesterton-thursday.txt&apos;, &apos;edgeworth-parents.txt&apos;, &apos;melville-moby_dick.txt&apos;, &apos;milton-paradise.txt&apos;, &apos;shakespeare-caesar.txt&apos;, &apos;shakespeare-hamlet.txt&apos;, &apos;shakespeare-macbeth.txt&apos;, &apos;whitman-leaves.txt&apos;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">raw = nltk.corpus.gutenberg.raw(<span class="string">'bryant-stories.txt'</span>)</span><br><span class="line">print(raw[:<span class="number">300</span>])</span><br></pre></td></tr></table></figure><pre><code>[Stories to Tell to Children by Sara Cone Bryant 1918]TWO LITTLE RIDDLES IN RHYME     There&apos;s a garden that I ken,     Full of little gentlemen;     Little caps of blue they wear,     And green ribbons, very fair.           (Flax.)     From house to house he goes,     A me</code></pre><hr><h1 id="2-토큰생성-tokenizing"><a href="#2-토큰생성-tokenizing" class="headerlink" title="2. 토큰생성(tokenizing)"></a>2. 토큰생성(tokenizing)</h1><h4 id="sentence-unit"><a href="#sentence-unit" class="headerlink" title="sentence unit"></a>sentence unit</h4><ul><li><code>sent_tokenize</code>: return sentence</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> sent_tokenize</span><br><span class="line">sent_tokenize(raw[:<span class="number">300</span>])</span><br></pre></td></tr></table></figure><pre><code>[&quot;[Stories to Tell to Children by Sara Cone Bryant 1918] \r\n\r\n\r\nTWO LITTLE RIDDLES IN RHYME\r\n\r\n\r\n     There&apos;s a garden that I ken,\r\n     Full of little gentlemen;\r\n     Little caps of blue they wear,\r\n     And green ribbons, very fair.&quot;, &apos;(Flax.)&apos;, &apos;From house to house he goes,\r\n     A me&apos;]</code></pre><h4 id="word-unit"><a href="#word-unit" class="headerlink" title="word unit"></a>word unit</h4><ul><li><code>word_tokenize</code>= <code>TreebankWordTokenizer</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line">word_tokenize(<span class="string">"this's, a, test! ha."</span>)</span><br></pre></td></tr></table></figure><pre><code>[&apos;this&apos;, &quot;&apos;s&quot;, &apos;,&apos;, &apos;a&apos;, &apos;,&apos;, &apos;test&apos;, &apos;!&apos;, &apos;ha&apos;, &apos;.&apos;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> TreebankWordTokenizer</span><br><span class="line">tree = TreebankWordTokenizer()</span><br><span class="line">tree.tokenize(<span class="string">"this's, a, test! ha."</span>)</span><br></pre></td></tr></table></figure><pre><code>[&apos;this&apos;, &quot;&apos;s&quot;, &apos;,&apos;, &apos;a&apos;, &apos;,&apos;, &apos;test&apos;, &apos;!&apos;, &apos;ha&apos;, &apos;.&apos;]</code></pre><ul><li><code>WordPunctTokenizer</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> WordPunctTokenizer</span><br><span class="line">punct = WordPunctTokenizer()</span><br><span class="line">punct.tokenize(<span class="string">"this's, a, test! ha."</span>)</span><br></pre></td></tr></table></figure><pre><code>[&apos;this&apos;, &quot;&apos;&quot;, &apos;s&apos;, &apos;,&apos;, &apos;a&apos;, &apos;,&apos;, &apos;test&apos;, &apos;!&apos;, &apos;ha&apos;, &apos;.&apos;]</code></pre><ul><li><code>RegexpTokenizer</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> RegexpTokenizer</span><br><span class="line">pattern = <span class="string">"[\w]+"</span></span><br><span class="line">retokenize = RegexpTokenizer(pattern)</span><br><span class="line">retokenize.tokenize(raw[<span class="number">50</span>:<span class="number">100</span>])</span><br></pre></td></tr></table></figure><pre><code>[&apos;918&apos;, &apos;TWO&apos;, &apos;LITTLE&apos;, &apos;RIDDLES&apos;, &apos;IN&apos;, &apos;RHYME&apos;, &apos;T&apos;]</code></pre><hr><h1 id="3-형태소-분석"><a href="#3-형태소-분석" class="headerlink" title="3. 형태소 분석"></a>3. 형태소 분석</h1><ul><li>어간 추출 stemming: 단순 어미 제거, 즉 정확한 어간 아님</li><li>원형 복원 lemmatizing: 같은 의미 지니는 여러 단어를 사전형으로 통일.<ul><li>품사 part of speech 지정시, 더 정확</li></ul></li><li>품사 부착 part-of-speech tagging</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words = retokenize.tokenize(raw[<span class="number">1300</span>:<span class="number">2000</span>])</span><br></pre></td></tr></table></figure><h4 id="stemming"><a href="#stemming" class="headerlink" title="stemming"></a>stemming</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br><span class="line">st = PorterStemmer()</span><br><span class="line">[(w, st.stem(w)) <span class="keyword">for</span> w <span class="keyword">in</span> words][:<span class="number">15</span>]</span><br></pre></td></tr></table></figure><pre><code>[(&apos;said&apos;, &apos;said&apos;), (&apos;a&apos;, &apos;a&apos;), (&apos;little&apos;, &apos;littl&apos;), (&apos;soft&apos;, &apos;soft&apos;), (&apos;cheery&apos;, &apos;cheeri&apos;), (&apos;voice&apos;, &apos;voic&apos;), (&apos;and&apos;, &apos;and&apos;), (&apos;I&apos;, &apos;I&apos;), (&apos;want&apos;, &apos;want&apos;), (&apos;to&apos;, &apos;to&apos;), (&apos;come&apos;, &apos;come&apos;), (&apos;in&apos;, &apos;in&apos;), (&apos;N&apos;, &apos;N&apos;), (&apos;no&apos;, &apos;no&apos;), (&apos;said&apos;, &apos;said&apos;)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> LancasterStemmer</span><br><span class="line">st = LancasterStemmer()</span><br><span class="line">[(w, st.stem(w)) <span class="keyword">for</span> w <span class="keyword">in</span> words][:<span class="number">15</span>]</span><br></pre></td></tr></table></figure><pre><code>[(&apos;said&apos;, &apos;said&apos;), (&apos;a&apos;, &apos;a&apos;), (&apos;little&apos;, &apos;littl&apos;), (&apos;soft&apos;, &apos;soft&apos;), (&apos;cheery&apos;, &apos;cheery&apos;), (&apos;voice&apos;, &apos;voic&apos;), (&apos;and&apos;, &apos;and&apos;), (&apos;I&apos;, &apos;i&apos;), (&apos;want&apos;, &apos;want&apos;), (&apos;to&apos;, &apos;to&apos;), (&apos;come&apos;, &apos;com&apos;), (&apos;in&apos;, &apos;in&apos;), (&apos;N&apos;, &apos;n&apos;), (&apos;no&apos;, &apos;no&apos;), (&apos;said&apos;, &apos;said&apos;)]</code></pre><h4 id="lemmatizing"><a href="#lemmatizing" class="headerlink" title="lemmatizing"></a>lemmatizing</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line">lm = WordNetLemmatizer()</span><br><span class="line">[(w, lm.lemmatize(w)) <span class="keyword">for</span> w <span class="keyword">in</span> words][:<span class="number">15</span>]</span><br></pre></td></tr></table></figure><pre><code>[(&apos;said&apos;, &apos;said&apos;), (&apos;a&apos;, &apos;a&apos;), (&apos;little&apos;, &apos;little&apos;), (&apos;soft&apos;, &apos;soft&apos;), (&apos;cheery&apos;, &apos;cheery&apos;), (&apos;voice&apos;, &apos;voice&apos;), (&apos;and&apos;, &apos;and&apos;), (&apos;I&apos;, &apos;I&apos;), (&apos;want&apos;, &apos;want&apos;), (&apos;to&apos;, &apos;to&apos;), (&apos;come&apos;, &apos;come&apos;), (&apos;in&apos;, &apos;in&apos;), (&apos;N&apos;, &apos;N&apos;), (&apos;no&apos;, &apos;no&apos;), (&apos;said&apos;, &apos;said&apos;)]</code></pre><hr><h4 id="pos-tagging"><a href="#pos-tagging" class="headerlink" title="pos tagging"></a>pos tagging</h4><ul><li>품사 POS 구분: 낱말을 문법적 기능, 형태, 뜻에 따라 구분</li><li>NLTK는 Penn Treebank Tagset 채택<ul><li>NNP: 단수 고유명사</li><li>VB: 동사</li><li>VBP: 동사 현재형</li><li>TO: 전치사</li><li>NN: 명사</li><li>DT: 관형사</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tag <span class="keyword">import</span> pos_tag</span><br><span class="line">sentence = sent_tokenize(raw[<span class="number">203</span>:<span class="number">400</span>])[<span class="number">0</span>]</span><br><span class="line">sentence</span><br></pre></td></tr></table></figure><pre><code>&apos;And green ribbons, very fair.&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">word = word_tokenize(sentence)</span><br><span class="line">word</span><br></pre></td></tr></table></figure><pre><code>[&apos;And&apos;, &apos;green&apos;, &apos;ribbons&apos;, &apos;,&apos;, &apos;very&apos;, &apos;fair&apos;, &apos;.&apos;]</code></pre><ul><li><code>pos_tag</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tagged_list = pos_tag(word)</span><br><span class="line">tagged_list</span><br></pre></td></tr></table></figure><pre><code>[(&apos;And&apos;, &apos;CC&apos;), (&apos;green&apos;, &apos;JJ&apos;), (&apos;ribbons&apos;, &apos;NNS&apos;), (&apos;,&apos;, &apos;,&apos;), (&apos;very&apos;, &apos;RB&apos;), (&apos;fair&apos;, &apos;JJ&apos;), (&apos;.&apos;, &apos;.&apos;)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.help.upenn_tagset(<span class="string">'JJ'</span>)</span><br></pre></td></tr></table></figure><pre><code>JJ: adjective or numeral, ordinal    third ill-mannered pre-war regrettable oiled calamitous first separable    ectoplasmic battery-powered participatory fourth still-to-be-named    multilingual multi-disciplinary ...</code></pre><ul><li>filtering</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cc_list = [t[<span class="number">0</span>] <span class="keyword">for</span> t <span class="keyword">in</span> tagged_list <span class="keyword">if</span> t[<span class="number">1</span>] == <span class="string">"CC"</span>]</span><br><span class="line">cc_list</span><br></pre></td></tr></table></figure><pre><code>[&apos;And&apos;]</code></pre><ul><li><code>untag</code>: return word</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tag <span class="keyword">import</span> untag</span><br><span class="line">untag(tagged_list)</span><br></pre></td></tr></table></figure><pre><code>[&apos;And&apos;, &apos;green&apos;, &apos;ribbons&apos;, &apos;,&apos;, &apos;very&apos;, &apos;fair&apos;, &apos;.&apos;]</code></pre><hr><h4 id="pos-tagging-text-pre-processing-연습"><a href="#pos-tagging-text-pre-processing-연습" class="headerlink" title="pos tagging: text pre-processing 연습"></a>pos tagging: text pre-processing 연습</h4><ul><li>scikit-learn 자연어 분석시 “같은 토큰/다른 품사” = 다른 토큰</li><li>처리방법<ul><li>convert to “토큰/품사”</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenizer</span><span class="params">(doc)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="string">"/"</span>.join(p) <span class="keyword">for</span> p <span class="keyword">in</span> tagged_list]</span><br><span class="line"></span><br><span class="line">tokenizer(sentence)</span><br></pre></td></tr></table></figure><pre><code>[&apos;And/CC&apos;, &apos;green/JJ&apos;, &apos;ribbons/NNS&apos;, &apos;,/,&apos;, &apos;very/RB&apos;, &apos;fair/JJ&apos;, &apos;./.&apos;]</code></pre><hr><h1 id="4-text-class"><a href="#4-text-class" class="headerlink" title="4. text class"></a>4. text class</h1><ul><li><code>plot</code>: 단어token의 사용 빈도 그래프화</li><li><code>dispersion_plot</code>: 단어가 사용된 위치 시각화<ul><li>eg. 소설의 등장인물 등장 위치</li></ul></li><li><code>concordance</code>: lines 입력 갯수만큼 해당 문장 display</li><li><code>similar</code>: 해당 단어와 비슷한 문맥에서 사용된 단어</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> Text</span><br><span class="line">text = Text(retokenize.tokenize(raw))</span><br></pre></td></tr></table></figure><ul><li><code>plot</code>: 단어token의 사용 빈도 그래프화</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">text.plot(<span class="number">30</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_files/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_43_0.png" alt="png"></p><ul><li><code>dispersion_plot</code>: 단어가 사용된 위치 시각화<ul><li>eg. 소설의 등장인물 등장 위치</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">raw = nltk.corpus.gutenberg.raw(<span class="string">'austen-emma.txt'</span>)</span><br><span class="line">text = Text(retokenize.tokenize(raw))</span><br><span class="line"></span><br><span class="line">text.dispersion_plot([<span class="string">'Emma'</span>, <span class="string">'Knightly'</span>, <span class="string">'Frank'</span>, <span class="string">'Jane'</span>, <span class="string">'Robert'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_files/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_45_0.png" alt="png"></p><ul><li><code>concordance</code>: lines 입력 갯수만큼 해당 문장 display</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text.concordance(<span class="string">'Emma'</span>, lines=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>Displaying 5 of 865 matches: Emma by Jane Austen 1816 VOLUME I CHAPTER Jane Austen 1816 VOLUME I CHAPTER I Emma Woodhouse handsome clever and rich wf both daughters but particularly of Emma Between _them_ it was more the intimnd friend very mutually attached and Emma doing just what she liked highly est by her own The real evils indeed of Emma s situation were the power of having</code></pre><ul><li><code>similar</code>: 해당 단어와 비슷한 문맥에서 사용된 단어</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text.similar(<span class="string">'Emma'</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><pre><code>she it he i harriet you her jane him that</code></pre><hr><h1 id="5-FreqDist"><a href="#5-FreqDist" class="headerlink" title="5. FreqDist"></a>5. FreqDist</h1><ul><li><code>FreqDist</code>: 문서에 사용된 단어의 사용빈도 정보 담는 class</li><li>return: <code>{&#39;word&#39;: frequency}</code></li></ul><h4 id="사용법1-1"><a href="#사용법1-1" class="headerlink" title="사용법1)"></a>사용법1)</h4><ul><li><code>Text</code> class의 vocab으로 추출</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fd = text.vocab()</span><br><span class="line">type(fd)</span><br></pre></td></tr></table></figure><pre><code>nltk.probability.FreqDist</code></pre><h4 id="사용법2-1"><a href="#사용법2-1" class="headerlink" title="사용법2)"></a>사용법2)</h4><ul><li>말뭉치에서 추려낸 단어로 <code>FreqDist</code> class 객체 생성<ul><li>예) Emma.txt corpus에서 사람(NNP, 고유대명사)만 추출 &amp; apply stop words</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.help.upenn_tagset(<span class="string">'NNP'</span>)</span><br></pre></td></tr></table></figure><pre><code>NNP: noun, proper, singular    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA    Shannon A.K.C. Meltex Liverpool ...</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">emma_tokens = pos_tag(retokenize.tokenize(raw))</span><br><span class="line">len(emma_tokens), emma_tokens[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>(161983, (&apos;Emma&apos;, &apos;NN&apos;))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> FreqDist</span><br><span class="line"></span><br><span class="line">stopwords = [<span class="string">'Mr.'</span>, <span class="string">'Mrs.'</span>, <span class="string">'Miss'</span>, <span class="string">'Mr'</span>, <span class="string">'Mrs'</span>, <span class="string">'Dear'</span>]</span><br><span class="line">names_list = [t[<span class="number">0</span>] <span class="keyword">for</span> t <span class="keyword">in</span> emma_tokens <span class="keyword">if</span> t[<span class="number">1</span>] == <span class="string">"NNP"</span> <span class="keyword">and</span> t[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br><span class="line">fd_names = FreqDist(names_list)</span><br><span class="line">fd_names</span><br></pre></td></tr></table></figure><pre><code>FreqDist({&apos;Emma&apos;: 830, &apos;Harriet&apos;: 491, &apos;Weston&apos;: 439, &apos;Knightley&apos;: 389, &apos;Elton&apos;: 385, &apos;Woodhouse&apos;: 304, &apos;Jane&apos;: 299, &apos;Fairfax&apos;: 241, &apos;Churchill&apos;: 223, &apos;Frank&apos;: 208, ...})</code></pre><hr><ul><li><code>N()</code>: 전체 단어수</li><li><code>freq(&quot;word&quot;)</code>: 확률</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fd_names.N(), fd_names[<span class="string">'Emma'</span>], fd_names.freq(<span class="string">'Emma'</span>)</span><br></pre></td></tr></table></figure><pre><code>(7863, 830, 0.10555767518758744)</code></pre><ul><li><code>most_common</code>: 출현빈도 높은 단어</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fd_names.most_common(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>[(&apos;Emma&apos;, 830), (&apos;Harriet&apos;, 491), (&apos;Weston&apos;, 439), (&apos;Knightley&apos;, 389), (&apos;Elton&apos;, 385)]</code></pre><hr><h1 id="6-wordcloud"><a href="#6-wordcloud" class="headerlink" title="6. wordcloud"></a>6. wordcloud</h1><ul><li><code>FreqDist</code> 활용</li><li>단어 빈도수에 따른 시각화</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line">wc = WordCloud(width=<span class="number">1000</span>, height=<span class="number">600</span>, background_color=<span class="string">'white'</span>, random_state=<span class="number">0</span>)</span><br><span class="line">plt.imshow(wc.generate_from_frequencies(fd_names))</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_files/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_65_0.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> text </tag>
            
            <tag> preprocessing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>&lt;How to create hexo github page&gt;</title>
      <link href="/2019/01/26/how-to-create-hexo-github-page/"/>
      <url>/2019/01/26/how-to-create-hexo-github-page/</url>
      
        <content type="html"><![CDATA[<h3 id="install-Node-js"><a href="#install-Node-js" class="headerlink" title="install Node.js"></a>install Node.js</h3><pre><code>$ wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.11/install.sh</code></pre><h3 id="install-hexo"><a href="#install-hexo" class="headerlink" title="install hexo"></a>install hexo</h3><pre><code>$ npm install hexo-cli -g$ hexo init blog # blog = &lt;file name&gt;$ cd blog</code></pre><h3 id="set-theme"><a href="#set-theme" class="headerlink" title="set theme"></a>set theme</h3><pre><code>$ git clone https://github.com/probberechts/hexo-theme-cactus.git themes/cactus$ vi _config.yml</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theme: cactus</span><br></pre></td></tr></table></figure><h3 id="setting-deploy-config"><a href="#setting-deploy-config" class="headerlink" title="setting deploy config."></a>setting deploy config.</h3><pre><code>$ npm install hexo-deployer-git --save$ vi _config.yml</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: https://github.com/HenryPaik1/HenryPaik1.github.io.git</span><br></pre></td></tr></table></figure><h3 id="apply-modification-amp-run-hexo-server"><a href="#apply-modification-amp-run-hexo-server" class="headerlink" title="apply modification &amp; run hexo server"></a>apply modification &amp; run hexo server</h3><pre><code>$ hexo g$ hexo s</code></pre><h3 id="sync-github"><a href="#sync-github" class="headerlink" title="sync github"></a>sync github</h3><pre><code>$ hexo d</code></pre><p><strong>refernce:</strong><br><a href="https://github.com/probberechts/hexo-theme-cactus" target="_blank" rel="noopener">https://github.com/probberechts/hexo-theme-cactus</a><br><a href="https://hexo.io/docs/commands" target="_blank" rel="noopener">https://hexo.io/docs/commands</a></p>]]></content>
      
      
      <categories>
          
          <category> github </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
