<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>[Stat] 결정계(Coefficient of Determination, r squared)</title>
      <link href="/2019/02/23/Recap_rsquareok/"/>
      <url>/2019/02/23/Recap_rsquareok/</url>
      
        <content type="html"><![CDATA[<h1 id="결정계수-R-2-Coefficient-of-Determination"><a href="#결정계수-R-2-Coefficient-of-Determination" class="headerlink" title="결정계수($R^2$, Coefficient of Determination)"></a>결정계수($R^2$, Coefficient of Determination)</h1><a id="more"></a><script type="math/tex; mode=display">R^2 = 1 - \dfrac{RSS}{TSS}=\dfrac{ESS}{TSS} \\TSS = RSS + ESS\\RSS = \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 \\TSS = \sum_{i=1}^N (y_i - \bar{y})^2</script><ul><li>y값이 퍼진 정도보다, $\hat{y}$가 퍼진 정도가 클 수는 없음<ul><li>직관적으로 생각해보면, $\hat{y}$이 산점한 y의 중앙을 뚫고 지나가기 때문에 이해가능</li></ul></li><li>기하학적으로 보면, <strong>$\hat{y}$는 잔차$e$를 최소화</strong>하는 값을 찾았기 때문에(OLS) 아래와 같이 설명 가능</li></ul><script type="math/tex; mode=display">||y||^2 = ||\hat{y}||^2 + ||e||^2</script><ul><li>아래 그림에서는:<ul><li>$||y||^2 = ||b||^2$</li><li>$||\hat{y}||^2 = ||A\hat{x}||$</li><li>$||e||^2 = ||b-A \hat{x}||^2$</li></ul></li></ul><p style="text-align:center">    <img src="/Recap_rsquared_files/OLS.png" width="500">    (https://slideplayer.com/slide/2342847/)</p>    <h1 id="조정결정계수-adjusted-R-2"><a href="#조정결정계수-adjusted-R-2" class="headerlink" title="조정결정계수 (adjusted $R^2$)"></a>조정결정계수 (adjusted $R^2$)</h1><ul><li>독립변수 갯수에 따라 결정 계수의 값을 조정</li></ul><h3 id="질문"><a href="#질문" class="headerlink" title="질문"></a>질문</h3><ul><li>상수항 없을 때 결정계수값이 높은 이유?<ul><li>계산시 TSS가 커짐 -&gt; $R^2$가 커짐</li></ul></li><li>with intercept<script type="math/tex; mode=display">R^2 = 1 - \frac{\sum_i (y_i - \hat y_i)^2}{\sum_i (y_i - \bary)^2}</script></li><li>without intercept<script type="math/tex; mode=display">R_0^2 = 1 - \frac{\sum_i (y_i - \hat y_i)^2}{\sum_i y_i^2}</script></li><li>reference:<br>  <a href="https://stats.stackexchange.com/questions/26176/removal-of-statistically-significant-intercept-term-increases-r2-in-linear-mo" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/26176/removal-of-statistically-significant-intercept-term-increases-r2-in-linear-mo</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Stat </tag>
            
            <tag> Regression </tag>
            
            <tag> r_squared </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] Command Cheat Sheet(on going)</title>
      <link href="/2019/02/17/linuxchaet/"/>
      <url>/2019/02/17/linuxchaet/</url>
      
        <content type="html"><![CDATA[<pre><code>1) show only dir. whithin current dir: ls -d */</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cmd </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] netstat to check network status</title>
      <link href="/2019/02/17/netstat/"/>
      <url>/2019/02/17/netstat/</url>
      
        <content type="html"><![CDATA[<p><code>netstat</code> is used to check port status.<br><a id="more"></a><br><code>net-tools</code> pkg includes <code>netstat</code><br>1) install<br>    $ sudo apt update<br>    $ sudo apt install net-tools</p><p>current status of port</p><p>2)<br>    $ sudo netstat —program —listening —numeric  —tcp</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> netstat </tag>
            
            <tag> net-tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Math] Covariance and Correlation</title>
      <link href="/2019/02/16/Recap_covandcorr/"/>
      <url>/2019/02/16/Recap_covandcorr/</url>
      
        <content type="html"><![CDATA[<h1 id="공분산-covariance-amp-상관계수-correlation-coefficient"><a href="#공분산-covariance-amp-상관계수-correlation-coefficient" class="headerlink" title="공분산(covariance) &amp; 상관계수(correlation coefficient)"></a>공분산(covariance) &amp; 상관계수(correlation coefficient)</h1><a id="more"></a><h2 id="다변수-확률변수-간의-상관관계-표현"><a href="#다변수-확률변수-간의-상관관계-표현" class="headerlink" title="- 다변수 확률변수 간의 상관관계 표현"></a>- <strong>다변수 확률변수 간의 상관관계 표현</strong></h2><h2 id="1-공분산"><a href="#1-공분산" class="headerlink" title="1. 공분산"></a>1. 공분산</h2><script type="math/tex; mode=display">Cov[X, Y] = E[(X-E[X])(Y-E[Y])]</script><h3 id="표본공분산-sample-covariance"><a href="#표본공분산-sample-covariance" class="headerlink" title="표본공분산(sample covariance)"></a>표본공분산(sample covariance)</h3><ul><li>절대값: 무의미</li><li>부호: <strong>데이터 간 상관관계 방향</strong>(x의 $\bar{x}$ 대비 증감에 따른 y의 $\bar{y}$ 대비 증감)</li></ul><script type="math/tex; mode=display">s_{xy} = \dfrac{1}{N} \sum_{i=1}^N(x_i - \bar{x})(y_i - \bar{y})</script><ul><li>$(\bar{x}, \bar{y})$를 원점으로 $(x-\bar{x}) \times (y-\bar{y})$ 사각형의 면적으로 계산<ul><li>음수 면적 존재</li></ul></li></ul><h2 id="2-상관계수"><a href="#2-상관계수" class="headerlink" title="2. 상관계수"></a>2. 상관계수</h2><ul><li>공분산 normalize<script type="math/tex; mode=display">\rho[X, Y] = \dfrac{Cov[X, Y]} {\sqrt{Var[X] \cdot Var[Y]}}</script></li></ul><h3 id="표본상관계수-correlation-coefficient"><a href="#표본상관계수-correlation-coefficient" class="headerlink" title="표본상관계수(correlation coefficient)"></a>표본상관계수(correlation coefficient)</h3><ul><li>절대값: 변수 간 <strong>(의존)크기=선형(직선)관계 크기</strong> 표현(scatter_plot 선형 정도)<ul><li>즉, x알면 y를 알 수 있는 정도</li><li>비선형은 catch 불완전<ul><li>eg. 2차함수: x알면 y 100% 맞출 수 있지만(완전한 상관관계 존재), corr값은 0 가능</li></ul></li></ul></li><li>부호: 데이터 상관관계 방향<ul><li><strong>중요</strong>: scatter plot의 <strong>기울기</strong> 절대값 크기는 <strong>상관계수와 아무런 의미 없음</strong><script type="math/tex; mode=display">r_{xy} = \dfrac{s_{xy}}{\sqrt{s_x^2 s_y^2}}</script></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 상관계수의 예</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">corrs = [<span class="number">1</span>, <span class="number">.7</span>, <span class="number">.3</span>, <span class="number">-.3</span>, <span class="number">-.7</span>, <span class="number">-1</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">mean = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i, r <span class="keyword">in</span> enumerate(corrs):</span><br><span class="line">    cov = [[<span class="number">1</span>, r], [r, <span class="number">1</span>]]</span><br><span class="line">    x, y = np.random.multivariate_normal(mean, cov, size=<span class="number">1000</span>).T</span><br><span class="line">    plt.subplot(<span class="number">1</span>, len(corrs), i+<span class="number">1</span>)</span><br><span class="line">    plt.plot(x, y, <span class="string">'ro'</span>, ms=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#     plt.axis('equal')</span></span><br><span class="line">    plt.title(<span class="string">r"$\rho=&#123;&#125;$"</span>.format(r))</span><br><span class="line">    plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.suptitle(<span class="string">"corr and scatter_plot"</span>, y=<span class="number">1.1</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_covandcorr_files/Recap_covandcorr_1_0.png" alt=""></p><p>reference</p><ul><li><a href="https://datascienceschool.net/view-notebook/4cab41c0d9cd4eafaff8a45f590592c5/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/4cab41c0d9cd4eafaff8a45f590592c5/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> covariance </tag>
            
            <tag> correlation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] ARIMA 모델 모수추정 일반</title>
      <link href="/2019/02/14/Recap_TimeSeries(0)_ok/"/>
      <url>/2019/02/14/Recap_TimeSeries(0)_ok/</url>
      
        <content type="html"><![CDATA[<h1 id="확률과정-모형-추정"><a href="#확률과정-모형-추정" class="headerlink" title="확률과정 모형 추정"></a>확률과정 모형 추정</h1><a id="more"></a><h3 id="1-결정론적-추세-Deterministic-Trend-제거"><a href="#1-결정론적-추세-Deterministic-Trend-제거" class="headerlink" title="1. 결정론적 추세(Deterministic Trend) 제거"></a>1. 결정론적 추세(Deterministic Trend) 제거</h3><pre><code>- 다항식 추세</code></pre><h3 id="2-확률적-추세-Stochastic-Trend-제거"><a href="#2-확률적-추세-Stochastic-Trend-제거" class="headerlink" title="2. 확률적 추세(Stochastic Trend) 제거"></a>2. 확률적 추세(Stochastic Trend) 제거</h3><pre><code>- ARIMA- ADF 사용    - H0: 단위근 존재 -&gt; Integration 존재 -&gt; 차분필요</code></pre><h3 id="3-정규성-확인"><a href="#3-정규성-확인" class="headerlink" title="3. 정규성 확인"></a>3. 정규성 확인</h3><pre><code>- 정규성을 띠면 백색잡음 -&gt; ARMA 모형 적용가능- 일반 선형확률과정은 가우시안 정규분포 따름(백색잡음의 선형조합)- 정규성 개선을 위한 방법    - Box-Cox    - 로그변환</code></pre><h3 id="4-ARMA-모형의-차수-결정"><a href="#4-ARMA-모형의-차수-결정" class="headerlink" title="4.  ARMA 모형의 차수 결정"></a>4.  ARMA 모형의 차수 결정</h3><pre><code>- MA: ACF가 특정차수이상에서 사라짐(cut-off)- AR: PACF가 특정차수이상에서 사라짐- ARMA: ACF/PACF가 특정차수이상에서 사라지지 않음    - 모수추정: AIC/BIC, MML/LM/MLE 등 사용    - bootstrapping으로 모수의 표준오차 추정</code></pre><h3 id="5-모형-진단"><a href="#5-모형-진단" class="headerlink" title="5. 모형 진단"></a>5. 모형 진단</h3><pre><code>- 잔차 정규성 검정- 잔차에 ACF/PACF/Ljung-Box(H0: k=0이외 상관계수0) Q검정으로 모형 차수 재확인</code></pre><hr><h1 id="Tip"><a href="#Tip" class="headerlink" title="Tip"></a>Tip</h1><h3 id="1-로그변환-및-Box-Cox-변환"><a href="#1-로그변환-및-Box-Cox-변환" class="headerlink" title="1) 로그변환 및 Box-Cox 변환"></a>1) 로그변환 및 Box-Cox 변환</h3><h4 id="왜-사용-to-get-constant-variance-rightarrow-and-then-detrend-rightarrow-stationary-process"><a href="#왜-사용-to-get-constant-variance-rightarrow-and-then-detrend-rightarrow-stationary-process" class="headerlink" title="왜 사용? to get constant variance $\rightarrow$ and then detrend $\rightarrow$ stationary process"></a>왜 사용? to get constant variance $\rightarrow$ and then detrend $\rightarrow$ stationary process</h4><ul><li>비정상확률 과정 중 시간t에 의존하여 기댓값 및 분산이 변하는 경우</li><li>eg. 기댓값은 t에 의존, 표준편차는 $\mu$에 의존<script type="math/tex; mode=display">E[Y_t] = \mu_t = f(t) \\\sqrt{Var[Y_t]} = \mu_t \sigma \\E[\log{Y_t}] = \log{\mu_t} \\Var[\log{Y_t}] \approx \sigma^2 \rightarrow \text{constant}</script></li><li>cf. log는 차분 후에도 trend가 잡히지 않을 경우에도 사용<ul><li>즉, 시점이 변함에 따라 증가하다가, 일정 시점 이후부터 급격히 증가하는 자료의 경우, 차분을 여러번 해도 trend가 안 잡힘 $/rightarrow$ log변환 후 차분</li></ul></li></ul><h3 id="2-모형구분"><a href="#2-모형구분" class="headerlink" title="2) 모형구분"></a>2) 모형구분</h3><ul><li>AR vs MA: 모두 백색잡음 $\epsilon$의 선형 조합. ACF &amp; PACF로 구분 가능</li><li>ARMA(Stationary) vs ARIMA(Non-Stationary): 특성방정식이 다름. ADF로 구분 가능<ul><li>ARMA(p, q)<script type="math/tex; mode=display">Y_t = \phi_1Y_{t-1}+ \cdots + \phi_p Y_{t-p} + \cdots</script></li><li>ARIMA(p, 1, q):<script type="math/tex; mode=display">Y_t = (1+\phi_1)Y_t + (\phi_2 - \phi_1)Y_{t-1} + \cdots + (\phi_p - \phi_{p-1})Y_{t-p} - \phi_p Y_{t-p-1} + \cdots</script></li></ul></li></ul><h3 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h3><p><img src="/Recap_TimeSeries%280%29_ok_files\acfvspacf.png" alt="http://stat.snu.ac.kr/time/download/%EC%8B%9C%EA%B3%84%EC%97%B4%EB%B6%84%EC%84%9D6%EC%9E%A5%EA%B0%95%EC%9D%98.pdf"></p><h1 id="예제-MA-amp-AR의-ACF-amp-PACF-비교"><a href="#예제-MA-amp-AR의-ACF-amp-PACF-비교" class="headerlink" title="예제) MA &amp; AR의 ACF &amp; PACF 비교"></a>예제) MA &amp; AR의 ACF &amp; PACF 비교</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ma</span></span><br><span class="line">theta = <span class="number">0.6</span></span><br><span class="line">ar = [<span class="number">1</span>]</span><br><span class="line">ma = [<span class="number">1</span>, theta]</span><br><span class="line">a = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">s = a.generate_sample(<span class="number">20</span>, burnin=<span class="number">240</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>,<span class="number">7</span>))</span><br><span class="line">plt.subplot(<span class="number">411</span>)</span><br><span class="line">plt.stem(a.acf(<span class="number">20</span>))</span><br><span class="line">plt.subplot(<span class="number">412</span>)</span><br><span class="line">plt.stem(a.pacf(<span class="number">20</span>))</span><br><span class="line"></span><br><span class="line">ax=plt.subplot(<span class="number">413</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(s, ax=ax)</span><br><span class="line">ax=plt.subplot(<span class="number">414</span>)</span><br><span class="line">sm.tsa.graphics.plot_pacf(s, method=<span class="string">'ywm'</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_4_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AR</span></span><br><span class="line">phi = <span class="number">0.6</span></span><br><span class="line">ar = [<span class="number">1</span>, phi]</span><br><span class="line">ma = [<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">a = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">s = a.generate_sample(<span class="number">20</span>, burnin=<span class="number">240</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>,<span class="number">7</span>))</span><br><span class="line">plt.subplot(<span class="number">411</span>)</span><br><span class="line">plt.stem(a.acf(<span class="number">20</span>))</span><br><span class="line">plt.subplot(<span class="number">412</span>)</span><br><span class="line">plt.stem(a.pacf(<span class="number">20</span>))</span><br><span class="line"></span><br><span class="line">ax=plt.subplot(<span class="number">413</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(s, ax=ax)</span><br><span class="line">ax=plt.subplot(<span class="number">414</span>)</span><br><span class="line">sm.tsa.graphics.plot_pacf(s, method=<span class="string">'ywm'</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_5_0.png" alt=" "></p><h2 id="예제-Shampoo-Sales-Dataset"><a href="#예제-Shampoo-Sales-Dataset" class="headerlink" title="예제) Shampoo Sales Dataset"></a>예제) Shampoo Sales Dataset</h2><ul><li><ol><li>Deterministic Trend &amp; Seasonality</li></ol></li><li><ol><li>Stochastic Trend &amp; Seasonality: Multiplicative SARIMA</li></ol></li></ul><h3 id="Original-data"><a href="#Original-data" class="headerlink" title="Original data"></a>Original data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'shampoo.csv'</span>)</span><br><span class="line">df.dropna(inplace=<span class="keyword">True</span>)</span><br><span class="line">X = df.values[:, <span class="number">1</span>]</span><br><span class="line">plt.plot(X)</span><br><span class="line">plt.show()</span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_8_0.png" alt=" "></p><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 36 entries, 0 to 35Data columns (total 2 columns):Month                                        36 non-null objectSales of shampoo over a three year period    36 non-null float64dtypes: float64(1), object(1)memory usage: 864.0+ bytes</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parser</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> datetime.strptime(<span class="string">'190'</span> + x[<span class="string">'Month'</span>], <span class="string">'%Y-%m'</span>)</span><br><span class="line"></span><br><span class="line">df[<span class="string">'Month'</span>] = df.apply(parser, axis=<span class="number">1</span>)</span><br><span class="line">df = df.rename_axis(<span class="string">'order'</span>).reset_index()</span><br><span class="line">df.columns = [<span class="string">'order'</span>, <span class="string">'date'</span>, <span class="string">'val'</span>]</span><br><span class="line">df[<span class="string">'order'</span>] = df[<span class="string">'order'</span>] + <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MA 아님</span></span><br><span class="line">sm.tsa.graphics.plot_acf(df[<span class="string">'val'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_11_0.png" alt=" "></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AR(2) 가능성</span></span><br><span class="line">sm.tsa.graphics.plot_pacf(df[<span class="string">'val'</span>], method=<span class="string">'ywm'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_12_0.png" alt=" "></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sm.tsa.adfuller(df[<span class="string">'val'</span>])</span><br></pre></td></tr></table></figure><pre><code>(3.060142083641183, 1.0, 10, 25, {&#39;1%&#39;: -3.7238633119999998, &#39;5%&#39;: -2.98648896, &#39;10%&#39;: -2.6328004}, 278.9972644263031)</code></pre><hr><h2 id="1-Deterministic-Trend-amp-Seasonality"><a href="#1-Deterministic-Trend-amp-Seasonality" class="headerlink" title="1. Deterministic Trend &amp; Seasonality"></a>1. Deterministic Trend &amp; Seasonality</h2><h3 id="1-결정론적-추세-확인-linear"><a href="#1-결정론적-추세-확인-linear" class="headerlink" title="1) 결정론적 추세 확인: linear"></a>1) 결정론적 추세 확인: linear</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">f = <span class="string">"val ~ order"</span></span><br><span class="line">mod = sm.OLS.from_formula(f, df)</span><br><span class="line">res = mod.fit()</span><br><span class="line">print(res.summary())</span><br></pre></td></tr></table></figure><pre><code>                            OLS Regression Results                            ==============================================================================Dep. Variable:                    val   R-squared:                       0.730Model:                            OLS   Adj. R-squared:                  0.722Method:                 Least Squares   F-statistic:                     91.97Date:                Thu, 14 Feb 2019   Prob (F-statistic):           3.37e-11Time:                        22:07:16   Log-Likelihood:                -207.13No. Observations:                  36   AIC:                             418.3Df Residuals:                      34   BIC:                             421.4Df Model:                           1                                         Covariance Type:            nonrobust                                         ==============================================================================                 coef    std err          t      P&gt;|t|      [0.025      0.975]------------------------------------------------------------------------------Intercept     89.1371     26.723      3.336      0.002      34.829     143.445order         12.0791      1.260      9.590      0.000       9.519      14.639==============================================================================Omnibus:                        3.174   Durbin-Watson:                   1.937Prob(Omnibus):                  0.205   Jarque-Bera (JB):                2.703Skew:                           0.666   Prob(JB):                        0.259Kurtosis:                       2.827   Cond. No.                         43.4==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">t = df.order; y = df.val</span><br><span class="line">trend1 = res.params[<span class="number">0</span>] + res.params[<span class="number">1</span>]*t</span><br><span class="line">plt.plot(t, y, <span class="string">'-'</span>)</span><br><span class="line">plt.plot(t, trend1, <span class="string">'-'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_18_0.png" alt=" "></p><h3 id="2-결정론적-추세-확인-quadratic"><a href="#2-결정론적-추세-확인-quadratic" class="headerlink" title="2) 결정론적 추세 확인: quadratic"></a>2) 결정론적 추세 확인: quadratic</h3><ul><li>r sqaure 더 높음</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">f = <span class="string">"val ~ order + I(order**2)"</span></span><br><span class="line">mod = sm.OLS.from_formula(f, df)</span><br><span class="line">res = mod.fit()</span><br><span class="line">print(res.summary())</span><br></pre></td></tr></table></figure><pre><code>                            OLS Regression Results                            ==============================================================================Dep. Variable:                    val   R-squared:                       0.832Model:                            OLS   Adj. R-squared:                  0.821Method:                 Least Squares   F-statistic:                     81.51Date:                Thu, 14 Feb 2019   Prob (F-statistic):           1.71e-13Time:                        22:07:24   Log-Likelihood:                -198.63No. Observations:                  36   AIC:                             403.3Df Residuals:                      33   BIC:                             408.0Df Model:                           2                                         Covariance Type:            nonrobust                                         =================================================================================                    coef    std err          t      P&gt;|t|      [0.025      0.975]---------------------------------------------------------------------------------Intercept       202.8789     33.300      6.092      0.000     135.129     270.629order            -5.8801      4.150     -1.417      0.166     -14.324       2.563I(order ** 2)     0.4854      0.109      4.461      0.000       0.264       0.707==============================================================================Omnibus:                        2.850   Durbin-Watson:                   3.055Prob(Omnibus):                  0.241   Jarque-Bera (JB):                2.222Skew:                           0.608   Prob(JB):                        0.329Kurtosis:                       2.971   Cond. No.                     1.92e+03==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 1.92e+03. This might indicate that there arestrong multicollinearity or other numerical problems.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">trend2 = res.params[<span class="number">0</span>] + res.params[<span class="number">1</span>] * t + res.params[<span class="number">2</span>] * (t**<span class="number">2</span>)</span><br><span class="line">plt.plot(t, y, <span class="string">'-'</span>)</span><br><span class="line">plt.plot(t, trend2, <span class="string">'-'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_21_0.png" alt=" "></p><h3 id="3-remove-determinstic-trend-only"><a href="#3-remove-determinstic-trend-only" class="headerlink" title="3) remove determinstic trend only"></a>3) remove determinstic trend only</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'diff'</span>] = df[<span class="string">'val'</span>] - trend1</span><br><span class="line">df[<span class="string">'diff2'</span>] = df[<span class="string">'val'</span>] - trend2</span><br><span class="line">df[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>order</th>      <th>date</th>      <th>val</th>      <th>diff</th>      <th>diff2</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>1901-01-01</td>      <td>266.0</td>      <td>164.783784</td>      <td>68.515884</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>1901-02-01</td>      <td>145.9</td>      <td>32.604710</td>      <td>-47.160121</td>    </tr>    <tr>      <th>2</th>      <td>3</td>      <td>1901-03-01</td>      <td>183.1</td>      <td>57.725637</td>      <td>-6.506894</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>1901-04-01</td>      <td>119.3</td>      <td>-18.153436</td>      <td>-67.824437</td>    </tr>    <tr>      <th>4</th>      <td>5</td>      <td>1901-05-01</td>      <td>180.3</td>      <td>30.767490</td>      <td>-5.312748</td>    </tr>  </tbody></table></div><h3 id="4-1-plotting-linear-vs-quadratic"><a href="#4-1-plotting-linear-vs-quadratic" class="headerlink" title="4.1) plotting: linear vs quadratic"></a>4.1) plotting: linear vs quadratic</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(df.order, df[<span class="string">'val'</span>], label=<span class="string">'original'</span>)</span><br><span class="line">plt.plot(df.order, df[<span class="string">'diff'</span>], label=<span class="string">'trend: linear'</span>)</span><br><span class="line">plt.plot(df.order, df[<span class="string">'diff2'</span>], label=<span class="string">'trend: quadratic'</span>)</span><br><span class="line">plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_25_0.png" alt=" "></p><h3 id="4-2-plotting-resid-linear-vs-quadratic"><a href="#4-2-plotting-resid-linear-vs-quadratic" class="headerlink" title="4.2) plotting resid: linear vs quadratic"></a>4.2) plotting resid: linear vs quadratic</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(df.order - df[<span class="string">'diff'</span>], label=<span class="string">'trend: linear'</span>)</span><br><span class="line">plt.plot(df.order - df[<span class="string">'diff2'</span>], label=<span class="string">'trend: quadratic'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_27_0.png" alt=" "></p><h3 id="5-remove-Trend-amp-Seasonality"><a href="#5-remove-Trend-amp-Seasonality" class="headerlink" title="5) remove Trend &amp; Seasonality"></a>5) remove Trend &amp; Seasonality</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'cat'</span>] = df[<span class="string">'order'</span>] % <span class="number">15</span></span><br><span class="line">df[<span class="string">'cat'</span>].astype(<span class="string">'category'</span>)</span><br><span class="line">f = <span class="string">'val ~ C(cat) + order + I(order**2) - 1'</span></span><br><span class="line">mod = sm.OLS.from_formula(f, df)</span><br><span class="line">res = mod.fit()</span><br><span class="line">print(res.summary())</span><br></pre></td></tr></table></figure><pre><code>                            OLS Regression Results                            ==============================================================================Dep. Variable:                    val   R-squared:                       0.958Model:                            OLS   Adj. R-squared:                  0.924Method:                 Least Squares   F-statistic:                     27.41Date:                Thu, 14 Feb 2019   Prob (F-statistic):           8.58e-10Time:                        22:07:43   Log-Likelihood:                -173.44No. Observations:                  36   AIC:                             380.9Df Residuals:                      19   BIC:                             407.8Df Model:                          16                                         Covariance Type:            nonrobust                                         =================================================================================                    coef    std err          t      P&gt;|t|      [0.025      0.975]---------------------------------------------------------------------------------C(cat)[0]       174.7258     39.418      4.433      0.000      92.224     257.228C(cat)[1]       262.7115     30.125      8.721      0.000     199.658     325.765C(cat)[2]       128.9006     30.535      4.221      0.000      64.990     192.811C(cat)[3]       253.1511     30.877      8.199      0.000     188.526     317.776C(cat)[4]       130.1963     31.149      4.180      0.001      65.000     195.392C(cat)[5]       198.3030     31.355      6.324      0.000     132.676     263.930C(cat)[6]       197.2711     31.498      6.263      0.000     131.346     263.196C(cat)[7]       277.3137     37.662      7.363      0.000     198.485     356.142C(cat)[8]       186.0607     38.172      4.874      0.000     106.167     265.955C(cat)[9]       199.0857     38.599      5.158      0.000     118.298     279.874C(cat)[10]      151.8388     38.942      3.899      0.001      70.333     233.345C(cat)[11]      297.0200     39.200      7.577      0.000     214.974     379.066C(cat)[12]      146.5293     39.374      3.722      0.001      64.119     228.939C(cat)[13]      198.5167     39.465      5.030      0.000     115.915     281.118C(cat)[14]      142.2322     39.478      3.603      0.002      59.603     224.861order            -5.5256      3.059     -1.806      0.087     -11.928       0.877I(order ** 2)     0.4860      0.081      6.027      0.000       0.317       0.655==============================================================================Omnibus:                        0.957   Durbin-Watson:                   2.711Prob(Omnibus):                  0.620   Jarque-Bera (JB):                0.508Skew:                           0.290   Prob(JB):                        0.776Kurtosis:                       3.053   Cond. No.                     8.31e+03==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 8.31e+03. This might indicate that there arestrong multicollinearity or other numerical problems.</code></pre><h3 id="6-plotting"><a href="#6-plotting" class="headerlink" title="6) plotting"></a>6) plotting</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.plot(df[<span class="string">'val'</span>], label=<span class="string">'orginal'</span>)</span><br><span class="line">plt.plot(res.fittedvalues, label=<span class="string">'seasonality+deterministic trend'</span>, lw=<span class="number">3</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># residual</span></span><br><span class="line">plt.subplot(<span class="number">212</span>)</span><br><span class="line">plt.plot(res.resid, label=<span class="string">'residuals'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.legend.Legend at 0x7f4c44182240&gt;</code></pre><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_31_1.png" alt=" "></p><h3 id="7-1-잔차검정-정규성-pass"><a href="#7-1-잔차검정-정규성-pass" class="headerlink" title="7.1) 잔차검정: 정규성 pass"></a>7.1) 잔차검정: 정규성 pass</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.probplot(res.resid, plot=plt)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_33_0.png" alt=" "></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.shapiro(res.resid)</span><br></pre></td></tr></table></figure><pre><code>(0.986703634262085, 0.9349536895751953)</code></pre><h3 id="7-2-잔차검정-이분산성"><a href="#7-2-잔차검정-이분산성" class="headerlink" title="7.2) 잔차검정: 이분산성"></a>7.2) 잔차검정: 이분산성</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(res.fittedvalues, res.resid)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x7f4c428741d0&gt;</code></pre><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_36_1.png" alt=" "></p><h3 id="7-3-잔차검정-자기상관계수-ACF"><a href="#7-3-잔차검정-자기상관계수-ACF" class="headerlink" title="7.3) 잔차검정: 자기상관계수 ACF"></a>7.3) 잔차검정: 자기상관계수 ACF</h3><ul><li>lag=0 이외에 상관관계 존재 -&gt; 잔차 독립조건 위배</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(<span class="number">211</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(res.resid, ax=ax1, lags=<span class="number">15</span>)</span><br><span class="line">ax2 = plt.subplot(<span class="number">212</span>)</span><br><span class="line">sm.tsa.graphics.plot_pacf(res.resid, ax=ax2, lags=<span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_38_0.png" alt=" "></p><h3 id="7-3-Ljung-Box-검정"><a href="#7-3-Ljung-Box-검정" class="headerlink" title="7.3) Ljung-Box 검정"></a>7.3) Ljung-Box 검정</h3><ul><li>잔차가 독립적이라면, 귀무가설(ACF값이 lag=k까지 모두 0) 성립해야 함</li><li>아래는 기각</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val, pval = sm.stats.diagnostic.acorr_ljungbox(res.resid)</span><br><span class="line">plt.stem(pval)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="\Recap_TimeSeries%280%29_ok_files/Recap_TimeSeries%280%29_ok_40_0.png" alt=" "></p><h2 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h2><ul><li>결정론적 모델 부적합</li></ul><hr><ul><li>reference<ul><li><a href="https://www.ltrr.arizona.edu/webhome/dmeko/geos585a.html#cdownload" target="_blank" rel="noopener">https://www.ltrr.arizona.edu/webhome/dmeko/geos585a.html#cdownload</a></li><li><a href="https://datascienceschool.net/view-notebook/e4b52228ac5749418d51409fdc4f9cef/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/e4b52228ac5749418d51409fdc4f9cef/</a></li><li><a href="https://machinelearningmastery.com/time-series-trends-in-python/" target="_blank" rel="noopener">https://machinelearningmastery.com/time-series-trends-in-python/</a></li><li><a href="http://stat.snu.ac.kr/time/download/%EC%8B%A4%EC%8A%B5%EA%B0%95%EC%9D%983.pdf" target="_blank" rel="noopener">http://stat.snu.ac.kr/time/download/%EC%8B%A4%EC%8A%B5%EA%B0%95%EC%9D%983.pdf</a></li></ul></li></ul><h2 id="자가질문"><a href="#자가질문" class="headerlink" title="자가질문"></a>자가질문</h2><ul><li>pacf lag=0에서 1이 안되는 이유: 자료가 작아서 lag이 너무 크면 계산에 오류 발생? No, method=’ywm’(biased method)</li><li>How to know if a model is deterministic or stochastic model?<ul><li>detrend 후 잔차가 백색잡음이면 stochastic model</li></ul></li><li>determinisitic &amp; stochastic trend &amp; seasonality 동시에 존재 가능?</li><li>왜 detrend하고 나서 regression으로 seasonality 찾으면 안되는지?</li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 시계열모수추정 </tag>
            
            <tag> Timeseries_process </tag>
            
            <tag> Timeseries_log_transform </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] Restart ubuntu wifi without reboot</title>
      <link href="/2019/02/14/restartwifi/"/>
      <url>/2019/02/14/restartwifi/</url>
      
        <content type="html"><![CDATA[<p>Wifi under Ubuntu env often fail to find signal.<br>Here is how to restart Wifi setting without reboot.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lshw -C network 2&gt;&amp;1 | grep wireless | grep driver</span><br></pre></td></tr></table></figure></p><pre><code># need &quot;driver=&#39;name&#39;&quot; for a next step&gt;&gt; configuration: broadcast=yes driver=iwlwifi driverversion=4.15.0-45-generic firmware=18.168.6.1 latency=0 link=no multicast=yes wireless=IEEE 802.11</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo modprobe -r iwlwifi &amp;&amp; sudo modprobe iwlwifi</span><br></pre></td></tr></table></figure><p>Clear.</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> network </tag>
            
            <tag> wifi </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[ML] 차원의 저주 (Curse of Dimensionality)</title>
      <link href="/2019/02/13/Recap_Curse_of_dimensionalityok/"/>
      <url>/2019/02/13/Recap_Curse_of_dimensionalityok/</url>
      
        <content type="html"><![CDATA[<h1 id="차원의-저주-Curse-of-Dimensionality"><a href="#차원의-저주-Curse-of-Dimensionality" class="headerlink" title="차원의 저주 Curse of Dimensionality"></a>차원의 저주 Curse of Dimensionality</h1><a id="more"></a><h3 id="1-의미-차원이-커서-분석에-어려움을-겪음"><a href="#1-의미-차원이-커서-분석에-어려움을-겪음" class="headerlink" title="1) 의미: 차원이 커서 분석에 어려움을 겪음"></a>1) 의미: 차원이 커서 분석에 어려움을 겪음</h3><h3 id="2-문제"><a href="#2-문제" class="headerlink" title="2) 문제:"></a>2) 문제:</h3><h4 id="A-Computational-Problem"><a href="#A-Computational-Problem" class="headerlink" title="A. Computational Problem"></a>A. Computational Problem</h4><h4 id="B-Sparse-Matrices"><a href="#B-Sparse-Matrices" class="headerlink" title="B. Sparse Matrices"></a>B. Sparse Matrices</h4><ul><li>데이터 간의 거리 증가<ul><li>eg. n차원 상의 점 $p(p_1, \cdots, p_n), q(q_1, \cdots, q_n)$ 의 거리<script type="math/tex; mode=display">d(p, q) = \sqrt{\sum_{i=1}^n (p_i - q_i)^2}</script></li></ul></li><li><p>데이터 간 평균 거리(avg distance, euclidean distance) 유지하려면, 기하급수적으로 많은 데이터 필요($\text{dim}^n$)</p></li><li><p>Poor Prediction</p><ul><li>hard to find pattern $\rightarrow$ cannot train similar features</li><li>lots of Params, but almost useless $\rightarrow$ likely to overtif to noise</li></ul></li></ul><h3 id="2-해결책"><a href="#2-해결책" class="headerlink" title="2) 해결책"></a>2) 해결책</h3><ul><li>Feature Selection</li><li>PCA(주성분, 잠재변수latent variable)<ul><li>데이터 분포에서 variance가 큰 방향의 벡터에 데이터를 정사영</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 차원의저주 </tag>
            
            <tag> Curse_of_Dimensionality </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Math] 고유값 분해 (Eigen Value Decomposition)</title>
      <link href="/2019/02/13/Recap_evdok/"/>
      <url>/2019/02/13/Recap_evdok/</url>
      
        <content type="html"><![CDATA[<h1 id="고유값-분해-Eigen-Value-Decomposition"><a href="#고유값-분해-Eigen-Value-Decomposition" class="headerlink" title="고유값 분해(Eigen Value Decomposition)"></a>고유값 분해(Eigen Value Decomposition)</h1><a id="more"></a><ul><li>정방행렬 B에 대해$Bv = \lambda v$ 를 만족하는 고유값$\lambda$, 벡터$v$를 찾는 작업</li><li>즉, 선형변환B에 의한 결과가 자기자신의 상수배가 되는, 0이 아닌 벡터(고유벡터)를 구하는 작업<ul><li>고유벡터 $v$: 선형변환 B에 대해 방향이 보존되는 방향벡터<ul><li>고유벡터간 orthogonal</li></ul></li><li>고유값 $\lambda$: 벡터 크기 스케일링 정도</li></ul></li></ul><h2 id="대각화"><a href="#대각화" class="headerlink" title="대각화"></a>대각화</h2><ul><li>고유벡터행렬V로 행렬A를 표현<script type="math/tex; mode=display">A = V \Lambda V^T</script></li></ul><h3 id="예제-아래-행렬B를-고유값-분해-하시오"><a href="#예제-아래-행렬B를-고유값-분해-하시오" class="headerlink" title="예제: 아래 행렬B를 고유값 분해 하시오"></a>예제: 아래 행렬B를 고유값 분해 하시오</h3><script type="math/tex; mode=display">B =\begin{bmatrix}2 & 3 \\2 & 1\end{bmatrix}</script><ul><li>$Bv = \lambda v$ 증명하시오</li></ul><h3 id="1-np-linalg-eig"><a href="#1-np-linalg-eig" class="headerlink" title="1) np.linalg.eig"></a>1) <code>np.linalg.eig</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">B = np.array([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">             [<span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line">B</span><br></pre></td></tr></table></figure><pre><code>array([[2, 3],       [2, 1]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w, v = np.linalg.eig(B)</span><br></pre></td></tr></table></figure><h3 id="2-eigen-val-amp-vec"><a href="#2-eigen-val-amp-vec" class="headerlink" title="2) eigen val &amp; vec"></a>2) eigen val &amp; vec</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># eigen values</span></span><br><span class="line">w</span><br></pre></td></tr></table></figure><pre><code>array([ 4., -1.])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lambda1 = w[<span class="number">0</span>]</span><br><span class="line">lambda2 = w[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># eigen vectors: normalized</span></span><br><span class="line">v</span><br></pre></td></tr></table></figure><pre><code>array([[ 0.83205029, -0.70710678],       [ 0.5547002 ,  0.70710678]])</code></pre><h3 id="3-manually-calculated-eigen-vec"><a href="#3-manually-calculated-eigen-vec" class="headerlink" title="3) manually calculated eigen vec"></a>3) manually calculated eigen vec</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">v1 = np.array([[<span class="number">3</span>],</span><br><span class="line">               [<span class="number">2</span>]])</span><br><span class="line">v2 = np.array([[<span class="number">-1</span>],</span><br><span class="line">               [<span class="number">1</span>]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">norm1 = np.sqrt(np.dot(v1.T,v1))</span><br><span class="line">norm1 = np.squeeze(norm1)</span><br><span class="line">norm2 = np.sqrt(np.dot(v2.T, v2))</span><br><span class="line">norm2 = np.squeeze(norm2)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">normal_v1 = v1 / norm1</span><br><span class="line">normal_v2 = v2 / norm2</span><br><span class="line">normal_v1</span><br></pre></td></tr></table></figure><pre><code>array([[0.83205029],       [0.5547002 ]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.concatenate([normal_v1, normal_v2], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>array([[ 0.83205029, -0.70710678],       [ 0.5547002 ,  0.70710678]])</code></pre><h3 id="4-Bv-lambda-v"><a href="#4-Bv-lambda-v" class="headerlink" title="4) $Bv = \lambda v$"></a>4) $Bv = \lambda v$</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Bv = lambda v</span></span><br><span class="line">np.dot(B, normal_v1) == lambda1 * normal_v1</span><br><span class="line">np.dot(B, normal_v2) == lambda2 * normal_v2</span><br></pre></td></tr></table></figure><pre><code>array([[ True],       [ True]])</code></pre>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 고유값분해 </tag>
            
            <tag> eigenvalue </tag>
            
            <tag> eigenvector </tag>
            
            <tag> 대각화 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] Make alias</title>
      <link href="/2019/02/11/alias/"/>
      <url>/2019/02/11/alias/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Execute-application-on-Linux"><a href="#1-Execute-application-on-Linux" class="headerlink" title="1) Execute application on Linux"></a>1) Execute application on Linux</h1><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ path/application_name</span><br></pre></td></tr></table></figure><h1 id="2-Execute-app-by-alias"><a href="#2-Execute-app-by-alias" class="headerlink" title="2) Execute app by alias"></a>2) Execute app by alias</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ alias shortcut_key=&quot;path/app&quot;</span><br></pre></td></tr></table></figure><p>eg.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ alias Typora=&quot;/home/henry/Documents/app/Typora-linux-x64/Typora&quot;</span><br></pre></td></tr></table></figure></p><h1 id="3-Use-alias-permanently"><a href="#3-Use-alias-permanently" class="headerlink" title="3) Use alias permanently"></a>3) Use alias permanently</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ gedit ~/.bashrc</span><br><span class="line">~~</span><br><span class="line">and add `alias Typora=&quot;/home/henry/Documents/app/Typora-linux-x64/Typora&quot;`</span><br><span class="line">at the bottom.</span><br><span class="line">After then,</span><br></pre></td></tr></table></figure><p>$ source ~/.bashrc<br>~~~</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> alias </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Math] Singular Value Decomposition, SVD</title>
      <link href="/2019/02/11/Recap_SVD/"/>
      <url>/2019/02/11/Recap_SVD/</url>
      
        <content type="html"><![CDATA[<h1 id="특이값-분해-Singular-Value-Decomposition-SVD"><a href="#특이값-분해-Singular-Value-Decomposition-SVD" class="headerlink" title="특이값 분해(Singular Value Decomposition, SVD)"></a>특이값 분해(Singular Value Decomposition, SVD)</h1><a id="more"></a><ul><li>활용: 1) 차원감소 2) 압축 3) 잠재변수 분석 4) PCA보다 계산 속도 빠름<script type="math/tex; mode=display">A = U \Sigma V^T ( m \times n)</script></li><li>$U: \text{left singular vector}, orthogonal, m \times m, \text{eigen-vector of } AA^T$</li><li>$V: \text{right singular vector}, orthogonal, n \times n, \text{eigen-vector of } A^TA$</li><li>$\text{The diagonal entries of } \Sigma: \text{singular values of A} A$<ul><li>$\text{singular-value}^2$ = eigen-value</li></ul></li></ul><h2 id="예제-영화-평점"><a href="#예제-영화-평점" class="headerlink" title="예제) 영화 평점"></a>예제) 영화 평점</h2><ul><li>A ~ E 영화 5편(column)에 관객 7명(index)이 평점 부여</li><li>영화는 SF, Romance 두가지 부류</li><li>관객들은 SF, Romance에 대한 기호가 확실</li></ul><h3 id="1-SVD"><a href="#1-SVD" class="headerlink" title="1) SVD"></a>1) SVD</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">             [<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">             [<span class="number">4</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">             [<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">             [<span class="number">0</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">4</span>,<span class="number">4</span>],</span><br><span class="line">             [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">5</span>,<span class="number">5</span>],</span><br><span class="line">             [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">2</span>]])</span><br><span class="line">A</span><br></pre></td></tr></table></figure><pre><code>array([[1, 1, 1, 0, 0],       [3, 3, 3, 0, 0],       [4, 4, 4, 0, 0],       [5, 5, 5, 0, 0],       [0, 2, 0, 4, 4],       [0, 0, 0, 5, 5],       [0, 1, 0, 2, 2]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">idx1 = [<span class="string">'SF'</span>] * <span class="number">4</span></span><br><span class="line">idx2 = [<span class="string">'Romance'</span>] * <span class="number">3</span></span><br><span class="line">idx = idx1 + idx2</span><br><span class="line">idx_ = [idx + <span class="string">" lover"</span> + str(i) <span class="keyword">for</span> i, idx <span class="keyword">in</span> enumerate(idx, <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">col = list(<span class="string">'ABCDE'</span>)</span><br><span class="line">col_ = [<span class="string">"movie_"</span> + idx <span class="keyword">for</span> idx <span class="keyword">in</span> col]</span><br><span class="line">col_</span><br></pre></td></tr></table></figure><pre><code>[&#39;movie_A&#39;, &#39;movie_B&#39;, &#39;movie_C&#39;, &#39;movie_D&#39;, &#39;movie_E&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mov = pd.DataFrame(A,columns=col_, index=idx_)</span><br><span class="line">mov</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A</th>      <th>movie_B</th>      <th>movie_C</th>      <th>movie_D</th>      <th>movie_E</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>1</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>SF lover2</th>      <td>3</td>      <td>3</td>      <td>3</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>SF lover3</th>      <td>4</td>      <td>4</td>      <td>4</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>SF lover4</th>      <td>5</td>      <td>5</td>      <td>5</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>0</td>      <td>2</td>      <td>0</td>      <td>4</td>      <td>4</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>0</td>      <td>0</td>      <td>0</td>      <td>5</td>      <td>5</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>0</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>2</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">left_s, v, right_s = np.linalg.svd(A)</span><br><span class="line">print(<span class="string">" Original Matrix A: &#123;&#125; \n Left_SV: &#123;&#125; \n Right_SV: &#123;&#125; \n Singualr Values: &#123;&#125;"</span>\</span><br><span class="line">      .format(A.shape, left_s.shape, right_s.shape, v.shape))</span><br></pre></td></tr></table></figure><pre><code> Original Matrix A: (7, 5) Left_SV: (7, 7) Right_SV: (5, 5) Singualr Values: (5,)</code></pre><hr><h3 id="2-Number-of-Singular-Values"><a href="#2-Number-of-Singular-Values" class="headerlink" title="2) Number of Singular Values"></a>2) Number of Singular Values</h3><ul><li>주성분1, 2가 data의 94% 설명</li><li>영화 5편을 2개 부류로 나눌 수 있음</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SVD = pd.DataFrame(v, columns=[<span class="string">'Singular values'</span>], index=np.arange(<span class="number">1</span>,<span class="number">6</span>))</span><br><span class="line">SVD[<span class="string">'Portion'</span>] = round(SVD / SVD.sum(), <span class="number">3</span>)</span><br><span class="line">SVD[<span class="string">'Portion_cum'</span>] = SVD[<span class="string">'Portion'</span>].cumsum()</span><br><span class="line">SVD</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Singular values</th>      <th>Portion</th>      <th>Portion_cum</th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>1.248101e+01</td>      <td>0.535</td>      <td>0.535</td>    </tr>    <tr>      <th>2</th>      <td>9.508614e+00</td>      <td>0.407</td>      <td>0.942</td>    </tr>    <tr>      <th>3</th>      <td>1.345560e+00</td>      <td>0.058</td>      <td>1.000</td>    </tr>    <tr>      <th>4</th>      <td>3.046427e-16</td>      <td>0.000</td>      <td>1.000</td>    </tr>    <tr>      <th>5</th>      <td>0.000000e+00</td>      <td>0.000</td>      <td>1.000</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(SVD[<span class="string">'Portion_cum'</span>])</span><br><span class="line">plt.scatter(<span class="number">2</span>, <span class="number">0.942</span>, marker=<span class="string">'o'</span>, c=<span class="string">'red'</span>, s=<span class="number">100</span>)</span><br><span class="line">plt.xticks(np.arange(<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line">plt.xlabel(<span class="string">'Num of PC'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Cumulative Portion'</span>)</span><br><span class="line">plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="Recap_SVD_files/Recap_SVD_9_0.png" alt="png"></p><h3 id="3-Compared-with-Original-data"><a href="#3-Compared-with-Original-data" class="headerlink" title="3) Compared with Original data"></a>3) Compared with Original data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PC: 2</span></span><br><span class="line">left_s[:,:<span class="number">2</span>]</span><br></pre></td></tr></table></figure><pre><code>array([[-0.13759913, -0.02361145],       [-0.41279738, -0.07083435],       [-0.5503965 , -0.09444581],       [-0.68799563, -0.11805726],       [-0.15277509,  0.59110096],       [-0.07221651,  0.73131186],       [-0.07638754,  0.29555048]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.diag(v)[:<span class="number">2</span>, :<span class="number">2</span>]</span><br></pre></td></tr></table></figure><pre><code>array([[12.48101469,  0.        ],       [ 0.        ,  9.50861406]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">right_s[:<span class="number">2</span>, :]</span><br></pre></td></tr></table></figure><pre><code>array([[-0.56225841, -0.5928599 , -0.56225841, -0.09013354, -0.09013354],       [-0.12664138,  0.02877058, -0.12664138,  0.69537622,  0.69537622]])</code></pre><h4 id="3-1-retored-by-PCA2"><a href="#3-1-retored-by-PCA2" class="headerlink" title="3.1) retored by PCA2"></a>3.1) retored by PCA2</h4><ul><li>if Original Matrix is too sparse, this restored Matrix would be used</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">col_pc2 = [x + <span class="string">'_reversed'</span> <span class="keyword">for</span> x <span class="keyword">in</span> col_]</span><br><span class="line">restore_PC2 = pd.DataFrame(np.linalg.multi_dot([left_s[:,:<span class="number">2</span>], np.diag(v)[:<span class="number">2</span>, :<span class="number">2</span>], right_s[:<span class="number">2</span>, :]]), columns=col_pc2, index=idx_,)</span><br><span class="line">restore_PC2</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A_reversed</th>      <th>movie_B_reversed</th>      <th>movie_C_reversed</th>      <th>movie_D_reversed</th>      <th>movie_E_reversed</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>0.994042</td>      <td>1.011704</td>      <td>0.994042</td>      <td>-0.001327</td>      <td>-0.001327</td>    </tr>    <tr>      <th>SF lover2</th>      <td>2.982126</td>      <td>3.035113</td>      <td>2.982126</td>      <td>-0.003982</td>      <td>-0.003982</td>    </tr>    <tr>      <th>SF lover3</th>      <td>3.976168</td>      <td>4.046818</td>      <td>3.976168</td>      <td>-0.005309</td>      <td>-0.005309</td>    </tr>    <tr>      <th>SF lover4</th>      <td>4.970210</td>      <td>5.058522</td>      <td>4.970210</td>      <td>-0.006636</td>      <td>-0.006636</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>0.360313</td>      <td>1.292165</td>      <td>0.360313</td>      <td>4.080263</td>      <td>4.080263</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>-0.373851</td>      <td>0.734429</td>      <td>-0.373851</td>      <td>4.916721</td>      <td>4.916721</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>0.180157</td>      <td>0.646082</td>      <td>0.180157</td>      <td>2.040132</td>      <td>2.040132</td>    </tr>  </tbody></table></div><h4 id="3-2-Comparing-Original-data-with-Restored-PC2"><a href="#3-2-Comparing-Original-data-with-Restored-PC2" class="headerlink" title="3.2) Comparing Original_data with Restored_PC2"></a>3.2) Comparing Original_data with Restored_PC2</h4><ul><li>Similar with Original data</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.concat([mov, restore_PC2], axis=<span class="number">1</span>)</span><br><span class="line">df.columns=col_ + col_pc2</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A</th>      <th>movie_B</th>      <th>movie_C</th>      <th>movie_D</th>      <th>movie_E</th>      <th>movie_A_reversed</th>      <th>movie_B_reversed</th>      <th>movie_C_reversed</th>      <th>movie_D_reversed</th>      <th>movie_E_reversed</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>1</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0.994042</td>      <td>1.011704</td>      <td>0.994042</td>      <td>-0.001327</td>      <td>-0.001327</td>    </tr>    <tr>      <th>SF lover2</th>      <td>3</td>      <td>3</td>      <td>3</td>      <td>0</td>      <td>0</td>      <td>2.982126</td>      <td>3.035113</td>      <td>2.982126</td>      <td>-0.003982</td>      <td>-0.003982</td>    </tr>    <tr>      <th>SF lover3</th>      <td>4</td>      <td>4</td>      <td>4</td>      <td>0</td>      <td>0</td>      <td>3.976168</td>      <td>4.046818</td>      <td>3.976168</td>      <td>-0.005309</td>      <td>-0.005309</td>    </tr>    <tr>      <th>SF lover4</th>      <td>5</td>      <td>5</td>      <td>5</td>      <td>0</td>      <td>0</td>      <td>4.970210</td>      <td>5.058522</td>      <td>4.970210</td>      <td>-0.006636</td>      <td>-0.006636</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>0</td>      <td>2</td>      <td>0</td>      <td>4</td>      <td>4</td>      <td>0.360313</td>      <td>1.292165</td>      <td>0.360313</td>      <td>4.080263</td>      <td>4.080263</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>0</td>      <td>0</td>      <td>0</td>      <td>5</td>      <td>5</td>      <td>-0.373851</td>      <td>0.734429</td>      <td>-0.373851</td>      <td>4.916721</td>      <td>4.916721</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>0</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>2</td>      <td>0.180157</td>      <td>0.646082</td>      <td>0.180157</td>      <td>2.040132</td>      <td>2.040132</td>    </tr>  </tbody></table></div><h3 id="4-applying-PC1-PC2"><a href="#4-applying-PC1-PC2" class="headerlink" title="4) applying PC1, PC2"></a>4) applying PC1, PC2</h3><ul><li>U(left singular vectors M): user to PCA similarity M</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SVD2 = pd.DataFrame(left_s[:,:<span class="number">2</span>] ,columns=[<span class="string">'PC1'</span>, <span class="string">'PC2'</span>,], index=idx_)</span><br><span class="line">SVD2</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PC1</th>      <th>PC2</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>-0.137599</td>      <td>-0.023611</td>    </tr>    <tr>      <th>SF lover2</th>      <td>-0.412797</td>      <td>-0.070834</td>    </tr>    <tr>      <th>SF lover3</th>      <td>-0.550397</td>      <td>-0.094446</td>    </tr>    <tr>      <th>SF lover4</th>      <td>-0.687996</td>      <td>-0.118057</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>-0.152775</td>      <td>0.591101</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>-0.072217</td>      <td>0.731312</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>-0.076388</td>      <td>0.295550</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 비교: user</span></span><br><span class="line">df2 = pd.concat([mov, SVD2], axis=<span class="number">1</span>)</span><br><span class="line">df2.columns = col_ + list(SVD2.columns)</span><br><span class="line">df2</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A</th>      <th>movie_B</th>      <th>movie_C</th>      <th>movie_D</th>      <th>movie_E</th>      <th>PC1</th>      <th>PC2</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>1</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>-0.137599</td>      <td>-0.023611</td>    </tr>    <tr>      <th>SF lover2</th>      <td>3</td>      <td>3</td>      <td>3</td>      <td>0</td>      <td>0</td>      <td>-0.412797</td>      <td>-0.070834</td>    </tr>    <tr>      <th>SF lover3</th>      <td>4</td>      <td>4</td>      <td>4</td>      <td>0</td>      <td>0</td>      <td>-0.550397</td>      <td>-0.094446</td>    </tr>    <tr>      <th>SF lover4</th>      <td>5</td>      <td>5</td>      <td>5</td>      <td>0</td>      <td>0</td>      <td>-0.687996</td>      <td>-0.118057</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>0</td>      <td>2</td>      <td>0</td>      <td>4</td>      <td>4</td>      <td>-0.152775</td>      <td>0.591101</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>0</td>      <td>0</td>      <td>0</td>      <td>5</td>      <td>5</td>      <td>-0.072217</td>      <td>0.731312</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>0</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>2</td>      <td>-0.076388</td>      <td>0.295550</td>    </tr>  </tbody></table></div><h3 id="5-applying-PC1-PC2"><a href="#5-applying-PC1-PC2" class="headerlink" title="5) applying PC1, PC2"></a>5) applying PC1, PC2</h3><ul><li>movie to PC<ul><li>movie_A heavily corresponds to PC</li><li>movie_B heavily corresponds to PC</li><li>$\dots$</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">col_pca = [x + <span class="string">"_PC2"</span> <span class="keyword">for</span> x <span class="keyword">in</span> col_]</span><br><span class="line">df3 = pd.DataFrame(right_s[:<span class="number">2</span>,:], index=[<span class="string">'PC1'</span>, <span class="string">'PC2'</span>], columns=col_pca)</span><br><span class="line">df3</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A_PC2</th>      <th>movie_B_PC2</th>      <th>movie_C_PC2</th>      <th>movie_D_PC2</th>      <th>movie_E_PC2</th>    </tr>  </thead>  <tbody>    <tr>      <th>PC1</th>      <td>-0.562258</td>      <td>-0.592860</td>      <td>-0.562258</td>      <td>-0.090134</td>      <td>-0.090134</td>    </tr>    <tr>      <th>PC2</th>      <td>-0.126641</td>      <td>0.028771</td>      <td>-0.126641</td>      <td>0.695376</td>      <td>0.695376</td>    </tr>  </tbody></table></div><h4 id="4-Wrap-up"><a href="#4-Wrap-up" class="headerlink" title="4) Wrap-up"></a>4) Wrap-up</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># user to PC</span></span><br><span class="line">SVD2</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PC1</th>      <th>PC2</th>    </tr>  </thead>  <tbody>    <tr>      <th>SF lover1</th>      <td>-0.137599</td>      <td>-0.023611</td>    </tr>    <tr>      <th>SF lover2</th>      <td>-0.412797</td>      <td>-0.070834</td>    </tr>    <tr>      <th>SF lover3</th>      <td>-0.550397</td>      <td>-0.094446</td>    </tr>    <tr>      <th>SF lover4</th>      <td>-0.687996</td>      <td>-0.118057</td>    </tr>    <tr>      <th>Romance lover5</th>      <td>-0.152775</td>      <td>0.591101</td>    </tr>    <tr>      <th>Romance lover6</th>      <td>-0.072217</td>      <td>0.731312</td>    </tr>    <tr>      <th>Romance lover7</th>      <td>-0.076388</td>      <td>0.295550</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># movie to PC</span></span><br><span class="line">df3</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>movie_A_PC2</th>      <th>movie_B_PC2</th>      <th>movie_C_PC2</th>      <th>movie_D_PC2</th>      <th>movie_E_PC2</th>    </tr>  </thead>  <tbody>    <tr>      <th>PC1</th>      <td>-0.562258</td>      <td>-0.592860</td>      <td>-0.562258</td>      <td>-0.090134</td>      <td>-0.090134</td>    </tr>    <tr>      <th>PC2</th>      <td>-0.126641</td>      <td>0.028771</td>      <td>-0.126641</td>      <td>0.695376</td>      <td>0.695376</td>    </tr>  </tbody></table></div><hr><p>reference</p><ul><li><a href="https://datascienceschool.net/view-notebook/30055dc68e8f4db0b7f6e4b56a571d52/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/30055dc68e8f4db0b7f6e4b56a571d52/</a></li><li><a href="https://www.youtube.com/watch?v=P5mlg91as1c&amp;t=490s" target="_blank" rel="noopener">https://www.youtube.com/watch?v=P5mlg91as1c&amp;t=490s</a></li></ul><p>질문</p><ul><li>왜 고유값이 설명력의 ‘양’을 대변하는지</li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SVD </tag>
            
            <tag> 압축 </tag>
            
            <tag> 차원감소 </tag>
            
            <tag> 잠재변수분석LAV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Stat]누적밀도함수cdf &amp; 확률밀도함수pdf</title>
      <link href="/2019/02/08/cdf-pdf/"/>
      <url>/2019/02/08/cdf-pdf/</url>
      
        <content type="html"><![CDATA[<h1 id="1-확률모형-probability-model"><a href="#1-확률모형-probability-model" class="headerlink" title="1. 확률모형 probability model"></a>1. 확률모형 probability model</h1><a id="more"></a><ul><li>Mathmatical representation of a random phenomenon</li><li>be defined by its <strong>sample space</strong>, <strong>events</strong> within the sample spaace, and <strong>probabilities</strong> associated with each event</li><li>Data generator<ul><li>분포distribution 특성이 같은 데이터를 만듦</li><li>데이터 생성과정이 수학적으로 기술될 수 있음</li></ul></li></ul><h1 id="2-확률변수"><a href="#2-확률변수" class="headerlink" title="2. 확률변수"></a>2. 확률변수</h1><ul><li>$\omega \in \Omega \xrightarrow{Random Variable} x \in R$</li><li>$X_{Random Variable}(\omega) = x (x \in R)$<ul><li>확률이 정의된 <strong>표본공간의 모든 표본</strong>을 <strong>실수인 숫자</strong>로 바꾸는 <strong>함수</strong></li></ul></li><li>cf 참고<ul><li>표본공간Sample space: 가능한 모든 표본의 집합</li><li>확률표본Probabilistic/Random sample: 확률적 문제에서 발생가능한 하나의 현상/경우<ul><li>eg. 동전 앞면 또는 뒷면</li></ul></li></ul></li></ul><h1 id="3-확률분포함수"><a href="#3-확률분포함수" class="headerlink" title="3. 확률분포함수"></a>3. 확률분포함수</h1><ul><li>확률분포probability distribution: 어떤 사건에 어느 정도의 <strong>확률이 할당</strong>되어있는지 묘사한 정보</li><li>기술하는 방법: <strong>1) 누적분포함수cdf 2) 확률밀도함수pdf 3) 확률질량함수pmf</strong></li></ul><h2 id="1-누적분포함수-cumulative-distribution-function-cdf"><a href="#1-누적분포함수-cumulative-distribution-function-cdf" class="headerlink" title="1) 누적분포함수 cumulative distribution function, cdf"></a>1) 누적분포함수 cumulative distribution function, cdf</h2><ul><li>$F(x) = P(S_x) = P(\{ X \le x\ \})$<ul><li>$S_x = \{ -\infty \le X \le x\}$</li></ul></li><li>단조증가</li><li><strong>y</strong>: 확률</li><li>참고<ul><li>단순구간사건: $A = \{a \le x \le b \}$</li><li>확률: $P(A) = P(\{a \le x \le b \}) = P(a, b) = P(-\infty, b) - P(-\infty, a)$</li></ul></li></ul><h2 id="2-확률밀도함수-probability-denstiy-function-pdf"><a href="#2-확률밀도함수-probability-denstiy-function-pdf" class="headerlink" title="2) 확률밀도함수 probability denstiy function, pdf"></a>2) 확률밀도함수 probability denstiy function, pdf</h2><ul><li>cdf의 미분: $f(x) = \dfrac{dF(x)}{dx} $</li><li><strong>y</strong>: cdf 특정 구간의 기울기 = 특정한 구간 확률의 상대적 높이</li></ul><p>reference</p><ul><li><a href="https://datascienceschool.net/view-notebook/c46ce2d2a60d48edbc7c3e6e71394c26/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/c46ce2d2a60d48edbc7c3e6e71394c26/</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> cdf </tag>
            
            <tag> pdf </tag>
            
            <tag> random_variable </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Stat] p-value</title>
      <link href="/2019/02/08/pvalue/"/>
      <url>/2019/02/08/pvalue/</url>
      
        <content type="html"><![CDATA[<h1 id="1-p-value-유의확률"><a href="#1-p-value-유의확률" class="headerlink" title="1. p-value(유의확률)"></a>1. p-value(유의확률)</h1><a id="more"></a><ul><li><strong>귀무가설이 맞다고 가정했을 떄</strong>, 현재의 검정 통계량과 같은 표본 데이터가 발생할 확률</li><li>즉, 현재 검정통계량과 같거나, <strong>더 극단적인(extrem), 더 희귀한(are) 값</strong>이 나올 확률<ul><li><strong>유의확률이 매우 작으면</strong>, 귀무가설이 맞다는 가정하에서는, 현재 검정 통계량이 발생할 가능성이 매우 낮다는 의미 $\rightarrow$ <strong>귀무가설 기각</strong></li></ul></li></ul><h1 id="2-회귀계수-가중치의-신뢰구간-or-오차범위"><a href="#2-회귀계수-가중치의-신뢰구간-or-오차범위" class="headerlink" title="2. 회귀계수 가중치의 신뢰구간 or 오차범위"></a>2. 회귀계수 가중치의 신뢰구간 or 오차범위</h1><ul><li><p>1) 단일계수 t-test(Single Coefficient t-test)</p><ul><li>검정 통계량: 정규화된 모수오차$\dfrac{\hat{w}_i - 0}{se_i}$</li><li>$H_{0} : 회귀계수 w_i = 0$</li></ul></li><li><p>2) F-검정: 전체 회귀 계수가 모두 의미 있는지 확인</p><ul><li>$H_0 : w_1, \cdots, w_i = 0$</li></ul></li></ul><h1 id="3-표준오차"><a href="#3-표준오차" class="headerlink" title="3. 표준오차"></a>3. 표준오차</h1><ul><li><strong>표본평균의 표준편차</strong>: 모평균과 표본평균 사이에 얼마나 오차가 발생하는가</li><li>모집단에 대한 정보 제공 없음<ul><li>표본표준편차: $s_x = \dfrac{1}{n-1} \sqrt{\sum_{i=1}^n (x_i - \bar{x})^2}$</li><li>표준오차: $s.e(\hat{x}) = \dfrac{s_x}{\sqrt{n}}$</li></ul></li></ul><h1 id="3-p-value-유의할-점"><a href="#3-p-value-유의할-점" class="headerlink" title="3. p-value: 유의할 점"></a>3. p-value: 유의할 점</h1><ul><li>데이터가 많아지면, 표준오차는 작아짐</li><li>p-value는 data와 null hypothesis의 거리를 측정하는 것이므로 데이터가 많아지면 p-value는 siginificant로 나옴<ul><li>예컨대, $\hat{\beta} = 1, SE( \beta ) = 0.2$라면 $\hat{beta}$은 0으로부터 SE단위(0.2) 5만큼 떨어져 있는 것  </li></ul></li></ul><hr><p>reference</p><ul><li><a href="http://www.galitshmueli.com/system/files/Largesample-12-6-2012.pdf" target="_blank" rel="noopener">http://www.galitshmueli.com/system/files/Largesample-12-6-2012.pdf</a></li><li><a href="https://stats.stackexchange.com/questions/197676/why-do-t-test-use-standard-error-and-not-standard-deviation" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/197676/why-do-t-test-use-standard-error-and-not-standard-deviation</a></li><li><a href="https://datascienceschool.net/view-notebook/743cdedec523447a907b2b0abda45533/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/743cdedec523447a907b2b0abda45533/</a><br>질문</li><li>pvalue문제 어떻게 해결</li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> Stat </tag>
            
            <tag> p-value </tag>
            
            <tag> 표준오차 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] 일반 선형확률과정 ARMA / ARIMA(5)</title>
      <link href="/2019/02/04/Recap_TimeSeries_ARMA_ARIMA(5)ok/"/>
      <url>/2019/02/04/Recap_TimeSeries_ARMA_ARIMA(5)ok/</url>
      
        <content type="html"><![CDATA[<h2 id="일반-선형확률과정-모형-general-linear-process-model"><a href="#일반-선형확률과정-모형-general-linear-process-model" class="headerlink" title="일반 선형확률과정 모형(general linear process model)"></a>일반 선형확률과정 모형(general linear process model)</h2><a id="more"></a><h3 id="3-ARMA-p-q"><a href="#3-ARMA-p-q" class="headerlink" title="3) ARMA(p, q)"></a>3) ARMA(p, q)</h3><ul><li>AR과 구분 불가 cf. AR 간에도 p차 구분불가</li><li>MA &amp; AR은 구분 가능</li></ul><script type="math/tex; mode=display">Y_t = -\phi_1 Y_{t-1} -\phi_2 Y_{t-2} - \phi_3 Y_{t-3} - \cdots + \epsilon_t \\+ \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}</script><ul><li><p>AR(p)와 MA(q) 성질 모두 가지는 모형</p><ul><li>$AR(p): Y_t = -\phi_1 Y_{t-1} - \phi_2 Y_{t-2} - \cdots$</li><li>$MA(q): Y_t = \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}$</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">ARMA(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment">#샘플링</span></span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">phi = <span class="number">0.7</span>; theta = <span class="number">-0.4</span></span><br><span class="line">ar=[<span class="number">1</span>, -phi];ma=[<span class="number">1</span>, theta]</span><br><span class="line">p1 = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">y1 = p1.generate_sample(<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">411</span>)</span><br><span class="line">plt.plot(y1, <span class="string">'o-'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">412</span>)</span><br><span class="line">plt.stem(p1.acf(<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">413</span>)</span><br><span class="line">sm.graphics.tsa.plot_acf(y1, lags=<span class="number">100</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">414</span>)</span><br><span class="line">sm.graphics.tsa.plot_pacf(y1, lags=<span class="number">100</span>, ax=ax, method=<span class="string">'ywm'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_ARMA_ARIMA%285%29ok_files/Recap_TimeSeries_ARMA_ARIMA%285%29ok_1_0.png" alt=""><br><img src="/Recap_TimeSeries_ARMA_ARIMA%285%29ok_files/pacf.png" alt=""></p><h3 id="4-ARIMA-모형-비정상과정"><a href="#4-ARIMA-모형-비정상과정" class="headerlink" title="4) ARIMA 모형: 비정상과정"></a>4) ARIMA 모형: 비정상과정</h3><ul><li>차분한 결과 $\nabla Y_t = Y_t - Y_{t-1}$가 ARMA 모형</li><li>ARIMA(p, d, q): $\nabla^d Y_t = ARMA(p, q) \rightarrow$ d번 차분 후 ARMA</li><li>특징: 자기상관계수 빠르게 감소하지 않음</li></ul><h3 id="4-1-단위근-특성"><a href="#4-1-단위근-특성" class="headerlink" title="4.1) 단위근 특성"></a>4.1) 단위근 특성</h3><ul><li>$(Y_t - Y_{t-1}) + \phi_1(Y_{t-1} - Y_{t-2}) + \cdots + \phi_p (Y_{t-p} - Y_{t-p-1}) =\\<br>  \epsilon_t + \theta_1 \epsilon_{t-1} + \cdots + \theta_q \epsilon_{t-q}$</li><li>ARIMA(p, 1, q)모형은 특성 방정식 해가 x=1 단위근 가짐</li><li>특성방정식: $(1-x)(1 + \phi_1 x + \cdots + \phi_p x^p)=0$</li></ul><h3 id="4-2-단위근-검정-ADF-Augmented-Dickey-Fuller-test"><a href="#4-2-단위근-검정-ADF-Augmented-Dickey-Fuller-test" class="headerlink" title="4.2) 단위근 검정: ADF(Augmented Dickey-Fuller) test"></a>4.2) 단위근 검정: ADF(Augmented Dickey-Fuller) test</h3><ul><li>DF 일반화</li><li>H0: 적분차수1 이상<ul><li><code>sm.tsa.adfuller</code><ul><li>adf: test statistic</li><li>pvalue: float</li></ul></li></ul></li></ul><h3 id="예-IMA-1-1"><a href="#예-IMA-1-1" class="headerlink" title="예) IMA(1, 1)"></a>예) IMA(1, 1)</h3><ul><li>$Y_t - Y_{t-1} = \epsilon_t - \theta \epsilon_{t-1}$</li><li>$Y_t = \epsilon_t + (1-\theta) \epsilon_{t-1} + (1 - \theta) \epsilon_{t-2} + (1-\theta) \epsilon_{t-3} \cdots +$</li><li>백색잡음의 누적 cumulation</li></ul><h3 id="예-IMA-2-2"><a href="#예-IMA-2-2" class="headerlink" title="예) IMA(2, 2)"></a>예) IMA(2, 2)</h3><ul><li>$(Y_t - Y _{t-1}) - (Y_{t-1} - Y_{t-2}) = \epsilon_t - \theta_1 \epsilon_{t-1} - \theta_2 \epsilon_{t-2}$</li></ul><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#IMA(2,2): theta1 = 1, theta2 = -0.6</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">theta1 = <span class="number">1</span>; theta2 = <span class="number">-0.6</span></span><br><span class="line">ar = [<span class="number">1</span>]; ma=[<span class="number">1</span>, theta1, theta2]</span><br><span class="line">p = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">sample = p.generate_sample(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">y2 = sample.cumsum().cumsum()</span><br><span class="line">y1 = np.diff(y2)</span><br><span class="line">y0 = np.diff(y1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># y0 = sample</span></span><br><span class="line"><span class="comment"># y1 = y0.cumsum()</span></span><br><span class="line"><span class="comment"># y2 = y1.cumsum()</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">313</span>)</span><br><span class="line">plt.title(<span class="string">'IMA(2,1): diff(2)'</span>)</span><br><span class="line">plt.plot(y0, <span class="string">'o-'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">312</span>)</span><br><span class="line">plt.title(<span class="string">'IMA(2,1): diff(1)'</span>)</span><br><span class="line">plt.plot(y1, <span class="string">'o-'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">311</span>)</span><br><span class="line">plt.title(<span class="string">'IMA(2,1): diff(0)'</span>)</span><br><span class="line">plt.plot(y2, <span class="string">'o-'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_ARMA_ARIMA%285%29ok_files/Recap_TimeSeries_ARMA_ARIMA%285%29ok_4_0.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">ax1 = plt.subplot(<span class="number">313</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(y0, lags=<span class="number">90</span>, ax=ax1)</span><br><span class="line">ax1.set_title(<span class="string">'ACF: IMA(2, 1): diff(2)'</span>)</span><br><span class="line"></span><br><span class="line">ax2 = plt.subplot(<span class="number">312</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(y1, lags=<span class="number">90</span>, ax=ax2)</span><br><span class="line">ax2.set_title(<span class="string">'ACF: IMA(2, 1): diff(1)'</span>)</span><br><span class="line"></span><br><span class="line">ax3 = plt.subplot(<span class="number">311</span>)</span><br><span class="line">sm.tsa.graphics.plot_acf(y2, lags=<span class="number">90</span>, ax=ax3)</span><br><span class="line">ax3.set_title(<span class="string">'ACF: IMA(2, 1): diff(0)'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.grid(<span class="keyword">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_ARMA_ARIMA%285%29ok_files/Recap_TimeSeries_ARMA_ARIMA%285%29ok_5_0.png" alt=""></p><hr><ul><li>ADF test 예시: y0 -&gt; 귀무가설 기각</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sm.tsa.adfuller(y2)</span><br></pre></td></tr></table></figure><pre><code>(-2.251162211352469, 0.1882029374890175, 8, 91, {&#39;1%&#39;: -3.50434289821397,  &#39;5%&#39;: -2.8938659630479413,  &#39;10%&#39;: -2.5840147047458037}, 307.88958150914243)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sm.tsa.adfuller(y1)</span><br></pre></td></tr></table></figure><pre><code>(-1.7069994687237129, 0.42750979630229596, 12, 86, {&#39;1%&#39;: -3.5087828609430614,  &#39;5%&#39;: -2.895783561573195,  &#39;10%&#39;: -2.5850381719848565}, 307.69019010591194)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sm.tsa.adfuller(y0)</span><br></pre></td></tr></table></figure><pre><code>(-2.5363882098874595, 0.10686979989276602, 6, 91, {&#39;1%&#39;: -3.50434289821397,  &#39;5%&#39;: -2.8938659630479413,  &#39;10%&#39;: -2.5840147047458037}, 305.82342887519786)</code></pre><hr><p>질문</p><ul><li>특성방정식 - 이해 부족</li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 일반선형확률과정 </tag>
            
            <tag> ARMA </tag>
            
            <tag> ARIMA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] 확률과정 및 시계열 이론(1)</title>
      <link href="/2019/02/04/Recap_Time%20series_theory(1)ok/"/>
      <url>/2019/02/04/Recap_Time%20series_theory(1)ok/</url>
      
        <content type="html"><![CDATA[<h1 id="확률과정-Random-process-Stochastic-process"><a href="#확률과정-Random-process-Stochastic-process" class="headerlink" title="확률과정(Random process, Stochastic process):"></a>확률과정(Random process, Stochastic process):</h1><a id="more"></a><ul><li>의미: 확률변수의 순서열(sequence of infinit random variables)</li><li>확률과정$Y = \{\cdots, Y_{-1}, Y_0, Y_{1}, \cdots\}$<ul><li>확률변수$Y_t$는 평행우주 t시간의 표본 generator</li></ul></li><li>시계열 자료는 확률 과정의 표본</li><li>앙상블 평균$E[Y_t]$: <strong>복수의 시계열 자료 표본</strong>에서 특정한 시간 t의 값만 평균(평행우주에서 $y_t$시간 값만 추출)<ul><li>현실세계는 불가능: 현실세계가 표본 하나</li><li>앙상블 평균 추정의 조건<ul><li>정상과정(stationary process) &amp; 에르고딕 과정(ergodic process)</li></ul></li></ul></li></ul><h2 id="1-확률과정의-기댓값-자기공분산-자기상관계수"><a href="#1-확률과정의-기댓값-자기공분산-자기상관계수" class="headerlink" title="1. 확률과정의 기댓값, 자기공분산, 자기상관계수"></a>1. 확률과정의 기댓값, 자기공분산, 자기상관계수</h2><ul><li>‘자기(auto)’: <strong>표본 하나의 set 내</strong>에서의 cov &amp; cor</li><li>확률과정 기댓값: $\mu_t = E[Y_t]$</li><li>자기공분산(auto-covariance): 방향 &amp; 거리<ul><li>$\gamma_{t, s}=Cov[Y_t, Y_s]=E[(Y_t - E[Y_t]) \cdot (Y_s - E[Y_s])]$</li></ul></li><li>자기상관계수(auto-correlation): 방향<ul><li>$\rho_{t,s} = \dfrac{\gamma_{t,s}}{\sqrt{\gamma_t \gamma_s}}= Corr[Y_t, Y_s] = \dfrac{Cov[Y_t, Y_s]}{\sqrt{Var[Y_t] \cdot Var[Y_s]}} \leq 1$</li></ul></li></ul><h2 id="2-정상확률과정"><a href="#2-정상확률과정" class="headerlink" title="2. 정상확률과정"></a>2. 정상확률과정</h2><ul><li>$Y_1, Y_2, \cdots$의 평균, 표준오차 등이 변하지 않음.</li><li><strong>쉽게 말하자면, 평균, 분산 등 모멘트 공식에 절대시간 t변수가 없고, 시차 k변수가 존재(이후 MA, AR 모델 등에서 확인)</strong></li><li>즉, 에르고딕 성질에 의해, 표본들이 하나의 generator에서 생성됨</li></ul><h3 id="2-1-자기공분산-시간-변수의-차이lag-k-에만-의존"><a href="#2-1-자기공분산-시간-변수의-차이lag-k-에만-의존" class="headerlink" title="2.1. 자기공분산: 시간 변수의 차이lag $k$에만 의존"></a>2.1. 자기공분산: 시간 변수의 차이lag $k$에만 의존</h3><p>$\gamma_{t, t+k} = \gamma_{0,k} \triangleq \gamma_k$</p><h3 id="2-2-자기상관계수-시간-변수의-차이lag-k-에만-의존"><a href="#2-2-자기상관계수-시간-변수의-차이lag-k-에만-의존" class="headerlink" title="2.2. 자기상관계수: 시간 변수의 차이lag $k$에만 의존"></a>2.2. 자기상관계수: 시간 변수의 차이lag $k$에만 의존</h3><p>$\rho_{t, t+k} = \rho_{0,k} \triangleq \rho_k = \dfrac{\gamma_k}{\gamma_0}$</p><ul><li>eg) ACF of AR(1): $\rho_k=\dfrac{\gamma_k}{\gamma_0}=(-\phi)^k \rightarrow \phi&lt;0$ 그래프는 진동</li></ul><h3 id="2-3-정상확률과정-특징"><a href="#2-3-정상확률과정-특징" class="headerlink" title="2.3 정상확률과정 특징"></a>2.3 정상확률과정 특징</h3><ul><li>확률과정 특성은 확률변수$Y_t$의 결합확률밀도함수 사용</li><li>협의의 정상확률과정(strictly stationary process): 모든 모멘트가 ‘절대시간’에 의존하지 않고 시차lag에만 의존<ul><li>$E[Y_t Y_{t+k_1} \cdots] = E[Y_s Y_{s+k_1 \cdots}]$</li></ul></li><li>광의의 정상확률과정(weak stationary process)<ul><li>1, 2차 모멘텀에 대해서만 ‘절대시간’ 의존하지 않음</li><li>$E[Y_t] = E[Y_s] = \mu$</li><li>$E[Y_t Y_{t+k}] = E[Y_s Y_{s+k}]$</li></ul></li><li>순수하게 백색잡음이라면, 어떤 시차lag에서도 자기상관$\rho$는 1</li></ul><h2 id="3-에르고딕-성질"><a href="#3-에르고딕-성질" class="headerlink" title="3. 에르고딕 성질"></a>3. 에르고딕 성질</h2><ul><li>정상확률 과정의 확률변수들($Y_t, Y_{t+1}, \cdots$)은 무조건부 분포 동일</li><li>따라서 현실 시계열 데이터를 <strong>하나의 분포</strong>에서 나온 <strong>표본 데이터</strong>로 간주</li><li>moment method(점 추정)에 따라 모수추정 가능: $\mu = E[X] = \bar{x}$</li></ul><h2 id="4-백색-잡음-white-noise"><a href="#4-백색-잡음-white-noise" class="headerlink" title="4. 백색 잡음 white noise"></a>4. 백색 잡음 white noise</h2><ul><li>확률과정 $\epsilon = \{\epsilon_1, \epsilon_2, \cdots\}$</li><li>$\epsilon_t \sim i.i.d$(independent and identically distributed)</li></ul><h2 id="5-랜덤-워크-Random-walk"><a href="#5-랜덤-워크-Random-walk" class="headerlink" title="5. 랜덤 워크 Random walk"></a>5. 랜덤 워크 Random walk</h2><ul><li>IMA(1,0)</li><li>과거 백색잡음의 cumsum</li></ul><hr><h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><h1 id="A1-Non-stationarity"><a href="#A1-Non-stationarity" class="headerlink" title="A1. Non-stationarity"></a>A1. Non-stationarity</h1><h2 id="Trend-amp-Seasonality"><a href="#Trend-amp-Seasonality" class="headerlink" title="Trend &amp; Seasonality"></a>Trend &amp; Seasonality</h2><ul><li>Trend</li><li>Seasonality: additive or multiplicative</li></ul><h1 id="A2-Stationarity"><a href="#A2-Stationarity" class="headerlink" title="A2. Stationarity"></a>A2. Stationarity</h1><h2 id="A-white-noise-series-sequence-of-random-numbers"><a href="#A-white-noise-series-sequence-of-random-numbers" class="headerlink" title="A white noise series(sequence of random numbers)"></a>A white noise series(sequence of random numbers)</h2><ul><li>a flat looking series</li><li>no trend</li><li>no constant variance over time</li><li>no a constant autocorrelation structure over time</li><li>no periodic fluctuations</li></ul><h1 id="A3-STL-Seasonal-and-Trend-Decomposition-using-Loess"><a href="#A3-STL-Seasonal-and-Trend-Decomposition-using-Loess" class="headerlink" title="A3. STL(Seasonal and Trend Decomposition using Loess)"></a>A3. STL(Seasonal and Trend Decomposition using Loess)</h1><h1 id="A4-Application"><a href="#A4-Application" class="headerlink" title="A4. Application"></a>A4. Application</h1><ul><li>explanation</li><li>control: identify anomal</li><li>forecasting</li></ul><h1 id="A5-Remove-trend-and-seasonality"><a href="#A5-Remove-trend-and-seasonality" class="headerlink" title="A5. Remove trend and seasonality"></a>A5. Remove trend and seasonality</h1><script type="math/tex; mode=display">X_t = \mu_t + S_t + Z_t</script><ul><li>$\mu_t$ trend component: 추정 방법 3가지<ul><li><strong>LSE</strong>: deterministic $\mu_t = f(t)$</li><li><strong>Smoothing by rolling mean</strong>: stocahstic, ARIMA</li><li><strong>Differencing</strong>: stocahstic, ARIMA</li></ul></li><li>$S_t$: seasonal component</li><li>$Z_t$: random noise component</li></ul><hr><h2 id="예시-CO2-Data"><a href="#예시-CO2-Data" class="headerlink" title="예시) CO2 Data"></a>예시) CO2 Data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">data = sm.datasets.get_rdataset(<span class="string">"CO2"</span>, package=<span class="string">"datasets"</span>)</span><br><span class="line">df = data.data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yearfraction2datetime</span><span class="params">(yearfraction, startyear=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> datetime</span><br><span class="line">    <span class="keyword">import</span> dateutil</span><br><span class="line">    year = int(yearfraction) + startyear</span><br><span class="line">    month = int(round(<span class="number">12</span> * (yearfraction - year)))</span><br><span class="line">    delta = dateutil.relativedelta.relativedelta(months=month)</span><br><span class="line">    date = datetime.datetime(year, <span class="number">1</span>, <span class="number">1</span>) + delta</span><br><span class="line">    <span class="keyword">return</span> date</span><br><span class="line"></span><br><span class="line">df[<span class="string">"datetime"</span>] = df.time.map(yearfraction2datetime)</span><br><span class="line">df[<span class="string">"month"</span>] = df.datetime.dt.month</span><br><span class="line">df.tail()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>time</th>      <th>value</th>      <th>datetime</th>      <th>month</th>    </tr>  </thead>  <tbody>    <tr>      <th>463</th>      <td>1997.583333</td>      <td>362.57</td>      <td>1997-08-01</td>      <td>8</td>    </tr>    <tr>      <th>464</th>      <td>1997.666667</td>      <td>360.24</td>      <td>1997-09-01</td>      <td>9</td>    </tr>    <tr>      <th>465</th>      <td>1997.750000</td>      <td>360.83</td>      <td>1997-10-01</td>      <td>10</td>    </tr>    <tr>      <th>466</th>      <td>1997.833333</td>      <td>362.49</td>      <td>1997-11-01</td>      <td>11</td>    </tr>    <tr>      <th>467</th>      <td>1997.916667</td>      <td>364.34</td>      <td>1997-12-01</td>      <td>12</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(df[<span class="string">'value'</span>])</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7ff3474934e0&gt;]</code></pre><p><img src="/Recap_Time%20series_theory%281%29ok_files/Recap_Time%20series_theory%281%29ok_6_1.png" alt="png"></p><p>질문</p><ul><li>Moving Average, Smoothing, differencing 관계</li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 확률과정 </tag>
            
            <tag> 정상확률과정 </tag>
            
            <tag> 랜덤워크 </tag>
            
            <tag> 백색잡음 </tag>
            
            <tag> ACF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] 일반 선형확률과정 AR(4)</title>
      <link href="/2019/02/04/Recap_TimeSeries_AR(4)ok/"/>
      <url>/2019/02/04/Recap_TimeSeries_AR(4)ok/</url>
      
        <content type="html"><![CDATA[<h2 id="일반-선형확률과정-모형-general-linear-process-model"><a href="#일반-선형확률과정-모형-general-linear-process-model" class="headerlink" title="일반 선형확률과정 모형(general linear process model)"></a>일반 선형확률과정 모형(general linear process model)</h2><a id="more"></a><h3 id="2-AR모형"><a href="#2-AR모형" class="headerlink" title="2) AR모형"></a>2) AR모형</h3><ul><li>MA모형 사용시, lag이 증가해도 $acf \ne 0$인 상태가 너무 오래 지속되는 경우(즉, q가 너무 커짐)</li><li>현재 값이, <strong>과거 자기 자신</strong>의 영향 <strong>직접</strong> 받음 + <strong>먼 과거의 백색잡음</strong> 영향 지속<ul><li>cf. MA모형: White noise를 통한 간접 관계</li></ul></li></ul><script type="math/tex; mode=display">Y_t = -\phi_1 Y_{t-1} - \phi_2 Y_{t-2} - \cdots</script><ul><li><strong>단, 계수$\phi$의 제한 조건 존재(에 따라 다름)</strong></li></ul><h3 id="예-AR-1"><a href="#예-AR-1" class="headerlink" title="예) AR(1)"></a>예) AR(1)</h3><p>$\phi(L)Y_t =  \epsilon_t$</p><p>$Y_t = -\phi Y_{t-1} + \epsilon_t$</p><p>$Y_t = \epsilon_t - \phi \epsilon_{t-1} - \phi^2 \epsilon_{t-2} - \cdots$</p><ul><li><p>$-1&lt;\phi&lt;1$</p><ul><li>cf. MA(1): $Y_t = \epsilon_t + \theta_1 \epsilon_{t-1}$</li></ul></li><li>$E[Y_t] = 0$</li><li>$Var[Y_t] = \gamma_0 = \dfrac{\sigma_{\epsilon}^2}{1-\phi^2}$</li><li>$\gamma_k = (- \phi)^k \dfrac{\sigma_{\epsilon^2}}{1-\phi^2}$ <strong>즉, AR(1)모델에서, lag=k일 때 자기공분산함수</strong><ul><li>$\rightarrow$ MA와 달리 <strong>먼 과거의 백색잡음 영향 계속 남아있음</strong></li><li>cf. <strong>MA(q)는 lag=k &gt; q이면 무조건 0</strong></li></ul></li><li>acf $\rho_k=\dfrac{\gamma_k}{\gamma_0}=(-\phi)^k \rightarrow \phi&lt;0$ 그래프는 진동</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># acf rho 예시</span></span><br><span class="line">lag_k = np.arange(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">phi = <span class="number">0.9</span></span><br><span class="line">acf = phi ** lag_k</span><br><span class="line">plt.stem(acf)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">phi = <span class="number">0.2</span></span><br><span class="line">acf = phi ** lag_k</span><br><span class="line">plt.stem(acf)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">phi = - <span class="number">0.9</span></span><br><span class="line">acf = phi ** lag_k</span><br><span class="line">plt.stem(acf)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">phi = - <span class="number">0.2</span></span><br><span class="line">acf = phi ** lag_k</span><br><span class="line">plt.stem(acf)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_AR%284%29ok_files/Recap_TimeSeries_AR%284%29ok_1_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AR(1) 샘플링</span></span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">phi = <span class="number">-0.9</span></span><br><span class="line">ar = [<span class="number">1</span>, -phi]; ma = [<span class="number">1</span>]</span><br><span class="line">p1 = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">y1 = p1.generate_sample(<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(y1, <span class="string">'o-'</span>)</span><br><span class="line">plt.title(<span class="string">"AR(1)"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_AR%284%29ok_files/Recap_TimeSeries_AR%284%29ok_2_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AR(1) acf (phi: -0.9)</span></span><br><span class="line">plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.stem(p1.acf(<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">212</span>)</span><br><span class="line">sm.graphics.tsa.plot_acf(y1, lags=<span class="number">100</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_AR%284%29ok_files/Recap_TimeSeries_AR%284%29ok_3_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AR(2) acf</span></span><br><span class="line"><span class="comment"># 자기상관 계수 0 나올 수 있음 -&gt; 진동 중 부호 바뀌는 지점</span></span><br><span class="line">phi1 = <span class="number">0.9</span>; phi2 = <span class="number">-0.6</span></span><br><span class="line">ar=[<span class="number">1</span>, -phi1, -phi2]; ma=[<span class="number">1</span>]</span><br><span class="line">p1 = sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">y1 = p1.generate_sample(<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.stem(p1.acf(<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">ax = plt.subplot(<span class="number">212</span>)</span><br><span class="line">sm.graphics.tsa.plot_acf(y1, lags=<span class="number">100</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_AR%284%29ok_files/Recap_TimeSeries_AR%284%29ok_4_0.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 일반선형확률과정 </tag>
            
            <tag> AR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] 비정상 확률과정(2)</title>
      <link href="/2019/02/04/Recap_TimeSeires(2)/"/>
      <url>/2019/02/04/Recap_TimeSeires(2)/</url>
      
        <content type="html"><![CDATA[<h2 id="비정상-확률과정"><a href="#비정상-확률과정" class="headerlink" title="비정상 확률과정"></a>비정상 확률과정</h2><a id="more"></a><ul><li>평균수준이 시간대에 따라 다름<ul><li>-&gt; 결정적Deterministic 추세: regression</li><li>-&gt; 확률적Stochastic 추세: 차분 &amp; ADF</li></ul></li><li>추세Trend 지님<ul><li>-&gt; 결정적 계절추세: regression</li><li>-&gt; 확률적 계절추세: 계절 차분</li></ul></li><li>계절성Seasonality 지님</li><li>분산 변함</li></ul><h3 id="Type-of-Non-stationary-Process"><a href="#Type-of-Non-stationary-Process" class="headerlink" title="Type of Non-stationary Process"></a>Type of Non-stationary Process</h3><ul><li>$E[y_t] \neq 0$ and change with time: 평균수준이</li><li>$Var[y_t]$ change with time -&gt; Ranom Walk</li></ul><h3 id="Random-Walk"><a href="#Random-Walk" class="headerlink" title="Random Walk"></a>Random Walk</h3><ul><li>확률과정</li><li>$\epsilon = \text{white noise}, \alpha = intercept$</li><li>1) $W_t = W_{t-1} + \epsilon_t$: Pure Random Walk</li><li>2) ST: $W_t = \alpha + W_{t-1}+\epsilon_t$: Random Walk with Drift</li><li>3) $W_t = \alpha + W_{t-1} + \beta t + \epsilon_t$: Random Walk with Drift and Derministic Trend  </li><li>cf) DT: $Y_t = \alpha + \beta t + \epsilon_t$: Deterministic Trend<br><img src="time1.gif" alt=""></li></ul><h3 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h3><h4 id="1-A-Random-Walk-with-or-without-a-drift"><a href="#1-A-Random-Walk-with-or-without-a-drift" class="headerlink" title="1. A Random Walk with or without a drift"></a>1. A Random Walk with or without a drift</h4><ul><li>Differencing: $\nabla W_t = W_t - W_{t-1}=\epsilon_t$ or $\alpha + \epsilon_t$</li><li>Detrending:<ul><li>$Y_t = \alpha + \beta t + \epsilon_t \rightarrow \nabla Y_t=$</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">df = sm.datasets.get_rdataset(<span class="string">"CanPop"</span>, package=<span class="string">"carData"</span>).data</span><br><span class="line">df.plot(x=<span class="string">'year'</span>, y=<span class="string">'population'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeires%282%29_files/Recap_TimeSeires%282%29_2_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># df = df.set_index('year')</span></span><br><span class="line">df_diff1 = df - df.shift()</span><br><span class="line">df_diff1.plot()</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f8892339390&gt;</code></pre><p><img src="/Recap_TimeSeires%282%29_files/Recap_TimeSeires%282%29_3_1.png" alt="png"></p><p>reference</p><ul><li>이론: <a href="http://www.irealism.org/xe/datascience/3226" target="_blank" rel="noopener">http://www.irealism.org/xe/datascience/3226</a></li><li>시계열 전반: <a href="https://otexts.com/fpp2/lag-plots.html" target="_blank" rel="noopener">https://otexts.com/fpp2/lag-plots.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 확률과정 </tag>
            
            <tag> 비정상확률과정 </tag>
            
            <tag> 추세 </tag>
            
            <tag> 계절성 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[시계열] 일반 선형확률과정 MA(3)</title>
      <link href="/2019/02/04/Recap_TimeSeries_MA(3)ok/"/>
      <url>/2019/02/04/Recap_TimeSeries_MA(3)ok/</url>
      
        <content type="html"><![CDATA[<h2 id="일반-선형확률과정-모형-general-linear-process-model"><a href="#일반-선형확률과정-모형-general-linear-process-model" class="headerlink" title="일반 선형확률과정 모형(general linear process model)"></a>일반 선형확률과정 모형(general linear process model)</h2><a id="more"></a><ul><li>정상확률과정stationary process</li><li><strong>가우시안 백색 잡음</strong>의 <strong>선형 조합</strong><br>$Y_t = \epsilon_t + \psi \epsilon_{t-1} + \cdots$</li><li>과거의 영향력 $\psi_n$은 계속 작아짐: $\sum_{i=1}^{\infty} \psi^2 &lt; \infty$<h3 id="1-MA-모형-과거와-간접적-관련-by-White-noise"><a href="#1-MA-모형-과거와-간접적-관련-by-White-noise" class="headerlink" title="1) MA 모형: 과거와 간접적 관련(by White noise)"></a>1) MA 모형: 과거와 간접적 관련(by White noise)</h3></li><li>MA(q)모형: 백색잡음 현재부터, <strong>q시간 지연된</strong> $\epsilon_{t-q}$까지 q+1개 항의 <strong>선형 가중합</strong><script type="math/tex; mode=display">Y_t = \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}</script></li></ul><h3 id="예-MA-1"><a href="#예-MA-1" class="headerlink" title="예) MA(1)"></a>예) MA(1)</h3><p>$Y_t = \theta(L) \epsilon_t$</p><p>$Y_t = \epsilon_t + \theta_1 \epsilon_{t-1}$</p><p>$Y_{t-1} = \epsilon_{t-1} + \theta_1 \epsilon_{t-2}$</p><ul><li>MA(1)모델<ul><li>$Y_{t}, Y_{t-1}$은 $\epsilon_{t-1}$로 <strong>간접적</strong>연결되어있음</li><li>lag=1 $\rightarrow$ 이므로 $Y_t, Y_{t-1}$ 만 상관관계 존재</li><li>$E[Y_t]=0$</li><li>$Var[Y_t]=\sigma_{\epsilon}^2(1+\theta^2)$</li><li>$Cov[Y_t, Y_{t-1}]=\theta \sigma_{\epsilon}^2$</li><li>$\rightarrow$ <strong>Indepent of “t”: Stationary</strong></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MA(1) 샘플링</span></span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">theta = <span class="number">0.9</span></span><br><span class="line">ar = [<span class="number">1</span>];ma = [<span class="number">1</span>, theta]</span><br><span class="line">p1 =  sm.tsa.ArmaProcess(ar, ma)</span><br><span class="line">y1 = p1.generate_sample(<span class="number">100</span>, burnin=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.plot(y1, <span class="string">'o-'</span>)</span><br><span class="line">plt.title(<span class="string">"MA(1)"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_MA%283%29ok_files/Recap_TimeSeries_MA%283%29ok_1_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MA(1) 자기상관계수</span></span><br><span class="line"><span class="comment"># lag=1에서 상관계수 0.5</span></span><br><span class="line">y_t_sample = y1[<span class="number">1</span>:]</span><br><span class="line">y_t_minus1_sample = y1[:<span class="number">-1</span>]</span><br><span class="line">r, p = sp.stats.pearsonr(y_t_sample, y_t_minus1_sample)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>,<span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">311</span>)</span><br><span class="line">sns.scatterplot(y_t_sample, y_t_minus1_sample)</span><br><span class="line">plt.xlabel(<span class="string">"$Y_&#123;t&#125;$"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"$Y_&#123;t-1&#125;$"</span>)</span><br><span class="line">plt.title(<span class="string">"MA(1); lag=1;\n(r=&#123;0:.3f&#125;; p=&#123;1:.3f&#125;)"</span>.format(r, p))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이론적 ACF: lag=1, 2, ..., 11 case</span></span><br><span class="line">plt.subplot(<span class="number">312</span>)</span><br><span class="line">plt.stem(p1.acf(<span class="number">11</span>))</span><br><span class="line">plt.title(<span class="string">'theoretical ACF'</span>)</span><br><span class="line"><span class="comment"># 샘플의 ACF</span></span><br><span class="line">ax = plt.subplot(<span class="number">313</span>)</span><br><span class="line">sm.graphics.tsa.plot_acf(y1, lags=<span class="number">10</span>, ax=ax)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/Recap_TimeSeries_MA%283%29ok_files/Recap_TimeSeries_MA%283%29ok_2_0.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Timeseries </tag>
            
            <tag> Math </tag>
            
            <tag> 일반선형확률과정 </tag>
            
            <tag> MA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] &quot;Brackets&quot;(Snippets) Install(Trouble shooting)</title>
      <link href="/2019/01/31/brack-install/"/>
      <url>/2019/01/31/brack-install/</url>
      
        <content type="html"><![CDATA[<h1 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h1><a id="more"></a><p>Download Brackets file from: <a href="https://github.com/adobe/brackets/releases" target="_blank" rel="noopener">https://github.com/adobe/brackets/releases</a><br>my Brackets ver. : 1.13.64-bit<br><em>It has problem with libcurl3 module which should be replaced with libcurl4.</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp ~/Downloads/Brackets.Release.1.13.64-bit.deb ~/[path]/ #path: dir you wanna install Brackets in</span><br><span class="line">$ cd [path]</span><br></pre></td></tr></table></figure></p><h1 id="Replace-libcurl3-with-liburl4"><a href="#Replace-libcurl3-with-liburl4" class="headerlink" title="Replace libcurl3 with liburl4"></a>Replace libcurl3 with liburl4</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ dpkg-deb -R ./Brackets.Release.1.13.64-bit.deb Brackets</span><br><span class="line">$ vi Brackets/DEBIAN/control</span><br></pre></td></tr></table></figure><p>and <strong>replace <code>libcurl3</code> with <code>libcurl4</code></strong></p><h1 id="Rebuild"><a href="#Rebuild" class="headerlink" title="Rebuild"></a>Rebuild</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ dpkg-deb -b Brackets Brackets-fixed.deb</span><br><span class="line">$ sudo dpkg -i Brackets-fixed.deb</span><br></pre></td></tr></table></figure><p>Maybe you encounter a warning message, but it doesn’t matter.<br>Brackets works well.</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bracket </tag>
            
            <tag> Snippets </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Math] 모수추정</title>
      <link href="/2019/01/30/Recap_%EB%AA%A8%EC%88%98%EC%B6%94%EC%A0%95%EC%9D%98%EB%AF%B8/"/>
      <url>/2019/01/30/Recap_%EB%AA%A8%EC%88%98%EC%B6%94%EC%A0%95%EC%9D%98%EB%AF%B8/</url>
      
        <content type="html"><![CDATA[<h2 id="검정test과-모수추정parameter-estimation"><a href="#검정test과-모수추정parameter-estimation" class="headerlink" title="검정test과 모수추정parameter-estimation"></a>검정test과 모수추정parameter-estimation</h2><a id="more"></a><ul><li>데이터 분석은 확률변수를 파악해가는 과정</li><li><strong>분포검정(distribution test)</strong>: 확률변수가 예상한 확률분포를 따르는지 검정<ul><li>eg. 정규성 검정(normarlity test)</li></ul></li><li><strong>모수검정(parameter test)</strong>: 분포를 정했을 때, 해당 pdf의 계수(coefficient, parameter)이 특정값을 가지는지, 또는 큰지 작은지 확인</li></ul><ul><li><strong>모수추정(parameter-estimation)</strong>: 모수가 어떤 값을 가질 확률이 가장 높은지 추정<ul><li>LSM(Least Squared Method): 가능성이 가장 큰 값 하나만 구함</li><li>MLE(Maximum Likelihood Estimation): 상동</li><li><strong>Bayesian Estimation</strong>: 가능한 모든 모수에 대해 확률 구함<ul><li>모수적(parametric) 방법: 모수 분포를 확률분포로 나타냄. Hyper Prams필요.<ul><li>데이터가 베르누이 분포 -&gt; 모수는 베타분포 따른다고 가정</li><li>데이터가 카테고리 분포 -&gt; 모수는 디리클레 분포 따른다고 가정</li></ul></li><li>비모수적(non-parametric) 방법: 모수의 분포와 동일한 분포를 가지는 숫자 집합 생성. eg. MCMC</li></ul></li></ul></li></ul><hr><h2 id="모수추정parameter-estimation"><a href="#모수추정parameter-estimation" class="headerlink" title="모수추정parameter-estimation"></a>모수추정parameter-estimation</h2><h2 id="1-최소자승법-LSM-least-squre-method"><a href="#1-최소자승법-LSM-least-squre-method" class="headerlink" title="1. 최소자승법 LSM(least squre method)"></a>1. 최소자승법 LSM(least squre method)</h2><ul><li>근사적으로 <strong>구하려는 해</strong>와, <strong>실제 해의 오차의 제곱의 합이 최소</strong>가 되는 해를 구하는 것</li><li><strong>minimizing the sum of squares of the residulas</strong></li></ul><h3 id="1-역행렬-존재"><a href="#1-역행렬-존재" class="headerlink" title="1) 역행렬 존재"></a>1) 역행렬 존재</h3><p>$Xw = y \rightarrow w=X^{-1}y$</p><ul><li>X: 계수행렬</li><li>w: 가중치 벡터(미지수벡터)</li><li>y: 상수벡터</li></ul><h3 id="2-역행렬-존재하지-않음"><a href="#2-역행렬-존재하지-않음" class="headerlink" title="2) 역행렬 존재하지 않음"></a>2) 역행렬 존재하지 않음</h3><p>$Ax=b$</p><ul><li>A: 계수 행렬</li><li>x: 미지수 벡터</li><li>b: 상수벡터<ul><li>선형 연립방정식의 해가 존재하지 않는 경우</li><li>data(방정식) &gt; Dim(미지수 갯수)</li></ul></li><li><strong>2.1) solution: 최소자승법</strong><ul><li>목표:  $Ax \approx b$ 최소화하는 $x$(미지수 벡터) 구하기</li><li>방법:</li><li>2.1.1) $\text{minimize L2 norm}$<ul><li>$Ax-b=e \rightarrow e^Te = ||e||^2=(Ax-b)^T(Ax-b)$</li><li>$x = \text{arg} \min_x e^Te$    </li></ul></li><li>2.1.2) $x = A^+b$ (pseudo inverse)<ul><li>e: 잔차(residual)</li><li>잔차벡터e L2 norm 최소화</li></ul></li></ul></li></ul><h2 id="2-최대-가능도-모수-추정-Maximum-Likelihood-Estimation"><a href="#2-최대-가능도-모수-추정-Maximum-Likelihood-Estimation" class="headerlink" title="2. 최대 가능도 모수 추정(Maximum Likelihood Estimation)"></a>2. 최대 가능도 모수 추정(Maximum Likelihood Estimation)</h2><h3 id="1-hat-theta-ML-arg-max-theta-log-L-theta-x-i"><a href="#1-hat-theta-ML-arg-max-theta-log-L-theta-x-i" class="headerlink" title="1) $\hat{\theta}_{ML} = \arg \max_{\theta} \log{L}(\theta; \{x_i\})$"></a>1) $\hat{\theta}_{ML} = \arg \max_{\theta} \log{L}(\theta; \{x_i\})$</h3><ul><li>추정한 pdf의 변수: $\theta$(params), 상수:$x$(sample)</li><li>표본: <strong>같은 확률분포</strong>에서 나온 독립적 값</li></ul><h3 id="2-가능도-함수-mathcal-L-theta-p-x-vert-theta"><a href="#2-가능도-함수-mathcal-L-theta-p-x-vert-theta" class="headerlink" title="2) 가능도 함수$\mathcal{L}(\theta)=p(x \vert \theta)$"></a>2) 가능도 함수$\mathcal{L}(\theta)=p(x \vert \theta)$</h3><h3 id="3-결합확률밀도함수-mathcal-L-theta-x-1-dots-x-N-prod-i-1-N-p-x-i-theta"><a href="#3-결합확률밀도함수-mathcal-L-theta-x-1-dots-x-N-prod-i-1-N-p-x-i-theta" class="headerlink" title="3) 결합확률밀도함수 $\mathcal{L}(\theta; x_1, \dots, x_N)=\prod_{i=1}^N p(x_i;\theta)$"></a>3) 결합확률밀도함수 $\mathcal{L}(\theta; x_1, \dots, x_N)=\prod_{i=1}^N p(x_i;\theta)$</h3><ul><li>예) $N(\mu, \sigma)$ 표본 x=1이라면, $\mu$=1일 때 pdf가 가장 높음</li></ul><h2 id="3-베이지안-모수-추정"><a href="#3-베이지안-모수-추정" class="headerlink" title="3. 베이지안 모수 추정"></a>3. 베이지안 모수 추정</h2><ul><li><strong>tartget: 모수의 사후 분포 $p_{posterior}(\mu| x_1, \dots, x_N)$</strong></li><li>모수의 값이 가질 수 있는 모든 가능성의 분포를 계산</li><li>Hyper prams: 모수$\theta$의 확률분포를 표현<h3 id="p-posterior-mu-x-1-dots-x-N-dfrac-p-likelihood-x-1-dots-x-N-mu-cdot-p-prior-mu-p-x-1-cdots-x-N"><a href="#p-posterior-mu-x-1-dots-x-N-dfrac-p-likelihood-x-1-dots-x-N-mu-cdot-p-prior-mu-p-x-1-cdots-x-N" class="headerlink" title="$p_{posterior}(\mu| x_1, \dots, x_N) = \dfrac{p_{likelihood}(x_1, \dots, x_N| \mu) \cdot p_{prior}(\mu)}{p(x_1, \cdots, x_N)}$"></a>$p_{posterior}(\mu| x_1, \dots, x_N) = \dfrac{p_{likelihood}(x_1, \dots, x_N| \mu) \cdot p_{prior}(\mu)}{p(x_1, \cdots, x_N)}$</h3></li><li>$p_{prior}(\mu)$: <em>모수</em>의 사전분포. 모수 분포 사전지식 없으면, uniform dist. $Beta(1,1)$ or Gaussian dist $N(0, 1)$</li><li>$p_{posterior}(\mu| x_1, \dots, x_N)$: 데이터(지식) 주어졌을 때 모수의 분포</li><li>$p_{likelihood}(x_1, \dots, x_N| \mu)$: 모수를 알 때, 데이터 $x_1, \dots, x_N$ 나올 수 있는 확률</li></ul><p>예제. 정규분포 기댓값 베이지안 모수 추정</p><ul><li>모수 $\mu$ 정규분포 따르는 것으로 가정</li><li>param $\sigma^2$은 알고 있다고 가정</li><li><p>$p_{posterior} \propto p_{likelihood} \cdot p_{prior} $</p></li><li><p><strong>prior</strong>: $p(\mu) = N(\mu_0, \sigma_0^2) = \dfrac{1}{\sqrt{2 \pi \sigma_0^2}}\exp(- \dfrac{(\mu - \mu_0)^2}{2 \sigma_0^2}) $</p><ul><li>$\mu_0$: unknown. $\mu_0$은 정규 분포(0, 1)를 따른다고 가정하고 시작.</li><li>즉, hyper param 초기값이 (0, 1) -&gt; 데이터 더할수록 갱신</li></ul></li><li><strong>likelihodd</strong>: $p(x_1, \cdots, x_N| \mu) = \prod_{i=1}^N N(x_i|\mu) = \prod_{i=1}^N\dfrac{1}{\sqrt{2 \pi \sigma_0^2}}\exp(- \dfrac{(x_i - \mu_0)^2}{2 \sigma_0^2}) $</li><li><strong>target:$p_{posterior}(\mu_0| x_1, \dots, x_N)$</strong><script type="math/tex; mode=display">\exp \left( -\dfrac{(\mu - \mu_0^{'})^2}{2 \sigma_0^{'2}}  \right)</script></li><li>hyper param은 데이터를 먹으면서 계속 갱신됨</li><li>즉, 아래의 $x_i$와 N에 따라 갱신</li><li><strong>다음 스텝에서는 $\mu’_0$이 $\mu_0$자리로 치환 -&gt; 새로운 데이터 바로바로 적용가능</strong><ul><li>$\mu_o^{‘}$</li><li>$\sigma_o^{‘}$<script type="math/tex; mode=display">\begin{eqnarray}\mu'_0 &=& \dfrac{\sigma^2}{N\sigma_0^2 + \sigma^2}\mu_0 + \dfrac{N\sigma_0^2}{N\sigma_0^2 + \sigma^2} \dfrac{\sum x_i}{N} \\\dfrac{1}{\sigma_0^{'2}} &=& \dfrac{1}{\sigma_0^{2}} + \dfrac{N}{\sigma^{'2}}\end{eqnarray}</script></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sp.stats.norm(mu).rvs(N)</span><br></pre></td></tr></table></figure><pre><code>array([ 2.52106488,  1.42421203,  2.14195316,  1.68067158,  2.69153875,        2.69474914,  1.27440262,  0.61663604,  0.4170616 ,  2.61037938,        0.81114074,  1.49318365,  1.40368596,  1.9474327 ,  0.06372019,        2.1887786 ,  2.52389102,  2.08842209,  1.68911383,  2.09740017,        2.39904635, -0.77259276,  3.95591231,  2.39009332,  1.34759142,        1.60904662,  2.49374178,  1.88389606, -0.03068447,  4.06449286,        1.88945934,  3.02017271,  1.30795015,  3.53637705,  2.28634369,        2.60884383,  0.95474663,  3.21114529,  2.68981816,  3.30184623,        1.37191244,  1.51897288,  4.3039167 ,  0.93998418,  1.8640503 ,        3.13689136,  2.09772497,  2.58295368,  1.60055097,  2.37005589])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sample generator</span></span><br><span class="line">mu, sigma2 = <span class="number">2</span>, <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># target: hyperparam</span></span><br><span class="line">mu0, sigma20 = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"></span><br><span class="line">xx = np.linspace(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1000</span>)</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터(지식)을 50개씩 늘려갔을 때, Posterior는 어떻게 변하는가</span></span><br><span class="line">line = [<span class="string">":"</span>, <span class="string">"-."</span>, <span class="string">"--"</span>, <span class="string">"-"</span>]</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> line:</span><br><span class="line">    N = <span class="number">50</span></span><br><span class="line">    x = sp.stats.norm(mu).rvs(N)</span><br><span class="line"></span><br><span class="line">    mu0 = sigma2 / (N*sigma20 + sigma2) * mu0 + \</span><br><span class="line">    (N * sigma20) / (N * sigma20 + sigma2) * x.mean()</span><br><span class="line">    sigma20 = <span class="number">1</span>/(<span class="number">1</span>/sigma20+ N/sigma2)</span><br><span class="line">    print(mu0)</span><br><span class="line"></span><br><span class="line">    ax.plot(xx, sp.stats.norm(mu0, sigma20).pdf(xx), ls=l, label=<span class="string">"&#123;&#125;th"</span>.format(i))</span><br><span class="line">    ax.legend()</span><br><span class="line">ax.axis([<span class="number">1.75</span>, <span class="number">2.25</span>, <span class="number">0</span>, <span class="number">25</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>1.98199932621583151.98058463032162012.07017885429149472.0303044050403543</code></pre><p><img src="/Recap_%EB%AA%A8%EC%88%98%EC%B6%94%EC%A0%95%EC%9D%98%EB%AF%B8_files/Recap_%EB%AA%A8%EC%88%98%EC%B6%94%EC%A0%95%EC%9D%98%EB%AF%B8_5_1.png" alt="png"></p><p>reference:</p><ul><li><a href="https://github.com/WillKoehrsen/probabilistic-programming/blob/master/Estimating%20Probabilities%20with%20Bayesian%20Inference.ipynb" target="_blank" rel="noopener">https://github.com/WillKoehrsen/probabilistic-programming/blob/master/Estimating%20Probabilities%20with%20Bayesian%20Inference.ipynb</a></li><li><a href="https://datascienceschool.net/view-notebook/ae35a40deb884cf88e85135b4b5a1130/" target="_blank" rel="noopener">https://datascienceschool.net/view-notebook/ae35a40deb884cf88e85135b4b5a1130/</a></li></ul><p>질문</p><ul><li>00확률분포의 모수, 의 확률분포는 00를 따르는가?<ul><li>아니다. 드물다. 이러한 사전분포는 conjugate prior이며 베타분포가 그러하다</li></ul></li><li>예제에서 hyper param 공식 유도시, 최대 가능도 함수 사용?</li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Math </tag>
            
            <tag> 모수추정 </tag>
            
            <tag> 베이지안 모수 추정 </tag>
            
            <tag> 최대가능도 </tag>
            
            <tag> 최소자승법 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Hexo] Customize hexo-cactus theme using .ejs</title>
      <link href="/2019/01/29/theme-tweak/"/>
      <url>/2019/01/29/theme-tweak/</url>
      
        <content type="html"><![CDATA[<h2 id="Example-Picture"><a href="#Example-Picture" class="headerlink" title="Example Picture"></a>Example Picture</h2><p><img src="/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_files/modifyejs.png" alt=""><br><a id="more"></a></p><h2 id="1-Change-‘Writing’-to-‘Recent-Posts’"><a href="#1-Change-‘Writing’-to-‘Recent-Posts’" class="headerlink" title="1. Change ‘Writing’ to ‘Recent Posts’"></a>1. Change ‘Writing’ to ‘Recent Posts’</h2><p><code>index.articles</code> indicates “writing”.<br>Need to change variable <code>index.articles</code> to “Recent Post”<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#path: themes&gt;cactus&gt;layout&gt;index.ejs</span><br><span class="line">&lt;section id=&quot;writing&quot;&gt;</span><br><span class="line">  &lt;span class=&quot;h1&quot;&gt;&lt;a href=&quot;&lt;%- url_for(&quot;archives&quot;) %&gt;&quot;&gt;&lt;%= __(&apos;index.articles&apos;) %&gt;&lt;/a&gt;&lt;/span&gt;</span><br><span class="line">  &lt;% if (theme.tags_overview &amp;&amp; site.tags.length) &#123; %&gt;</span><br></pre></td></tr></table></figure></p><p> <code>default.yml</code> save variables.<br> modified code:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#path: themes&gt;cactus&gt;languages&gt;default.yml</span><br><span class="line"> index:</span><br><span class="line">   find_me_on: Find me on</span><br><span class="line">   enum_comma: &apos;,&apos;</span><br><span class="line">   enum_and: and</span><br><span class="line">   articles: wrting # change to -&gt; Recent Posts</span><br><span class="line">   projects: Projects</span><br><span class="line">   topics: Topics</span><br><span class="line">   most_recent: Most recent</span><br></pre></td></tr></table></figure></p><h2 id="2-Display-Categories-on-the-first-page"><a href="#2-Display-Categories-on-the-first-page" class="headerlink" title="2. Display Categories on the first page"></a>2. Display Categories on the first page</h2><p>Note. prerequisite: categories page</p><pre><code>$ hexo new page categories</code></pre><p>and adding <code>type:categories</code> to <code>source&gt;categories&gt;index.md</code></p><p>Need to insert following code:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#path: themes&gt;cactus&gt;layout&gt;index.ejs</span><br><span class="line">&lt;section id=&quot;categories&quot; class=&quot;left&quot;&gt;</span><br><span class="line">  &lt;div class=&quot;category-list-title&quot;&gt;</span><br><span class="line">      &lt;span class=&quot;h1&quot;&gt;&lt;a href=&quot;&lt;%- url_for(&quot;categories&quot;) %&gt;&quot;&gt;&lt;%= __(&apos;nav.category&apos;) %&gt;&lt;/a&gt;&lt;/span&gt;</span><br><span class="line">      &lt;% var visibleCategories = 0 %&gt;</span><br><span class="line">      &lt;% site.categories.each(function(cat)&#123; %&gt;</span><br><span class="line">        &lt;% if (cat.length) &#123; %&gt;</span><br><span class="line">          &lt;% visibleCategories += 1 %&gt;</span><br><span class="line">        &lt;% &#125; %&gt;</span><br><span class="line">      &lt;% &#125;) %&gt;</span><br><span class="line">      &lt;%- _p(&apos;counter.categories&apos;, visibleCategories) %&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line">  &lt;div class=&quot;category-list&quot;&gt;</span><br><span class="line">    &lt;%- list_categories() %&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line">&lt;/section&gt;</span><br></pre></td></tr></table></figure></p><p>after the code below:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&lt;section id=&quot;writing&quot;&gt;</span><br><span class="line">  &lt;span class=&quot;h1&quot;&gt;&lt;a href=&quot;&lt;%- url_for(&quot;archives&quot;) %&gt;&quot;&gt;&lt;%= __(&apos;index.articles&apos;) %&gt;&lt;/a&gt;&lt;/span&gt;</span><br><span class="line">  &lt;% if (theme.tags_overview &amp;&amp; site.tags.length) &#123; %&gt;</span><br><span class="line">  &lt;span class=&quot;h2&quot;&gt;&lt;%= __(&apos;index.topics&apos;) %&gt;&lt;/span&gt;</span><br><span class="line">  &lt;span class=&quot;widget tagcloud&quot;&gt;</span><br><span class="line">    &lt;%- tagcloud(theme.tags_overview) %&gt;</span><br><span class="line">  &lt;/span&gt;</span><br><span class="line">  &lt;span class=&quot;h2&quot;&gt;&lt;%= __(&apos;index.most_recent&apos;) %&gt;&lt;/span&gt;</span><br><span class="line">  &lt;% &#125; %&gt;</span><br><span class="line">  &lt;ul class=&quot;post-list&quot;&gt;</span><br><span class="line">    &lt;% var field_sort = theme.posts_overview.sort_updated ? &apos;updated&apos; : &apos;date&apos; %&gt;</span><br><span class="line">    &lt;% if (theme.posts_overview.show_all_posts) &#123; %&gt;</span><br><span class="line">      &lt;% var show_posts = page.posts.sort(field_sort, &apos;desc&apos;) %&gt;</span><br><span class="line">    &lt;% &#125; else &#123; %&gt;</span><br><span class="line">      &lt;% var show_posts = site.posts.sort(field_sort, &apos;desc&apos;).limit(theme.posts_overview.post_count || 5) %&gt;</span><br><span class="line">    &lt;% &#125; %&gt;</span><br><span class="line">    &lt;% show_posts.each(function(post, i)&#123; %&gt;</span><br><span class="line">      &lt;li class=&quot;post-item&quot;&gt;</span><br><span class="line">        &lt;%- partial(&apos;_partial/post/date&apos;, &#123; post: post, class_name: &apos;meta&apos; &#125;) %&gt;</span><br><span class="line">        &lt;span&gt;&lt;%- partial(&apos;_partial/post/title&apos;, &#123; post: post, index: true, class_name: &apos;&apos; &#125;) %&gt;&lt;/span&gt;</span><br><span class="line">      &lt;/li&gt;</span><br><span class="line">    &lt;% &#125;); %&gt;</span><br><span class="line">  &lt;/ul&gt;</span><br><span class="line">  &lt;% if (theme.posts_overview.show_all_posts) &#123; %&gt;</span><br><span class="line">    &lt;%- partial(&apos;_partial/pagination&apos;) %&gt;</span><br><span class="line">  &lt;% &#125; %&gt;</span><br><span class="line">&lt;/section&gt;</span><br></pre></td></tr></table></figure></p><h2 id="3-Make-the-logo-stay-bright"><a href="#3-Make-the-logo-stay-bright" class="headerlink" title="3. Make the logo stay bright"></a>3. Make the logo stay bright</h2><p>Corret the code as below<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#path: theme&gt;cactus&gt;source&gt;css&gt;_partial&gt;header.styl</span><br><span class="line">#logo</span><br><span class="line">  display: inline-block</span><br><span class="line">  float: left</span><br><span class="line">  margin-right: 20px</span><br><span class="line">  width: $logo-width</span><br><span class="line">  height: $logo-height</span><br><span class="line">  border-radius: 5px</span><br><span class="line">  # delete -&gt; filter: grayscale(100%)</span><br><span class="line">  background-size: $logo-width $logo-height</span><br><span class="line">  background-repeat: no-repeat</span><br><span class="line">  # delete -&gt; -webkit-filter: grayscale(100%)</span><br></pre></td></tr></table></figure></p><p>and delete the code below:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#header:hover</span><br><span class="line">  #logo</span><br><span class="line">    filter: none</span><br><span class="line">    -webkit-filter: none</span><br></pre></td></tr></table></figure></p><h2 id="4-Place-Categoy-amp-Recent-Posts-side-by-side"><a href="#4-Place-Categoy-amp-Recent-Posts-side-by-side" class="headerlink" title="4. Place Categoy &amp; Recent Posts side by side"></a>4. Place Categoy &amp; Recent Posts side by side</h2><p>prerequisite: add class ‘.left’, ‘right’ to each section&lt;/br&gt;<br>Correct the code <code>.content</code> as below:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#path: themes&gt;cactus&gt;source&gt;CSS&gt;style.styl</span><br><span class="line">.content</span><br><span class="line">  position: relative</span><br><span class="line">  flex-wrap: wrap</span><br><span class="line">  flex-direction: row</span><br><span class="line">  min-height: 100%</span><br><span class="line">.left</span><br><span class="line">  float: left</span><br><span class="line">.right</span><br><span class="line">  float: right</span><br></pre></td></tr></table></figure></p><h2 id="5-Mange-font-color"><a href="#5-Mange-font-color" class="headerlink" title="5. Mange font color"></a>5. Mange font color</h2><p>path: themes&gt;cactus&gt;source&gt;css&gt;style.styl</p>]]></content>
      
      
      <categories>
          
          <category> Github </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] Install virtual python env</title>
      <link href="/2019/01/28/insatlling_virtual_env/"/>
      <url>/2019/01/28/insatlling_virtual_env/</url>
      
        <content type="html"><![CDATA[<h3 id="1-1-pyenv-설치"><a href="#1-1-pyenv-설치" class="headerlink" title="1.1 pyenv 설치"></a>1.1 pyenv 설치</h3><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install curl git-core gcc make zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev libssl-dev</span><br><span class="line">$ git clone https://github.com/pyenv/pyenv.git $HOME/.pyenv</span><br><span class="line">$ vim $HOME/.bashrc</span><br></pre></td></tr></table></figure><h3 id="1-2-configs-setting"><a href="#1-2-configs-setting" class="headerlink" title="1.2 configs setting"></a>1.2 configs setting</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ vi /.bash_profile</span><br><span class="line"></span><br><span class="line">export PYENV_ROOT=&quot;$HOME/.pyenv&quot;</span><br><span class="line">export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;</span><br><span class="line"></span><br><span class="line">eval &quot;$(pyenv init -)&quot;</span><br><span class="line">eval &quot;$(pyenv virtualenv-init -)&quot;</span><br></pre></td></tr></table></figure><h3 id="1-3-update"><a href="#1-3-update" class="headerlink" title="1.3 update"></a>1.3 update</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone git://github.com/pyenv/pyenv-update.git ~/.pyenv/plugins/pyenv-update</span><br></pre></td></tr></table></figure><h3 id="1-4-python-설치"><a href="#1-4-python-설치" class="headerlink" title="1.4 python 설치"></a>1.4 python 설치</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pyenv install 3.5.2</span><br></pre></td></tr></table></figure><hr><h3 id="2-1-pyenv-virtualenv-설치"><a href="#2-1-pyenv-virtualenv-설치" class="headerlink" title="2.1 pyenv-virtualenv 설치"></a>2.1 pyenv-virtualenv 설치</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenv</span><br></pre></td></tr></table></figure><h3 id="2-2-virtualenv-환경변수-추가"><a href="#2-2-virtualenv-환경변수-추가" class="headerlink" title="2.2 virtualenv 환경변수 추가"></a>2.2 virtualenv 환경변수 추가</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ echo &apos;eval &quot;$(pyenv virtualenv-init -)&quot;&apos; &gt;&gt; ~/.bash_profile</span><br><span class="line">$ source ~/.bash_profile</span><br></pre></td></tr></table></figure><h3 id="2-3-가상환경-설정"><a href="#2-3-가상환경-설정" class="headerlink" title="2.3 가상환경 설정"></a>2.3 가상환경 설정</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pyenv virtualenv 3.6.0 py3tensor</span><br></pre></td></tr></table></figure><h3 id="2-4-실행"><a href="#2-4-실행" class="headerlink" title="2.4 실행"></a>2.4 실행</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pyenv activate py3tensor</span><br></pre></td></tr></table></figure><h3 id="2-4-해제"><a href="#2-4-해제" class="headerlink" title="2.4 해제"></a>2.4 해제</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pyenv deactivate</span><br></pre></td></tr></table></figure><hr><h3 id="3-1-auto-env-설치"><a href="#3-1-auto-env-설치" class="headerlink" title="3.1 auto_env 설치"></a>3.1 auto_env 설치</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git clone git://github.com/kennethreitz/autoenv.git ~/.autoenv</span><br><span class="line">$ echo &apos;source ~/.autoenv/activate.sh&apos; &gt;&gt; ~/.bash_profile</span><br></pre></td></tr></table></figure><h3 id="3-2-local-지정"><a href="#3-2-local-지정" class="headerlink" title="3.2 local 지정"></a>3.2 local 지정</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir pyenv_test &amp;&amp; cd pyenv_test</span><br><span class="line">$ touch .env</span><br><span class="line">$ echo &quot;pyenv activate [virtualenv name]&quot; &gt; .env</span><br></pre></td></tr></table></figure><h3 id="3-3-global-해제"><a href="#3-3-global-해제" class="headerlink" title="3.3 global 해제"></a>3.3 global 해제</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vi ~/.env</span><br><span class="line">$ echo &quot;pyenv deactivate&quot; &gt; .env</span><br></pre></td></tr></table></figure><h3 id="4-1-Jupyter-notebook-for-virtual-env"><a href="#4-1-Jupyter-notebook-for-virtual-env" class="headerlink" title="4.1 Jupyter notebook for virtual env"></a>4.1 Jupyter notebook for virtual env</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ cd pyenv_test</span><br><span class="line">$ pip install ipykernel ipython</span><br><span class="line">$ mkdir /home/henry/.local/share/jupyter/kernels/py3ten</span><br><span class="line">$ vi kernel.jason</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"> &quot;argv&quot;: [ &quot;/Users/motta/.pyenv/versions/k_means/bin/python&quot;, &quot;-m&quot;, &quot;ipykernel&quot;,</span><br><span class="line">          &quot;-f&quot;, &quot;&#123;connection_file&#125;&quot;],</span><br><span class="line"> &quot;display_name&quot;: &quot;k_means&quot;,</span><br><span class="line"> &quot;language&quot;: &quot;python&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>reference:</p><p><a href="https://www.alfredo.motta.name/create-isolated-jupyter-ipython-kernels-with-pyenv-and-virtualenv/" target="_blank" rel="noopener">https://www.alfredo.motta.name/create-isolated-jupyter-ipython-kernels-with-pyenv-and-virtualenv/</a></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pyenv </tag>
            
            <tag> Python3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Linux] Create and post jupyter.md</title>
      <link href="/2019/01/28/how-to-create-jupyer/"/>
      <url>/2019/01/28/how-to-create-jupyer/</url>
      
        <content type="html"><![CDATA[<h3 id="See-the-example-below"><a href="#See-the-example-below" class="headerlink" title="See the example below:"></a>See the example below:</h3><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cd \path\to\file.md</span><br><span class="line">$ cp file.md \blog\soucre\_post\</span><br><span class="line">$ jupyer nbconvert --to markdown file.ipynb</span><br><span class="line">$ vi file.md</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># add following:</span><br><span class="line">title: &quot;jupyer notebook post&quot;</span><br><span class="line">date: 2019-01-28 00:00:00</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> Jupyter notebook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[ML] 자연어 처리(1)</title>
      <link href="/2019/01/28/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC(1)/"/>
      <url>/2019/01/28/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC(1)/</url>
      
        <content type="html"><![CDATA[<h2 id="index"><a href="#index" class="headerlink" title="index"></a>index</h2><p>자연어 처리(1)<br><a id="more"></a></p><ol><li>말뭉치(corpus)</li><li>토큰생성(tokenizing)</li></ol><ul><li>sentence unit<ul><li><code>sent_tokenize</code>: return sentence</li></ul></li><li>word unit<ul><li><code>word_tokenize</code><br>= <code>TreebankWordTokenizer</code></li><li><code>WordPunctTokenizer</code></li><li><code>RegexpTokenizer</code></li></ul></li></ul><ol><li>형태소 분석</li></ol><ul><li>어간 추출 stemming: 단순 어미 제거, 즉 정확한 어간 아님</li><li>원형 복원 lemmatizing: 같은 의미 지니는 여러 단어를 사전형으로 통일.<ul><li>품사 part of speech 지정시, 더 정확</li></ul></li><li>품사 부착 part-of-speech tagging</li></ul><p>cf. pos tagging</p><ul><li>품사 POS 구분: 낱말을 문법적 기능, 형태, 뜻에 따라 구분</li><li>NLTK는 Penn Treebank Tagset 채택<ul><li>NNP: 단수 고유명사</li><li>VB: 동사</li><li>VBP: 동사 현재형</li><li>TO: 전치사</li><li>NN: 명사</li><li>DT: 관형사</li></ul></li></ul><p>cf. pos tagging: text pre-processing 연습</p><ul><li>scikit-learn 자연어 분석시 “같은 토큰/다른 품사” = 다른 토큰</li><li>처리방법<ul><li>convert to “토큰/품사”</li></ul></li></ul><ol><li>text class</li></ol><ul><li><code>plot</code>: 단어token의 사용 빈도 그래프화</li><li><code>dispersion_plot</code>: 단어가 사용된 위치 시각화<ul><li>eg. 소설의 등장인물 등장 위치</li></ul></li><li><code>concordance</code>: lines 입력 갯수만큼 해당 문장 display</li><li><code>similar</code>: 해당 단어와 비슷한 문맥에서 사용된 단어</li></ul><ol><li>FreqDist</li></ol><ul><li><code>FreqDist</code>: 문서에 사용된 단어의 사용빈도 정보 담는 class</li><li>return: <code>{&#39;word&#39;: frequency}</code></li><li><code>N()</code>: 전체 단어수</li><li><code>freq(&quot;word&quot;)</code>: 확률</li><li><code>most_common</code>: 출현빈도 높은 단어</li></ul><p>5.1 사용법1)</p><ul><li><code>Text</code> class의 vocab으로 추출</li></ul><p>5.2 사용법2)</p><ul><li>말뭉치에서 추려낸 단어로 <code>FreqDist</code> class 객체 생성<ul><li>예) Emma.txt corpus에서 사람(NNP, 고유대명사)만 추출 &amp; apply stop words</li></ul></li><li><code>most_common</code>: 출현빈도 높은 단어</li></ul><ol><li>wordcloud</li></ol><ul><li><code>FreqDist</code> 활용</li><li>단어 빈도수에 따른 시각화</li></ul><hr><h2 id="Contents"><a href="#Contents" class="headerlink" title="Contents"></a>Contents</h2><h3 id="1-말뭉치-corpus"><a href="#1-말뭉치-corpus" class="headerlink" title="1. 말뭉치(corpus)"></a>1. 말뭉치(corpus)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">nltk.download(<span class="string">'book'</span>, quiet=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.book <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure><pre><code>*** Introductory Examples for the NLTK Book ***Loading text1, ..., text9 and sent1, ..., sent9Type the name of the text or sentence to view it.Type: &#39;texts()&#39; or &#39;sents()&#39; to list the materials.text1: Moby Dick by Herman Melville 1851text2: Sense and Sensibility by Jane Austen 1811text3: The Book of Genesistext4: Inaugural Address Corpustext5: Chat Corpustext6: Monty Python and the Holy Grailtext7: Wall Street Journaltext8: Personals Corpustext9: The Man Who Was Thursday by G . K . Chesterton 1908</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.corpus.gutenberg.fileids()</span><br></pre></td></tr></table></figure><pre><code>[&#39;austen-emma.txt&#39;, &#39;austen-persuasion.txt&#39;, &#39;austen-sense.txt&#39;, &#39;bible-kjv.txt&#39;, &#39;blake-poems.txt&#39;, &#39;bryant-stories.txt&#39;, &#39;burgess-busterbrown.txt&#39;, &#39;carroll-alice.txt&#39;, &#39;chesterton-ball.txt&#39;, &#39;chesterton-brown.txt&#39;, &#39;chesterton-thursday.txt&#39;, &#39;edgeworth-parents.txt&#39;, &#39;melville-moby_dick.txt&#39;, &#39;milton-paradise.txt&#39;, &#39;shakespeare-caesar.txt&#39;, &#39;shakespeare-hamlet.txt&#39;, &#39;shakespeare-macbeth.txt&#39;, &#39;whitman-leaves.txt&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">raw = nltk.corpus.gutenberg.raw(<span class="string">'bryant-stories.txt'</span>)</span><br><span class="line">print(raw[:<span class="number">300</span>])</span><br></pre></td></tr></table></figure><pre><code>[Stories to Tell to Children by Sara Cone Bryant 1918]TWO LITTLE RIDDLES IN RHYME     There&#39;s a garden that I ken,     Full of little gentlemen;     Little caps of blue they wear,     And green ribbons, very fair.           (Flax.)     From house to house he goes,     A me</code></pre><hr><h3 id="2-토큰생성-tokenizing"><a href="#2-토큰생성-tokenizing" class="headerlink" title="2. 토큰생성(tokenizing)"></a>2. 토큰생성(tokenizing)</h3><h4 id="sentence-unit"><a href="#sentence-unit" class="headerlink" title="sentence unit"></a>sentence unit</h4><ul><li><code>sent_tokenize</code>: return sentence</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> sent_tokenize</span><br><span class="line">sent_tokenize(raw[:<span class="number">300</span>])</span><br></pre></td></tr></table></figure><pre><code>[&quot;[Stories to Tell to Children by Sara Cone Bryant 1918] \r\n\r\n\r\nTWO LITTLE RIDDLES IN RHYME\r\n\r\n\r\n     There&#39;s a garden that I ken,\r\n     Full of little gentlemen;\r\n     Little caps of blue they wear,\r\n     And green ribbons, very fair.&quot;, &#39;(Flax.)&#39;, &#39;From house to house he goes,\r\n     A me&#39;]</code></pre><h4 id="word-unit"><a href="#word-unit" class="headerlink" title="word unit"></a>word unit</h4><ul><li><code>word_tokenize</code><br>= <code>TreebankWordTokenizer</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line">word_tokenize(<span class="string">"this's, a, test! ha."</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#39;this&#39;, &quot;&#39;s&quot;, &#39;,&#39;, &#39;a&#39;, &#39;,&#39;, &#39;test&#39;, &#39;!&#39;, &#39;ha&#39;, &#39;.&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> TreebankWordTokenizer</span><br><span class="line">tree = TreebankWordTokenizer()</span><br><span class="line">tree.tokenize(<span class="string">"this's, a, test! ha."</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#39;this&#39;, &quot;&#39;s&quot;, &#39;,&#39;, &#39;a&#39;, &#39;,&#39;, &#39;test&#39;, &#39;!&#39;, &#39;ha&#39;, &#39;.&#39;]</code></pre><ul><li><code>WordPunctTokenizer</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> WordPunctTokenizer</span><br><span class="line">punct = WordPunctTokenizer()</span><br><span class="line">punct.tokenize(<span class="string">"this's, a, test! ha."</span>)</span><br></pre></td></tr></table></figure><pre><code>[&#39;this&#39;, &quot;&#39;&quot;, &#39;s&#39;, &#39;,&#39;, &#39;a&#39;, &#39;,&#39;, &#39;test&#39;, &#39;!&#39;, &#39;ha&#39;, &#39;.&#39;]</code></pre><ul><li><code>RegexpTokenizer</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> RegexpTokenizer</span><br><span class="line">pattern = <span class="string">"[\w]+"</span></span><br><span class="line">retokenize = RegexpTokenizer(pattern)</span><br><span class="line">retokenize.tokenize(raw[<span class="number">50</span>:<span class="number">100</span>])</span><br></pre></td></tr></table></figure><pre><code>[&#39;918&#39;, &#39;TWO&#39;, &#39;LITTLE&#39;, &#39;RIDDLES&#39;, &#39;IN&#39;, &#39;RHYME&#39;, &#39;T&#39;]</code></pre><hr><h3 id="3-형태소-분석"><a href="#3-형태소-분석" class="headerlink" title="3. 형태소 분석"></a>3. 형태소 분석</h3><ul><li>어간 추출 stemming: 단순 어미 제거, 즉 정확한 어간 아님</li><li>원형 복원 lemmatizing: 같은 의미 지니는 여러 단어를 사전형으로 통일.<ul><li>품사 part of speech 지정시, 더 정확</li></ul></li><li>품사 부착 part-of-speech tagging</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words = retokenize.tokenize(raw[<span class="number">1300</span>:<span class="number">2000</span>])</span><br></pre></td></tr></table></figure><h4 id="stemming"><a href="#stemming" class="headerlink" title="stemming"></a>stemming</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br><span class="line">st = PorterStemmer()</span><br><span class="line">[(w, st.stem(w)) <span class="keyword">for</span> w <span class="keyword">in</span> words][:<span class="number">15</span>]</span><br></pre></td></tr></table></figure><pre><code>[(&#39;said&#39;, &#39;said&#39;), (&#39;a&#39;, &#39;a&#39;), (&#39;little&#39;, &#39;littl&#39;), (&#39;soft&#39;, &#39;soft&#39;), (&#39;cheery&#39;, &#39;cheeri&#39;), (&#39;voice&#39;, &#39;voic&#39;), (&#39;and&#39;, &#39;and&#39;), (&#39;I&#39;, &#39;I&#39;), (&#39;want&#39;, &#39;want&#39;), (&#39;to&#39;, &#39;to&#39;), (&#39;come&#39;, &#39;come&#39;), (&#39;in&#39;, &#39;in&#39;), (&#39;N&#39;, &#39;N&#39;), (&#39;no&#39;, &#39;no&#39;), (&#39;said&#39;, &#39;said&#39;)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> LancasterStemmer</span><br><span class="line">st = LancasterStemmer()</span><br><span class="line">[(w, st.stem(w)) <span class="keyword">for</span> w <span class="keyword">in</span> words][:<span class="number">15</span>]</span><br></pre></td></tr></table></figure><pre><code>[(&#39;said&#39;, &#39;said&#39;), (&#39;a&#39;, &#39;a&#39;), (&#39;little&#39;, &#39;littl&#39;), (&#39;soft&#39;, &#39;soft&#39;), (&#39;cheery&#39;, &#39;cheery&#39;), (&#39;voice&#39;, &#39;voic&#39;), (&#39;and&#39;, &#39;and&#39;), (&#39;I&#39;, &#39;i&#39;), (&#39;want&#39;, &#39;want&#39;), (&#39;to&#39;, &#39;to&#39;), (&#39;come&#39;, &#39;com&#39;), (&#39;in&#39;, &#39;in&#39;), (&#39;N&#39;, &#39;n&#39;), (&#39;no&#39;, &#39;no&#39;), (&#39;said&#39;, &#39;said&#39;)]</code></pre><h4 id="lemmatizing"><a href="#lemmatizing" class="headerlink" title="lemmatizing"></a>lemmatizing</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line">lm = WordNetLemmatizer()</span><br><span class="line">[(w, lm.lemmatize(w)) <span class="keyword">for</span> w <span class="keyword">in</span> words][:<span class="number">15</span>]</span><br></pre></td></tr></table></figure><pre><code>[(&#39;said&#39;, &#39;said&#39;), (&#39;a&#39;, &#39;a&#39;), (&#39;little&#39;, &#39;little&#39;), (&#39;soft&#39;, &#39;soft&#39;), (&#39;cheery&#39;, &#39;cheery&#39;), (&#39;voice&#39;, &#39;voice&#39;), (&#39;and&#39;, &#39;and&#39;), (&#39;I&#39;, &#39;I&#39;), (&#39;want&#39;, &#39;want&#39;), (&#39;to&#39;, &#39;to&#39;), (&#39;come&#39;, &#39;come&#39;), (&#39;in&#39;, &#39;in&#39;), (&#39;N&#39;, &#39;N&#39;), (&#39;no&#39;, &#39;no&#39;), (&#39;said&#39;, &#39;said&#39;)]</code></pre><hr><h4 id="pos-tagging"><a href="#pos-tagging" class="headerlink" title="pos tagging"></a>pos tagging</h4><ul><li>품사 POS 구분: 낱말을 문법적 기능, 형태, 뜻에 따라 구분</li><li>NLTK는 Penn Treebank Tagset 채택<ul><li>NNP: 단수 고유명사</li><li>VB: 동사</li><li>VBP: 동사 현재형</li><li>TO: 전치사</li><li>NN: 명사</li><li>DT: 관형사</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tag <span class="keyword">import</span> pos_tag</span><br><span class="line">sentence = sent_tokenize(raw[<span class="number">203</span>:<span class="number">400</span>])[<span class="number">0</span>]</span><br><span class="line">sentence</span><br></pre></td></tr></table></figure><pre><code>&#39;And green ribbons, very fair.&#39;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">word = word_tokenize(sentence)</span><br><span class="line">word</span><br></pre></td></tr></table></figure><pre><code>[&#39;And&#39;, &#39;green&#39;, &#39;ribbons&#39;, &#39;,&#39;, &#39;very&#39;, &#39;fair&#39;, &#39;.&#39;]</code></pre><ul><li><code>pos_tag</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tagged_list = pos_tag(word)</span><br><span class="line">tagged_list</span><br></pre></td></tr></table></figure><pre><code>[(&#39;And&#39;, &#39;CC&#39;), (&#39;green&#39;, &#39;JJ&#39;), (&#39;ribbons&#39;, &#39;NNS&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;very&#39;, &#39;RB&#39;), (&#39;fair&#39;, &#39;JJ&#39;), (&#39;.&#39;, &#39;.&#39;)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.help.upenn_tagset(<span class="string">'JJ'</span>)</span><br></pre></td></tr></table></figure><pre><code>JJ: adjective or numeral, ordinal    third ill-mannered pre-war regrettable oiled calamitous first separable    ectoplasmic battery-powered participatory fourth still-to-be-named    multilingual multi-disciplinary ...</code></pre><ul><li>filtering</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cc_list = [t[<span class="number">0</span>] <span class="keyword">for</span> t <span class="keyword">in</span> tagged_list <span class="keyword">if</span> t[<span class="number">1</span>] == <span class="string">"CC"</span>]</span><br><span class="line">cc_list</span><br></pre></td></tr></table></figure><pre><code>[&#39;And&#39;]</code></pre><ul><li><code>untag</code>: return word</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tag <span class="keyword">import</span> untag</span><br><span class="line">untag(tagged_list)</span><br></pre></td></tr></table></figure><pre><code>[&#39;And&#39;, &#39;green&#39;, &#39;ribbons&#39;, &#39;,&#39;, &#39;very&#39;, &#39;fair&#39;, &#39;.&#39;]</code></pre><hr><h4 id="pos-tagging-text-pre-processing-연습"><a href="#pos-tagging-text-pre-processing-연습" class="headerlink" title="pos tagging: text pre-processing 연습"></a>pos tagging: text pre-processing 연습</h4><ul><li>scikit-learn 자연어 분석시 “같은 토큰/다른 품사” = 다른 토큰</li><li>처리방법<ul><li>convert to “토큰/품사”</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenizer</span><span class="params">(doc)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="string">"/"</span>.join(p) <span class="keyword">for</span> p <span class="keyword">in</span> tagged_list]</span><br><span class="line"></span><br><span class="line">tokenizer(sentence)</span><br></pre></td></tr></table></figure><pre><code>[&#39;And/CC&#39;, &#39;green/JJ&#39;, &#39;ribbons/NNS&#39;, &#39;,/,&#39;, &#39;very/RB&#39;, &#39;fair/JJ&#39;, &#39;./.&#39;]</code></pre><hr><h3 id="4-text-class"><a href="#4-text-class" class="headerlink" title="4. text class"></a>4. text class</h3><ul><li><code>plot</code>: 단어token의 사용 빈도 그래프화</li><li><code>dispersion_plot</code>: 단어가 사용된 위치 시각화<ul><li>eg. 소설의 등장인물 등장 위치</li></ul></li><li><code>concordance</code>: lines 입력 갯수만큼 해당 문장 display</li><li><code>similar</code>: 해당 단어와 비슷한 문맥에서 사용된 단어</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> Text</span><br><span class="line">text = Text(retokenize.tokenize(raw))</span><br></pre></td></tr></table></figure><ul><li><code>plot</code>: 단어token의 사용 빈도 그래프화</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">text.plot(<span class="number">30</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_files/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_43_0.png" alt="png"></p><ul><li><code>dispersion_plot</code>: 단어가 사용된 위치 시각화<ul><li>eg. 소설의 등장인물 등장 위치</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">raw = nltk.corpus.gutenberg.raw(<span class="string">'austen-emma.txt'</span>)</span><br><span class="line">text = Text(retokenize.tokenize(raw))</span><br><span class="line"></span><br><span class="line">text.dispersion_plot([<span class="string">'Emma'</span>, <span class="string">'Knightly'</span>, <span class="string">'Frank'</span>, <span class="string">'Jane'</span>, <span class="string">'Robert'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_files/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_45_0.png" alt="png"></p><ul><li><code>concordance</code>: lines 입력 갯수만큼 해당 문장 display</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text.concordance(<span class="string">'Emma'</span>, lines=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>Displaying 5 of 865 matches: Emma by Jane Austen 1816 VOLUME I CHAPTER Jane Austen 1816 VOLUME I CHAPTER I Emma Woodhouse handsome clever and rich wf both daughters but particularly of Emma Between _them_ it was more the intimnd friend very mutually attached and Emma doing just what she liked highly est by her own The real evils indeed of Emma s situation were the power of having</code></pre><ul><li><code>similar</code>: 해당 단어와 비슷한 문맥에서 사용된 단어</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text.similar(<span class="string">'Emma'</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><pre><code>she it he i harriet you her jane him that</code></pre><hr><h3 id="5-FreqDist"><a href="#5-FreqDist" class="headerlink" title="5. FreqDist"></a>5. FreqDist</h3><ul><li><code>FreqDist</code>: 문서에 사용된 단어의 사용빈도 정보 담는 class</li><li>return: <code>{&#39;word&#39;: frequency}</code></li></ul><h4 id="사용법1"><a href="#사용법1" class="headerlink" title="사용법1)"></a>사용법1)</h4><ul><li><code>Text</code> class의 vocab으로 추출</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fd = text.vocab()</span><br><span class="line">type(fd)</span><br></pre></td></tr></table></figure><pre><code>nltk.probability.FreqDist</code></pre><h4 id="사용법2"><a href="#사용법2" class="headerlink" title="사용법2)"></a>사용법2)</h4><ul><li>말뭉치에서 추려낸 단어로 <code>FreqDist</code> class 객체 생성<ul><li>예) Emma.txt corpus에서 사람(NNP, 고유대명사)만 추출 &amp; apply stop words</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nltk.help.upenn_tagset(<span class="string">'NNP'</span>)</span><br></pre></td></tr></table></figure><pre><code>NNP: noun, proper, singular    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA    Shannon A.K.C. Meltex Liverpool ...</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">emma_tokens = pos_tag(retokenize.tokenize(raw))</span><br><span class="line">len(emma_tokens), emma_tokens[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>(161983, (&#39;Emma&#39;, &#39;NN&#39;))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> FreqDist</span><br><span class="line"></span><br><span class="line">stopwords = [<span class="string">'Mr.'</span>, <span class="string">'Mrs.'</span>, <span class="string">'Miss'</span>, <span class="string">'Mr'</span>, <span class="string">'Mrs'</span>, <span class="string">'Dear'</span>]</span><br><span class="line">names_list = [t[<span class="number">0</span>] <span class="keyword">for</span> t <span class="keyword">in</span> emma_tokens <span class="keyword">if</span> t[<span class="number">1</span>] == <span class="string">"NNP"</span> <span class="keyword">and</span> t[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</span><br><span class="line">fd_names = FreqDist(names_list)</span><br><span class="line">fd_names</span><br></pre></td></tr></table></figure><pre><code>FreqDist({&#39;Emma&#39;: 830, &#39;Harriet&#39;: 491, &#39;Weston&#39;: 439, &#39;Knightley&#39;: 389, &#39;Elton&#39;: 385, &#39;Woodhouse&#39;: 304, &#39;Jane&#39;: 299, &#39;Fairfax&#39;: 241, &#39;Churchill&#39;: 223, &#39;Frank&#39;: 208, ...})</code></pre><hr><ul><li><code>N()</code>: 전체 단어수</li><li><code>freq(&quot;word&quot;)</code>: 확률</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fd_names.N(), fd_names[<span class="string">'Emma'</span>], fd_names.freq(<span class="string">'Emma'</span>)</span><br></pre></td></tr></table></figure><pre><code>(7863, 830, 0.10555767518758744)</code></pre><ul><li><code>most_common</code>: 출현빈도 높은 단어</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fd_names.most_common(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>[(&#39;Emma&#39;, 830), (&#39;Harriet&#39;, 491), (&#39;Weston&#39;, 439), (&#39;Knightley&#39;, 389), (&#39;Elton&#39;, 385)]</code></pre><hr><h3 id="6-wordcloud"><a href="#6-wordcloud" class="headerlink" title="6. wordcloud"></a>6. wordcloud</h3><ul><li><code>FreqDist</code> 활용</li><li>단어 빈도수에 따른 시각화</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line">wc = WordCloud(width=<span class="number">1000</span>, height=<span class="number">600</span>, background_color=<span class="string">'white'</span>, random_state=<span class="number">0</span>)</span><br><span class="line">plt.imshow(wc.generate_from_frequencies(fd_names))</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_files/%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%281%29_65_0.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
          <category> ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Text </tag>
            
            <tag> Preprocessing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Hexo] Create hexo github page</title>
      <link href="/2019/01/26/how-to-create-hexo-github-page/"/>
      <url>/2019/01/26/how-to-create-hexo-github-page/</url>
      
        <content type="html"><![CDATA[<h3 id="install-Node-js"><a href="#install-Node-js" class="headerlink" title="install Node.js"></a>install Node.js</h3><a id="more"></a><pre><code>$ wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.11/install.sh</code></pre><h3 id="install-hexo"><a href="#install-hexo" class="headerlink" title="install hexo"></a>install hexo</h3><pre><code>$ npm install hexo-cli -g$ hexo init blog # blog = &lt;file name&gt;$ cd blog</code></pre><h3 id="set-theme"><a href="#set-theme" class="headerlink" title="set theme"></a>set theme</h3><pre><code>$ git clone https://github.com/probberechts/hexo-theme-cactus.git themes/cactus$ vi _config.yml</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theme: cactus</span><br></pre></td></tr></table></figure><h3 id="setting-deploy-config"><a href="#setting-deploy-config" class="headerlink" title="setting deploy config."></a>setting deploy config.</h3><pre><code>$ npm install hexo-deployer-git --save$ vi _config.yml</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: https://github.com/HenryPaik1/HenryPaik1.github.io.git</span><br></pre></td></tr></table></figure><h3 id="apply-modification-amp-run-hexo-server"><a href="#apply-modification-amp-run-hexo-server" class="headerlink" title="apply modification &amp; run hexo server"></a>apply modification &amp; run hexo server</h3><pre><code>$ hexo g$ hexo s</code></pre><h3 id="sync-github"><a href="#sync-github" class="headerlink" title="sync github"></a>sync github</h3><pre><code>$ hexo d</code></pre><p><strong>refernce:</strong><br><a href="https://github.com/probberechts/hexo-theme-cactus" target="_blank" rel="noopener">https://github.com/probberechts/hexo-theme-cactus</a><br><a href="https://hexo.io/docs/commands" target="_blank" rel="noopener">https://hexo.io/docs/commands</a></p>]]></content>
      
      
      <categories>
          
          <category> Github </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
